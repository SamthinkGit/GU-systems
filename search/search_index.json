{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f \ud83d\ude80 Introduction Welcome to the main repository for our cutting-edge project on the implementation of ECM (Execution-Cognition Machine) as a strategic approach towards the development of Computer Autonomous AI. This initiative represents a significant leap in crafting an intelligent system that not only mimic but also evolve human-like cognitive functionalities autonomously in computer interaction. \ud83e\udde0 The project revolves around designing, testing, and refining theoretical models that translate complex human problem-solving capabilities into computational strategies executable by AI. We integrate advanced AI frameworks, particularly focusing on AutoGPT as the backbone for adaptive and scalable solutions. Our system architecture is robust, accommodating rapid iterations and rigorous validations through continuous integration and deployment mechanisms. \ud83d\udcda For detailed insights into our methodologies and system functionalities, please refer to the README, the documentation included in this repository or surf through the pages of this Wiki.","title":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f"},{"location":"#gu-systems-ecm-approximation-to-computer-autonomous-ai","text":"","title":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f"},{"location":"#introduction","text":"Welcome to the main repository for our cutting-edge project on the implementation of ECM (Execution-Cognition Machine) as a strategic approach towards the development of Computer Autonomous AI. This initiative represents a significant leap in crafting an intelligent system that not only mimic but also evolve human-like cognitive functionalities autonomously in computer interaction. \ud83e\udde0 The project revolves around designing, testing, and refining theoretical models that translate complex human problem-solving capabilities into computational strategies executable by AI. We integrate advanced AI frameworks, particularly focusing on AutoGPT as the backbone for adaptive and scalable solutions. Our system architecture is robust, accommodating rapid iterations and rigorous validations through continuous integration and deployment mechanisms. \ud83d\udcda For detailed insights into our methodologies and system functionalities, please refer to the README, the documentation included in this repository or surf through the pages of this Wiki.","title":"\ud83d\ude80 Introduction"},{"location":"AgentProtocol/","text":"The Agent Protocol is an integral part of the ECM architecture which has also defined key modules for agents that have shown the best outcomes in various sectors. In this way the main goal of AP is solving the lack of a standardized set of rules or guidelines in Agent building. A problem that would make agents impractical to reimplement for new tasks or in different sectors. Purpose of the Agent Protocol The Agent Protocol is an open-source project that establishes a set of minimally intrusive rules on the architectures of Artificial General Intelligences (AGIs) to define the expected behavior externally, while maintaining a \"black box\" approach to their internal implementation. This standardization facilitates the reuse and adaptation of agent designs across different platforms and tasks without needing to understand or alter the underlying codebase. To conform to the Agent Protocol, an AGI must implement several key features: REST API : The agent should feature a RESTful API that external users can interact with. This API eliminates dependencies on the code and language, making the original design reusable and accessible. The REST API includes specific endpoints for task management and step execution, which standardize interactions and simplify the integration process: /ap/v1/agent/tasks [POST] : This endpoint is used to create new specific tasks that the agent must execute. It accepts a detailed description of the task, including necessary inputs for its execution. /ap/v1/agent/tasks/{task_id}/steps [POST] : Designed to trigger the next step in a task's execution. This allows for sequential and detailed control over the processes carried out by the agent, ensuring effective tracking of progress and task completion. Implementation Details of the Agent Protocol The implementation of the Agent Protocol includes predefined response mechanisms. These ensure that any agent can consistently report the status of tasks and steps, results obtained, or any artifacts generated during the process. These mechanisms are designed to be simple and flexible, adaptable to different technologies and frameworks without compromising functionality. To encourage broad adoption and ease the integration of agents from different platforms, the protocol also provides a set of SDKs. These SDKs abstract the complexities of direct API implementation, offering a simplified interface that allows developers to focus on the high-level logic of their agents without getting bogged down in communication details or API syntax. AutoGPT and the Agent Protocol Thanks to this protocol, AutoGPT has launched a framework called \"Forge,\" which greatly facilitates the creation of agents aligned with the Agent Protocol. Forge acts as a scaffolding that developers can use to build their agents, ensuring they meet the standards set forth by the Agent Protocol while focusing on innovation and functionality. Conclusion The Agent Protocol serves as a foundational component in the ecosystem of ECM/AutoGPT, providing a standardized approach to agent development. This standardization is crucial for scaling the implementation of intelligent agents across different domains and platforms, ensuring interoperability and reusability.","title":"AgentProtocol"},{"location":"AgentProtocol/#purpose-of-the-agent-protocol","text":"The Agent Protocol is an open-source project that establishes a set of minimally intrusive rules on the architectures of Artificial General Intelligences (AGIs) to define the expected behavior externally, while maintaining a \"black box\" approach to their internal implementation. This standardization facilitates the reuse and adaptation of agent designs across different platforms and tasks without needing to understand or alter the underlying codebase. To conform to the Agent Protocol, an AGI must implement several key features: REST API : The agent should feature a RESTful API that external users can interact with. This API eliminates dependencies on the code and language, making the original design reusable and accessible. The REST API includes specific endpoints for task management and step execution, which standardize interactions and simplify the integration process: /ap/v1/agent/tasks [POST] : This endpoint is used to create new specific tasks that the agent must execute. It accepts a detailed description of the task, including necessary inputs for its execution. /ap/v1/agent/tasks/{task_id}/steps [POST] : Designed to trigger the next step in a task's execution. This allows for sequential and detailed control over the processes carried out by the agent, ensuring effective tracking of progress and task completion.","title":"Purpose of the Agent Protocol"},{"location":"AgentProtocol/#implementation-details-of-the-agent-protocol","text":"The implementation of the Agent Protocol includes predefined response mechanisms. These ensure that any agent can consistently report the status of tasks and steps, results obtained, or any artifacts generated during the process. These mechanisms are designed to be simple and flexible, adaptable to different technologies and frameworks without compromising functionality. To encourage broad adoption and ease the integration of agents from different platforms, the protocol also provides a set of SDKs. These SDKs abstract the complexities of direct API implementation, offering a simplified interface that allows developers to focus on the high-level logic of their agents without getting bogged down in communication details or API syntax.","title":"Implementation Details of the Agent Protocol"},{"location":"AgentProtocol/#autogpt-and-the-agent-protocol","text":"Thanks to this protocol, AutoGPT has launched a framework called \"Forge,\" which greatly facilitates the creation of agents aligned with the Agent Protocol. Forge acts as a scaffolding that developers can use to build their agents, ensuring they meet the standards set forth by the Agent Protocol while focusing on innovation and functionality.","title":"AutoGPT and the Agent Protocol"},{"location":"AgentProtocol/#conclusion","text":"The Agent Protocol serves as a foundational component in the ecosystem of ECM/AutoGPT, providing a standardized approach to agent development. This standardization is crucial for scaling the implementation of intelligent agents across different domains and platforms, ensuring interoperability and reusability.","title":"Conclusion"},{"location":"Architecture-Guide/","text":"Introduction In this guide, you will gain a deep understanding of the ECM architecture implemented in this repository. We will explore the main modules and core approaches to solving the ECM problem. It is recommended that you first read the Theoretical Fundamentals and the Architecture Overview guides. The primary challenge of an ECM lies in synchronizing multiple layers. Although an ECM can be approached with various architectures, this repository divides all modules into four layers: - /cognition_layer : This directory contains all the AI agents responsible for thinking, planning, reasoning, and all necessary components to fully build and deploy those agents , generally adhering to the Agent Protocol Standard. - /ecm : This directory holds all the mediators, communicators, and middleware between the execution layer and the cognition layer. Only templates and virtual functions reside here , allowing the cognition layer to interact with the execution layer through any implementation using templates such as an Interpreter. Additionally, tools that can be used in both execution and cognition layers, such as the Exelent Parser or the Item Registry, are found here. - /execution_layer : This directory includes all modules that assist agents in executing commands , typically communicated using the Exelent language. Here, you can find thread managers, registries, callbacks, etc. - /action_space : This directory defines all the actions that agents can take . By importing these modules, you add new interactions to your agent, with actions resolved by the execution layer. Modules for keyboard interaction, window management, etc., can be found here. Base Execution Diagram for the ECM Each layer in this architecture plays a crucial role in ensuring the efficiency, coherence, and functionality of the AI system. The following diagram illustrates the main execution flow of the ECM. The upper layers focus on cognitive interactions and decision-making, while the lower layers handle practical execution and management of specific functions. This separation of responsibilities allows for better organization and facilitates maintenance and scalability of the system. Cognition Layer Agent The Cognition Layer Agent is responsible for interacting with the LL. Its primary function is to handle problems by receiving a user query and generating a response to that problem, generally returning Exelent code . For this implementation, the agent can use tools, multiple steps, requests to the LLM, etc. Regardless of the agent's internal workings, the external interface behaves as an iterator, where each step of the agent is controlled by lower layers. Some implementations of this layer can be found in the /cognition_layer/[module]/agents directory, where each agent follows different architectures. Here are some examples: /planex : Planex uses three different agents (Planification, Reduction, Translation) executed sequentially. Each agent contains a function .plan() , .reduce() , or .translate() to chain the generated data from the LLM, returning a string with the generated plan. /planexv2 : PlanexV2 reuses the code of the original Planex agent but implements a new Blamer agent that checks if the code is correct. If not, it executes the failed agent again until obtaining a valid plan. /RePlan : RePlan uses ReAct architecture to control the execution of the generated code. It uses PlanexV2 for generating Exelent files, and once generated, it manages the interpreters to approve, control, and check the execution of the plan. Note that all these agents depend on a set of prompts usually found in the directory /cognition_layer/[agent]/agents/prompts.py . Some implementations of these agents in action can be found in the /tests/sandbox directory, where you can experiment with different queries. Note also how some of these agents implement an iter() function, which returns a generator allowing you to easily execute all the steps of the agent. The messages returned may vary between different agents, but they can implement a Response model as a dataclass, where you can obtain information about each step. agent = RePlan() step: ReplanResponse # In this case the generator is async, but this doesn't need to be true for all agents async for step in replan.iter(query=\"Open the terminal in linux\"): print(f\"[{step.name}]\" + Style.RESET_ALL) print(step.content) Further information about each agent can be found on the same file or by checking the wiki if it the agent has already been published. FastAgentProtocol The FastAgentProtocol is a simplified and faster alternative to the previous AgentProtocol , which required server setups and remote API configurations. The new approach eliminates unnecessary complexity, enabling direct and efficient communication between agents and the main system. Note: This protocol can be found at /cognition_layer/protocols/fast_ap.py Simplification : No more server setup or port management. Performance : Local execution reduces latency. Standardization : Provides a unified, consistent framework for agent integration. The FastAgentProtocol acts as a mediator between the main system and cognitive agents. It leverages an iterator-based approach, where the agent defines an iterative process that yields step-by-step progress. Each step includes information such as the step's name, content, and whether it's the final step. More information can be found in the FastAgentProtocol section on the wiki ECM Core The Main Module or ECM Core can be found at /ecm/core and contains the main execution loop of the system. This component is the operational core where all modules are managed. Here, you can test all agents. These agents are implemented at the top of the file and will be executed until stopped by the user. Here are some properties of this module: This module does not depend on the implementations or internals of the cognition/execution layers; it uses only the virtual interfaces/APIs from the middlewares. By default, all agent actions are deactivated in the host for safety reasons. Instead of executing, the actions will only log a simulation of each action's execution (keyboard, mouse control, etc. CognitionLayer steps are not included, only Action space). If you want to run an agent on the host machine with full integration, use /ecm/core/run_in_host.py . You can run this module using the following command: python ecm/core/main.py --debug --agent [Planex|PlanexV2|RePlan...] You can also use -h for more information about the arguments. python ecm/core/main.py -h Interpreter The Interpreter unifies all executors within a single framework, allowing the system to execute functions and read commands from Exelent files. All interpreters must satisfy the attributes defined in the virtual class found at /ecm/mediator/Interpreter.py . This means all interpreters must contain the following properties: Contain and inherit all the methods and attributes defined in the virtual Interpreter class. Define a supports class for assigning all properties that can be used (at least the contained properties, extendable as needed) by inheriting from the InterpreterSupports class. If the Interpreter supports feedback returning, it must return a Feedback Object that is a subclass , inheriting from the Feedback class defined in /ecm/mediator/feedback.py and defining all specified methods/properties. Note that all feedback generated must always contain an _exec_code to define the status of the execution, using the ExecutionStatus(Enum) class defined in /ecm/mediator/feedback.py . Execution Layer Module The Execution Layer Module manages the execution of functions within the system. This component coordinates and oversees the operation of various threads, functions, callbacks, etc., needed for building the interpreter and achieving the full execution of multiple tasks and different behaviors defined in the Exelent language. This module can vary significantly, making it challenging to establish a standard implementation. However, you can explore the ROSA Insights to further investigate the key problems of this layer. Action Space The Action Space consists of executable functions that can be run on the host. It represents the set of actions and commands available for the AI to carry out in response to requests and tasks assigned. It should contain multiple functions to facilitate the actions of the Agents. These functions have the following properties: They can raise feedback if the interpreter that calls those functions enables it, but it is better to directly return information to the agent and save statuses between calls. They must always receive str or list[str] as arguments and return str because they will be managed by an AI with words. They should be as simple and straightforward as possible. Avoid more than 2 arguments per function. They must always contain a docstring explaining their functionality and how to use them. This docstring will be shown to the agents. These actions can be defined anywhere, but it is standard to define them in the /action_space directory. To define them, you just have to use the Item Registry as follows: from ecm.tools.registry import ItemRegistry @ItemRegistry.register(type=\"action\") def hello_world(): \"\"\"Says hello world.\\nUsage: hello_world()\"\"\" # noqa print(\"Hello World!\") If you want the Agents to have multiple names for using you function you can use the alias function of the Item Registry. This will improve the AI's ease and probability to use your tool. @ItemRegistry.alias([ \"say_hello_world\", \"greet\" ]) @ItemRegistry.register(type=\"action\") def hello_world(): \"\"\"Says hello world.\\nUsage: hello_world()\"\"\" # noqa print(\"Hello World!\") Note: Don't use more than 3 aliases if it isn't necessary, each alias results in more tokens parsed by the Agent. Finally, note that all these functions must be imported in order to be registered in the ItemRegistry. Therefore, in multiple files, you will find imports like the following, even though they are not used in the file: import action_space.talk.greet # noqa Note: More information about the ItemRegistry can be found on its own section at the wiki. Conclusion This guide has provided a comprehensive overview of the ECM architecture implemented in this repository, detailing its layered structure and key components. Each layer and module plays a vital role in the overall architecture. By adhering to the defined standards and protocols, the system achieves a high level of integration and functionality, capable of synchronizing both cognition and execution layer.","title":"Introduction"},{"location":"Architecture-Guide/#introduction","text":"In this guide, you will gain a deep understanding of the ECM architecture implemented in this repository. We will explore the main modules and core approaches to solving the ECM problem. It is recommended that you first read the Theoretical Fundamentals and the Architecture Overview guides. The primary challenge of an ECM lies in synchronizing multiple layers. Although an ECM can be approached with various architectures, this repository divides all modules into four layers: - /cognition_layer : This directory contains all the AI agents responsible for thinking, planning, reasoning, and all necessary components to fully build and deploy those agents , generally adhering to the Agent Protocol Standard. - /ecm : This directory holds all the mediators, communicators, and middleware between the execution layer and the cognition layer. Only templates and virtual functions reside here , allowing the cognition layer to interact with the execution layer through any implementation using templates such as an Interpreter. Additionally, tools that can be used in both execution and cognition layers, such as the Exelent Parser or the Item Registry, are found here. - /execution_layer : This directory includes all modules that assist agents in executing commands , typically communicated using the Exelent language. Here, you can find thread managers, registries, callbacks, etc. - /action_space : This directory defines all the actions that agents can take . By importing these modules, you add new interactions to your agent, with actions resolved by the execution layer. Modules for keyboard interaction, window management, etc., can be found here.","title":"Introduction"},{"location":"Architecture-Guide/#base-execution-diagram-for-the-ecm","text":"Each layer in this architecture plays a crucial role in ensuring the efficiency, coherence, and functionality of the AI system. The following diagram illustrates the main execution flow of the ECM. The upper layers focus on cognitive interactions and decision-making, while the lower layers handle practical execution and management of specific functions. This separation of responsibilities allows for better organization and facilitates maintenance and scalability of the system.","title":"Base Execution Diagram for the ECM"},{"location":"Architecture-Guide/#cognition-layer-agent","text":"The Cognition Layer Agent is responsible for interacting with the LL. Its primary function is to handle problems by receiving a user query and generating a response to that problem, generally returning Exelent code . For this implementation, the agent can use tools, multiple steps, requests to the LLM, etc. Regardless of the agent's internal workings, the external interface behaves as an iterator, where each step of the agent is controlled by lower layers. Some implementations of this layer can be found in the /cognition_layer/[module]/agents directory, where each agent follows different architectures. Here are some examples: /planex : Planex uses three different agents (Planification, Reduction, Translation) executed sequentially. Each agent contains a function .plan() , .reduce() , or .translate() to chain the generated data from the LLM, returning a string with the generated plan. /planexv2 : PlanexV2 reuses the code of the original Planex agent but implements a new Blamer agent that checks if the code is correct. If not, it executes the failed agent again until obtaining a valid plan. /RePlan : RePlan uses ReAct architecture to control the execution of the generated code. It uses PlanexV2 for generating Exelent files, and once generated, it manages the interpreters to approve, control, and check the execution of the plan. Note that all these agents depend on a set of prompts usually found in the directory /cognition_layer/[agent]/agents/prompts.py . Some implementations of these agents in action can be found in the /tests/sandbox directory, where you can experiment with different queries. Note also how some of these agents implement an iter() function, which returns a generator allowing you to easily execute all the steps of the agent. The messages returned may vary between different agents, but they can implement a Response model as a dataclass, where you can obtain information about each step. agent = RePlan() step: ReplanResponse # In this case the generator is async, but this doesn't need to be true for all agents async for step in replan.iter(query=\"Open the terminal in linux\"): print(f\"[{step.name}]\" + Style.RESET_ALL) print(step.content) Further information about each agent can be found on the same file or by checking the wiki if it the agent has already been published.","title":"Cognition Layer Agent"},{"location":"Architecture-Guide/#fastagentprotocol","text":"The FastAgentProtocol is a simplified and faster alternative to the previous AgentProtocol , which required server setups and remote API configurations. The new approach eliminates unnecessary complexity, enabling direct and efficient communication between agents and the main system. Note: This protocol can be found at /cognition_layer/protocols/fast_ap.py Simplification : No more server setup or port management. Performance : Local execution reduces latency. Standardization : Provides a unified, consistent framework for agent integration. The FastAgentProtocol acts as a mediator between the main system and cognitive agents. It leverages an iterator-based approach, where the agent defines an iterative process that yields step-by-step progress. Each step includes information such as the step's name, content, and whether it's the final step. More information can be found in the FastAgentProtocol section on the wiki","title":"FastAgentProtocol"},{"location":"Architecture-Guide/#ecm-core","text":"The Main Module or ECM Core can be found at /ecm/core and contains the main execution loop of the system. This component is the operational core where all modules are managed. Here, you can test all agents. These agents are implemented at the top of the file and will be executed until stopped by the user. Here are some properties of this module: This module does not depend on the implementations or internals of the cognition/execution layers; it uses only the virtual interfaces/APIs from the middlewares. By default, all agent actions are deactivated in the host for safety reasons. Instead of executing, the actions will only log a simulation of each action's execution (keyboard, mouse control, etc. CognitionLayer steps are not included, only Action space). If you want to run an agent on the host machine with full integration, use /ecm/core/run_in_host.py . You can run this module using the following command: python ecm/core/main.py --debug --agent [Planex|PlanexV2|RePlan...] You can also use -h for more information about the arguments. python ecm/core/main.py -h","title":"ECM Core"},{"location":"Architecture-Guide/#interpreter","text":"The Interpreter unifies all executors within a single framework, allowing the system to execute functions and read commands from Exelent files. All interpreters must satisfy the attributes defined in the virtual class found at /ecm/mediator/Interpreter.py . This means all interpreters must contain the following properties: Contain and inherit all the methods and attributes defined in the virtual Interpreter class. Define a supports class for assigning all properties that can be used (at least the contained properties, extendable as needed) by inheriting from the InterpreterSupports class. If the Interpreter supports feedback returning, it must return a Feedback Object that is a subclass , inheriting from the Feedback class defined in /ecm/mediator/feedback.py and defining all specified methods/properties. Note that all feedback generated must always contain an _exec_code to define the status of the execution, using the ExecutionStatus(Enum) class defined in /ecm/mediator/feedback.py .","title":"Interpreter"},{"location":"Architecture-Guide/#execution-layer-module","text":"The Execution Layer Module manages the execution of functions within the system. This component coordinates and oversees the operation of various threads, functions, callbacks, etc., needed for building the interpreter and achieving the full execution of multiple tasks and different behaviors defined in the Exelent language. This module can vary significantly, making it challenging to establish a standard implementation. However, you can explore the ROSA Insights to further investigate the key problems of this layer.","title":"Execution Layer Module"},{"location":"Architecture-Guide/#action-space","text":"The Action Space consists of executable functions that can be run on the host. It represents the set of actions and commands available for the AI to carry out in response to requests and tasks assigned. It should contain multiple functions to facilitate the actions of the Agents. These functions have the following properties: They can raise feedback if the interpreter that calls those functions enables it, but it is better to directly return information to the agent and save statuses between calls. They must always receive str or list[str] as arguments and return str because they will be managed by an AI with words. They should be as simple and straightforward as possible. Avoid more than 2 arguments per function. They must always contain a docstring explaining their functionality and how to use them. This docstring will be shown to the agents. These actions can be defined anywhere, but it is standard to define them in the /action_space directory. To define them, you just have to use the Item Registry as follows: from ecm.tools.registry import ItemRegistry @ItemRegistry.register(type=\"action\") def hello_world(): \"\"\"Says hello world.\\nUsage: hello_world()\"\"\" # noqa print(\"Hello World!\") If you want the Agents to have multiple names for using you function you can use the alias function of the Item Registry. This will improve the AI's ease and probability to use your tool. @ItemRegistry.alias([ \"say_hello_world\", \"greet\" ]) @ItemRegistry.register(type=\"action\") def hello_world(): \"\"\"Says hello world.\\nUsage: hello_world()\"\"\" # noqa print(\"Hello World!\") Note: Don't use more than 3 aliases if it isn't necessary, each alias results in more tokens parsed by the Agent. Finally, note that all these functions must be imported in order to be registered in the ItemRegistry. Therefore, in multiple files, you will find imports like the following, even though they are not used in the file: import action_space.talk.greet # noqa Note: More information about the ItemRegistry can be found on its own section at the wiki.","title":"Action Space"},{"location":"Architecture-Guide/#conclusion","text":"This guide has provided a comprehensive overview of the ECM architecture implemented in this repository, detailing its layered structure and key components. Each layer and module plays a vital role in the overall architecture. By adhering to the defined standards and protocols, the system achieves a high level of integration and functionality, capable of synchronizing both cognition and execution layer.","title":"Conclusion"},{"location":"Bibliography/","text":"Alias Name Date Link Keywords PMPA A Survey on Large Language Model based Autonomous Agents 2023 arXiv PMPA , State of Art , Agent Architecture Prompt Engineering A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications 2024 arXiv PromptEngineering , Comparative , Optimization Voyager Voyager: An Open-Ended Embodied Agent with Large Language Models 2023 arXiv AI Model , Minecraft , AutoGPT Fine-Tuned Models vs GPT4 Prompt Engineering or Fine Tuning: An Empirical Assessment of Large Language Models in Automated Software Engineering Tasks 2023 arXiv Fine-Tuning , PromptEngineering , GPT-4 EvalPlus (Code Evaluator) Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation 2023 NeurIPS evalution , test , leaderboards Grammar Prompting Grammar Prompting for Domain-Specific Language Generation with Large Language Models 2023 NeurIPS Formatting , Translation , Specialization LLM Repurposing Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains 2024 arXiv Specialization , Optimization , DSL LLM Planners Understanding the planning of LLM agents: A survey 2024 arXiv Planning , Agents , Autonomous ReAct ReAct: Synergizing Reasoning and Acting in Language Models 2022 arXiv Agent , Planner , Solver Weak/Strong AI Minds, brains, and programs. Behavioral and Brain Sciences 3 (3): 417-45 1980 Web-Archive AI Strong AI Weak AI The Cognition Problem The naturalistic imperative in cognitive science 04/97 BNC Cognition GPS Problem Solving Classical AI Artificial intelligence: a modern approach 2016 Hoasen Classic AI Searching STRIPS STRIPS: A new approach to the application of theorem proving to problem solving 1971 ScienceDirect STRIPS Classic AI PDDL Pddl | the planning domain definition language 1998 ResearchGate PDDL Planning GPT-4 Gpt-4 technical report 2023 ArXiv LLM GPT-4 OpenAI Gemini Welcome to the Gemini era: Google DeepMind and the information industry 2023 Emerald Gemini Google LLM Llama2 Llama 2: Open foundation and fine-tuned chat models 2023 ArXiv Llama-2 LLM Meta GPS Report on a general problem-solving program. 1959 bitSavers GPS Problem Solver Cognition Classical AI AGI Position: Levels of AGI for Operationalizing Progress on the Path to AGI 2023 ArXiv AGI Modern AI Strong AI AutoGPT From GPT to AutoGPT: a Brief Attention in NLP Processing using DL 2023 ResearchGate AGI Agents Deployment GPT SOAR The Soar Cognitive Architecture 2019 GoogleBooks SOAR Cognition Architecture Explore/Exploit Exploration and exploitation in evolutionary algorithms: A survey 2013 ArXiv Exploration Explotation Search Tree-Of-Thoughts Q* and State-Of-Art From google gemini to openai q*(q-star): A survey of reshaping the generative artificial intelligence (ai) research landscape 2023 ArXiV Q* State-Of-Art Mixture-Of-Experts (MOE) AGI","title":"Bibliography"},{"location":"Cognition-Layer-API-%28Planex%29/","text":"Cognition Layer API The Cognition Layer is the component of the ECM responsible for reasoning, planning, and resolving an Exelent file based on a user's query. User queries can vary widely, encompassing actions such as \"write Hello World in Notepad\" or \"edit this image in Photoshop.\" The ECM does not impose restrictions on the language or framework used to implement the cognition layer. We leverage the Agent Protocol REST API to facilitate communication with agents. In this tutorial, we will use Planex as an example agent for planning. Planex is a 3-step planner agent utilizing LangChain to approximate the ECM problem. This approximation involves three agents focusing on Planning, Reduction, and Translation, based on the Theoretical Analysis . However, the REST API interface remains consistent across all agents. Settling up As Planex operates as an API-based agent, it requires starting the PlanexServer to initialize all necessary components. Building the server is a blocking call, so it can be run in a separate .py file or a different process: import atexit import multiprocessing from cognition_layer.planexv2.api.server import PlanexV2Server server = PlanexV2Server(verbose=True) server_process = multiprocessing.Process(target=server.start) server_process.start() # We can manually join the proccess, but we will settle it as an atexit task for easing it. atexit.register(lambda p: p.join(), server_process) Using the verbose argument prints all intermediate steps. Running Planex With everything set up, we can start passing queries to Planex. There are two options for this: [Recommended] Using the Mediator class of the ECM, which simplifies API calls for Planex (or other Cognition Layer Agents). Directly using the Agent Protocol . Planex has two handlers (task_handler and step_handler) that support all API calls from the AP, allowing free usage if preferred. In this tutorial, we will use the Mediator class to run Planex. Note that this mediator acts as a client for the previously invoked RestAPI, so it must run within an APIClient from the Agent Protocol. First, we need to configure the API: import agent_protocol_client from cognition_layer.constants import API_ADDRESS from cognition_layer.constants import API_PORT host = f\"http://{API_ADDRESS}:{API_PORT}\" configuration = agent_protocol_client.Configuration(host=host) In this case, we use the default address and port of the ECM (0.0.0.0:8090), but feel free to change them as needed. Ensure the new address is updated in the ECM constants so the server adapts accordingly. With the configuration set, we can query a task using the mediator. The mediator is an async function and should be called within an async definition. from cognition_layer.api import CognitionMediator import asyncio async def main(): async with agent_protocol_client.ApiClient(configuration) as api_client: mediator = CognitionMediator(api_client) while True: query = input(\"Request a Task: \") task = await mediator.get_task(input=query) result = await mediator.run_task(task) print (\"Result: \", result) asyncio.run(main())","title":"Cognition Layer API"},{"location":"Cognition-Layer-API-%28Planex%29/#cognition-layer-api","text":"The Cognition Layer is the component of the ECM responsible for reasoning, planning, and resolving an Exelent file based on a user's query. User queries can vary widely, encompassing actions such as \"write Hello World in Notepad\" or \"edit this image in Photoshop.\" The ECM does not impose restrictions on the language or framework used to implement the cognition layer. We leverage the Agent Protocol REST API to facilitate communication with agents. In this tutorial, we will use Planex as an example agent for planning. Planex is a 3-step planner agent utilizing LangChain to approximate the ECM problem. This approximation involves three agents focusing on Planning, Reduction, and Translation, based on the Theoretical Analysis . However, the REST API interface remains consistent across all agents.","title":"Cognition Layer API"},{"location":"Cognition-Layer-API-%28Planex%29/#settling-up","text":"As Planex operates as an API-based agent, it requires starting the PlanexServer to initialize all necessary components. Building the server is a blocking call, so it can be run in a separate .py file or a different process: import atexit import multiprocessing from cognition_layer.planexv2.api.server import PlanexV2Server server = PlanexV2Server(verbose=True) server_process = multiprocessing.Process(target=server.start) server_process.start() # We can manually join the proccess, but we will settle it as an atexit task for easing it. atexit.register(lambda p: p.join(), server_process) Using the verbose argument prints all intermediate steps.","title":"Settling up"},{"location":"Cognition-Layer-API-%28Planex%29/#running-planex","text":"With everything set up, we can start passing queries to Planex. There are two options for this: [Recommended] Using the Mediator class of the ECM, which simplifies API calls for Planex (or other Cognition Layer Agents). Directly using the Agent Protocol . Planex has two handlers (task_handler and step_handler) that support all API calls from the AP, allowing free usage if preferred. In this tutorial, we will use the Mediator class to run Planex. Note that this mediator acts as a client for the previously invoked RestAPI, so it must run within an APIClient from the Agent Protocol. First, we need to configure the API: import agent_protocol_client from cognition_layer.constants import API_ADDRESS from cognition_layer.constants import API_PORT host = f\"http://{API_ADDRESS}:{API_PORT}\" configuration = agent_protocol_client.Configuration(host=host) In this case, we use the default address and port of the ECM (0.0.0.0:8090), but feel free to change them as needed. Ensure the new address is updated in the ECM constants so the server adapts accordingly. With the configuration set, we can query a task using the mediator. The mediator is an async function and should be called within an async definition. from cognition_layer.api import CognitionMediator import asyncio async def main(): async with agent_protocol_client.ApiClient(configuration) as api_client: mediator = CognitionMediator(api_client) while True: query = input(\"Request a Task: \") task = await mediator.get_task(input=query) result = await mediator.run_task(task) print (\"Result: \", result) asyncio.run(main())","title":"Running Planex"},{"location":"ECM-Problem-Analysis/","text":"Definition of the Problem To achieve an ECM (Efficient Computation Model), it is essential to demonstrate that the following equality holds true: $$[ \\text{Alg}_1(p \\mid C') = { \\lambda \\mid \\lambda \\in A' \\text{ and } \\text{Alg}_2(\\lambda)=s' } ]$$ Note: Remember that Alg is an alias for Algorithm For a deep and thorough understanding of this concept, we must first define the core variables within this context: 1. Action Space : The action space, denoted as $A$, refers to the comprehensive set of all possible actions abstracted from the framework that can be utilized to solve any given problem. Here, we distinguish three types: $A$ : This denotes all the conceivable actions that can be employed to resolve any problem. In this context, we assume that all problems are solvable using this space. $A^*$ : This refers to the minimal set of actions required to solve a specified problem. Thus, all problems can be solved utilizing this space. Unlike $A$, $A^*$ must be computable and Turing-Complete, ensuring that it can be executed algorithmically. $A'$ : This represents the set of actions contained within a particular approximation to the ECM problem. In this scenario, not all problems can be solved using this space, highlighting its limitations. 2. Action Sequences : An action sequence, represented by $\\lambda$, refers to a specific series of actions used to address and solve a particular problem. We categorize action sequences into three types: $\\lambda$ : This denotes the perfect set of actions, representing the ideal combination of steps required to solve a given problem most efficiently. $\\lambda^*$ : This refers to an optimal set of actions, which is one possible set of steps that can at least solve the problem, though it may not be the most efficient. $\\lambda'$ : This signifies a proposed set of actions generated by an algorithm intended to solve a unique problem. This proposed set does not guarantee that the problem will be solved, indicating potential inefficiencies or gaps in the algorithm. 3. Solutions : A solution, denoted by $s$, is an abstraction representing the resolution of a problem. We define solutions as follows: $s$ : This is a comprehensive solution that is capable of solving all conceivable problems. $s^*$ : This denotes a solution that is tailored to solve a specific, given problem. $s'$ : This represents a potential solution to a given problem, which is proposed but not assured to be effective or successful. Summary Table Perfect (All Problems) Optimal (One problem) Approximation (Could Fail) Action Space $$A$$ $$A^*$$ $$A'$$ Sequence $$\\lambda$$ $$\\lambda^*$$ $$\\lambda'$$ Solution $$s$$ $$s^*$$ $$s'$$ Note that we will sometimes use $\\lambda_n$ for referring to a specific instance of $\\lambda$. Error Abstraction To design and optimize the problem, we need to compute some form of error to estimate and compare the behavior of the ECM. We analyze the error of the core formula by splitting it into two parts: Cognition Space : Refers to the planning of the problem, mainly approached using NLP-based Agents. Execution Space : Refers to the execution of a given plan, approached using a more deterministic framework. Cognition Space Suppose we have a problem $p$ and we want to find a sequence of actions $\\lambda$ to solve it. The agent faces three main problems: Planification : Does the agent have the knowledge/capability to solve the problem? The core issue here is the agent's reasoning about the problem and generating an approximation to the problem, independent of the tools available. Reduction : How can the agent execute its plan with the given tools? The core issue here is reducing the computed actions to those the agent can use in its framework. If the framework lacks necessary tools, this step is impossible without failure. Translation : How can the agent translate its reasoning into a concrete framework/language? The core issue here is translating natural language reasoning into a programmatic definition. Execution Space After planning and reasoning, the steps must be executed to reach a solution. Similar to following a recipe, execution might not go as intended: Interpretation : There could be differences between the specified plan and runtime execution. For example, the plan might specify \"click the first word containing 'A'\", which could result in varied interpretations. Execution : Even ignoring interpretation, the planned step might raise an unforeseen exception, requiring the agent to re-plan. After having defined each type of error we want to make an abstraction of those errors, so we can analyze how we can make an approximation of them and know what should be improved. Let's see step by step an abstraction of each one: Planification $$ Planificate(query) \\rightarrow \\lambda_1 := [a,b,c,...] \\subseteq A \\mid Alg_2(\\lambda_1) = s $$ Let's break this equation down: The planification step is a function that receives a NL-query $Planificate(query)$ and returns a set of actions $[a,b,c,...]$ referred to as $\\lambda_1$. This function must meet two conditions: First, $\\lambda_1$ should be a subset of actions in $A$. Second, these actions should be executable to solve the query $Alg_2(\\lambda_1) = s$. Error : $$error_{plan} = 0 + [s - Alg_2(\\lambda_1)] = Alg_2(\\lambda) - Alg_2(\\lambda_1)$$ For computing the error, we can split the first equation into two parts. First, note that the possible error in $\\lambda_1 := [a,b,c,...] \\subseteq A$ is $0$ because: $A$ denotes all the conceivable actions that can be employed to resolve any problem. So by definition, the set of actions must be a subset of $A$. Then, we can define the error of $Alg_2(\\lambda_1)$ by comparing it with its expected value $s$. If the algorithm should return $s$, the error is $s - Alg_2(\\lambda_1)$. Note that a solution $s$ can also be defined as the execution of a perfect plan, $Alg_2(\\lambda)$, where $\\lambda$ is the perfect plan, leading to: $$error_{plan} = Alg_2(\\lambda) - Alg_2(\\lambda_1)$$ Reduction $$Reduce(\\lambda_1) \\rightarrow \\lambda_2 := [x,y,...] \\subseteq A^* \\mid Alg_2(\\lambda_2) = s^*$$ The reduction error is a function that receives a plan (a sequence of NL-actions) and reduces that plan to one where all actions are a subset of $A^*$. Note how we must consider the same conditions as in the planification section. Error : $$error_{reduction} = [ \\lambda^* - \\lambda_2 ] \\cup [ Alg_2(\\lambda^*) - Alg_2(\\lambda_2) ]$$ Following the same reasoning, we split the equation into two parts. First, there could be a gap between the optimal plan $\\lambda^*$ and the generated plan $\\lambda_2$, possibly due to a poor selection of tools even if planification succeeded. Second, there is the same error as previously: the plan must be executable to be valid. Since the optimal plan $\\lambda^*$ is executable, the error of the second part is $Alg_2(\\lambda^*) - Alg_2(\\lambda_2)$. Note that the second condition uses $\\lambda^*$ instead of $\\lambda$ used in the planification step. This is due to the action space $A^*$, where the best solution in an optimal action space is $\\lambda^*$ (not the perfect solution $\\lambda$). Also, we use $\\cup$ notation for joining the errors, since the relationship is not clear. Translation $$Translate(\\lambda_2) \\rightarrow \\lambda_3$$ The translation step is a function that receives the reduced plan and generates an equivalent description in the framework that will use that plan. The error in this process arises from the quality loss of the original plan. Error : $$error_{translation} = \\lambda_2 - \\lambda_3$$ Defining the error here is straightforward (theoretically). We compare the plan specified in natural language with its programmatic description. If the match is exact, the error is $0$. Interpretation $$Interpretate(\\lambda_3) \\rightarrow \\lambda_4 := [x_1, y_1, ...] \\subseteq A^*$$ The interpretation step is the reverse of the translation step. It can be seen as an encoding-decoding process, where errors arise from recovering the encoded data without quality loss. Error : $$error_{interpretation} = \\lambda_3 - \\lambda_4$$ Execution $$Execute(\\lambda_4) \\rightarrow s_4$$ In the execution function, the next step is not defined, as execution itself is the solution. The error is defined by the framework's capacity to properly run the given steps. Error : $$error_{execution} = s_4 - \\lambda_4$$ Summary Table Step Error Planification $$Alg_2(\\lambda) - Alg_2(\\lambda_1)$$ Reduction $$( \\lambda^* - \\lambda_2 ) \\cup ( Alg_2(\\lambda^*) - Alg_2(\\lambda_2) )$$ Translation (Encoding) $$\\lambda_2 - \\lambda_3$$ Interpretation (Decoding) $$\\lambda_3 - \\lambda_4$$ Execution $$s_4 - \\lambda_4$$","title":"ECM Problem Analysis"},{"location":"ECM-Problem-Analysis/#definition-of-the-problem","text":"To achieve an ECM (Efficient Computation Model), it is essential to demonstrate that the following equality holds true: $$[ \\text{Alg}_1(p \\mid C') = { \\lambda \\mid \\lambda \\in A' \\text{ and } \\text{Alg}_2(\\lambda)=s' } ]$$ Note: Remember that Alg is an alias for Algorithm For a deep and thorough understanding of this concept, we must first define the core variables within this context:","title":"Definition of the Problem"},{"location":"ECM-Problem-Analysis/#1-action-space","text":"The action space, denoted as $A$, refers to the comprehensive set of all possible actions abstracted from the framework that can be utilized to solve any given problem. Here, we distinguish three types: $A$ : This denotes all the conceivable actions that can be employed to resolve any problem. In this context, we assume that all problems are solvable using this space. $A^*$ : This refers to the minimal set of actions required to solve a specified problem. Thus, all problems can be solved utilizing this space. Unlike $A$, $A^*$ must be computable and Turing-Complete, ensuring that it can be executed algorithmically. $A'$ : This represents the set of actions contained within a particular approximation to the ECM problem. In this scenario, not all problems can be solved using this space, highlighting its limitations.","title":"1. Action Space:"},{"location":"ECM-Problem-Analysis/#2-action-sequences","text":"An action sequence, represented by $\\lambda$, refers to a specific series of actions used to address and solve a particular problem. We categorize action sequences into three types: $\\lambda$ : This denotes the perfect set of actions, representing the ideal combination of steps required to solve a given problem most efficiently. $\\lambda^*$ : This refers to an optimal set of actions, which is one possible set of steps that can at least solve the problem, though it may not be the most efficient. $\\lambda'$ : This signifies a proposed set of actions generated by an algorithm intended to solve a unique problem. This proposed set does not guarantee that the problem will be solved, indicating potential inefficiencies or gaps in the algorithm.","title":"2. Action Sequences:"},{"location":"ECM-Problem-Analysis/#3-solutions","text":"A solution, denoted by $s$, is an abstraction representing the resolution of a problem. We define solutions as follows: $s$ : This is a comprehensive solution that is capable of solving all conceivable problems. $s^*$ : This denotes a solution that is tailored to solve a specific, given problem. $s'$ : This represents a potential solution to a given problem, which is proposed but not assured to be effective or successful.","title":"3. Solutions:"},{"location":"ECM-Problem-Analysis/#summary-table","text":"Perfect (All Problems) Optimal (One problem) Approximation (Could Fail) Action Space $$A$$ $$A^*$$ $$A'$$ Sequence $$\\lambda$$ $$\\lambda^*$$ $$\\lambda'$$ Solution $$s$$ $$s^*$$ $$s'$$ Note that we will sometimes use $\\lambda_n$ for referring to a specific instance of $\\lambda$.","title":"Summary Table"},{"location":"ECM-Problem-Analysis/#error-abstraction","text":"To design and optimize the problem, we need to compute some form of error to estimate and compare the behavior of the ECM. We analyze the error of the core formula by splitting it into two parts: Cognition Space : Refers to the planning of the problem, mainly approached using NLP-based Agents. Execution Space : Refers to the execution of a given plan, approached using a more deterministic framework.","title":"Error Abstraction"},{"location":"ECM-Problem-Analysis/#cognition-space","text":"Suppose we have a problem $p$ and we want to find a sequence of actions $\\lambda$ to solve it. The agent faces three main problems: Planification : Does the agent have the knowledge/capability to solve the problem? The core issue here is the agent's reasoning about the problem and generating an approximation to the problem, independent of the tools available. Reduction : How can the agent execute its plan with the given tools? The core issue here is reducing the computed actions to those the agent can use in its framework. If the framework lacks necessary tools, this step is impossible without failure. Translation : How can the agent translate its reasoning into a concrete framework/language? The core issue here is translating natural language reasoning into a programmatic definition.","title":"Cognition Space"},{"location":"ECM-Problem-Analysis/#execution-space","text":"After planning and reasoning, the steps must be executed to reach a solution. Similar to following a recipe, execution might not go as intended: Interpretation : There could be differences between the specified plan and runtime execution. For example, the plan might specify \"click the first word containing 'A'\", which could result in varied interpretations. Execution : Even ignoring interpretation, the planned step might raise an unforeseen exception, requiring the agent to re-plan. After having defined each type of error we want to make an abstraction of those errors, so we can analyze how we can make an approximation of them and know what should be improved. Let's see step by step an abstraction of each one:","title":"Execution Space"},{"location":"ECM-Problem-Analysis/#planification","text":"$$ Planificate(query) \\rightarrow \\lambda_1 := [a,b,c,...] \\subseteq A \\mid Alg_2(\\lambda_1) = s $$ Let's break this equation down: The planification step is a function that receives a NL-query $Planificate(query)$ and returns a set of actions $[a,b,c,...]$ referred to as $\\lambda_1$. This function must meet two conditions: First, $\\lambda_1$ should be a subset of actions in $A$. Second, these actions should be executable to solve the query $Alg_2(\\lambda_1) = s$. Error : $$error_{plan} = 0 + [s - Alg_2(\\lambda_1)] = Alg_2(\\lambda) - Alg_2(\\lambda_1)$$ For computing the error, we can split the first equation into two parts. First, note that the possible error in $\\lambda_1 := [a,b,c,...] \\subseteq A$ is $0$ because: $A$ denotes all the conceivable actions that can be employed to resolve any problem. So by definition, the set of actions must be a subset of $A$. Then, we can define the error of $Alg_2(\\lambda_1)$ by comparing it with its expected value $s$. If the algorithm should return $s$, the error is $s - Alg_2(\\lambda_1)$. Note that a solution $s$ can also be defined as the execution of a perfect plan, $Alg_2(\\lambda)$, where $\\lambda$ is the perfect plan, leading to: $$error_{plan} = Alg_2(\\lambda) - Alg_2(\\lambda_1)$$","title":"Planification"},{"location":"ECM-Problem-Analysis/#reduction","text":"$$Reduce(\\lambda_1) \\rightarrow \\lambda_2 := [x,y,...] \\subseteq A^* \\mid Alg_2(\\lambda_2) = s^*$$ The reduction error is a function that receives a plan (a sequence of NL-actions) and reduces that plan to one where all actions are a subset of $A^*$. Note how we must consider the same conditions as in the planification section. Error : $$error_{reduction} = [ \\lambda^* - \\lambda_2 ] \\cup [ Alg_2(\\lambda^*) - Alg_2(\\lambda_2) ]$$ Following the same reasoning, we split the equation into two parts. First, there could be a gap between the optimal plan $\\lambda^*$ and the generated plan $\\lambda_2$, possibly due to a poor selection of tools even if planification succeeded. Second, there is the same error as previously: the plan must be executable to be valid. Since the optimal plan $\\lambda^*$ is executable, the error of the second part is $Alg_2(\\lambda^*) - Alg_2(\\lambda_2)$. Note that the second condition uses $\\lambda^*$ instead of $\\lambda$ used in the planification step. This is due to the action space $A^*$, where the best solution in an optimal action space is $\\lambda^*$ (not the perfect solution $\\lambda$). Also, we use $\\cup$ notation for joining the errors, since the relationship is not clear.","title":"Reduction"},{"location":"ECM-Problem-Analysis/#translation","text":"$$Translate(\\lambda_2) \\rightarrow \\lambda_3$$ The translation step is a function that receives the reduced plan and generates an equivalent description in the framework that will use that plan. The error in this process arises from the quality loss of the original plan. Error : $$error_{translation} = \\lambda_2 - \\lambda_3$$ Defining the error here is straightforward (theoretically). We compare the plan specified in natural language with its programmatic description. If the match is exact, the error is $0$.","title":"Translation"},{"location":"ECM-Problem-Analysis/#interpretation","text":"$$Interpretate(\\lambda_3) \\rightarrow \\lambda_4 := [x_1, y_1, ...] \\subseteq A^*$$ The interpretation step is the reverse of the translation step. It can be seen as an encoding-decoding process, where errors arise from recovering the encoded data without quality loss. Error : $$error_{interpretation} = \\lambda_3 - \\lambda_4$$","title":"Interpretation"},{"location":"ECM-Problem-Analysis/#execution","text":"$$Execute(\\lambda_4) \\rightarrow s_4$$ In the execution function, the next step is not defined, as execution itself is the solution. The error is defined by the framework's capacity to properly run the given steps. Error : $$error_{execution} = s_4 - \\lambda_4$$","title":"Execution"},{"location":"ECM-Problem-Analysis/#summary-table_1","text":"Step Error Planification $$Alg_2(\\lambda) - Alg_2(\\lambda_1)$$ Reduction $$( \\lambda^* - \\lambda_2 ) \\cup ( Alg_2(\\lambda^*) - Alg_2(\\lambda_2) )$$ Translation (Encoding) $$\\lambda_2 - \\lambda_3$$ Interpretation (Decoding) $$\\lambda_3 - \\lambda_4$$ Execution $$s_4 - \\lambda_4$$","title":"Summary Table"},{"location":"Exelent/","text":"Introduction So far, multiple planning languages have been developed to be computable, with PDDL (Planning Domain Definition Language) being widely used for automatic plan computation. JSON descriptions have also been utilized to enable LLMs to define objects or generations. In this context, Exelent (an acronym for 'Execution Language') emerges as a faster and easier declarative language with Pythonic syntax. Designed for describing AI-generated plans and sequences of programmatic steps to reach a solution, Exelent combines simplicity with the familiarity of Python. Key Properties of Exelent Pythonic Syntax : Exelent uses a Pythonic syntax, making it accessible and familiar to users of Python. This design choice leverages the extensive Python code training datasets of many LLMs, potentially improving results and reducing the need for extensive fine- Efficiency : The minimal use of keywords and dynamic resolution reduces the number of tokens that need to be generated by LLMs, resulting in more efficient and cost-effective requests. Compatibility : Exelent is compatible with all Python functions, including support for multitasking and parallel planning. Additional behaviors are under development to further enhance its capabilities. Ease of Parsing and Extension : Exelent is easy to parse and extend using the built-in ExelentParser or directly with the ast library, which is fully supported. By incorporating these properties, Exelent aims to provide a robust and efficient solution for AI-driven plan generation and execution. Syntax The syntax of Exelent is straightforward. Each file contains a set of plans, which can be built following three Define a Plan Function : All plans are defined as functions. A plan definition can include arguments specifying the properties of the plan. Define Types within Each Plan : A type represents a predefined behavior, similar to using loops (e.g., \"for\" or \"while\") in imperative programming languages. Types can have properties specified through its arguments. Define Actions within Each Type : An action corresponds to a function that will be linked during the interpretation of the file. Actions are similar to function calls but without declarations, imports, or definitions. Note: This section describes the syntax and structures of the Exelent language. However, it is essential to check the functionality support in the Interpreter Capabilities Table for the interpreter you select. We are working on developing a stable and unified interpreter for Exelent. Following these steps, a standard plan in Exelent will have the following structure: def <plan>(<properties>): with <type>(<properties>): <action>() <action>() As an example, this is a hello_world.xlnt file: # hello_world.xlnt def hello_world(): with Sequential(): print(\"Hello World!\") Rules and Specifications Although Exelent look like standard Python programs (and are parsed as such), they must adhere to the following specifications to conform to Exelent: Rule of Non-Definition: Exelent files do not contain \"import\" statements, function definitions, or imperative keywords like loops or conditionals. This is because Exelent is a declarative language designed to look like Python. The interpreter is responsible for linking and resolving all functions used in the file. For example: # The file does not contain any more def complex_task(): with Sequential(): do_task_1(\"arg1\") do_task_2(arg2=\"arg2\") Note: While having files with undefined functions is unusual in other languages, in this time, the interpreter will resolve these functions automaticall, so there is no need to worry. KeywordCase Rule : Python reserved keywords remain unchanged, but all Exelent-specific keywords start with an uppercase letter . For instance, \"Sequential()\" is a reserved type in Exelent, so all function/action names must start with a lowercase letter. Pythonic Syntax : All code must be indented and follow a syntax compatible with Python (version 3.10 or later), including proper tabulation, allowing for easier argument formatting. Types Each with statement in Exelent is associated with a predefined type. The built-in types in Exelent, which must be supported by each interpreter, include: Sequential : Executes the following actions in order. If an action fails, it exits and returns an error. Parallel : Executes the following actions concurrently, initializing and resolving their feedback simultaneously. Conclusion You have now learned the fundamentals of using Exelent to define and execute plans with Pythonic syntax. By mastering the straightforward rules and leveraging predefined types, you are well-equipped to create efficient and flexible plans that seamlessly integrate with Python functions using Exelent. You can take a look to the interpreter tutorials to start using Exelent.","title":"Exelent"},{"location":"Exelent/#introduction","text":"So far, multiple planning languages have been developed to be computable, with PDDL (Planning Domain Definition Language) being widely used for automatic plan computation. JSON descriptions have also been utilized to enable LLMs to define objects or generations. In this context, Exelent (an acronym for 'Execution Language') emerges as a faster and easier declarative language with Pythonic syntax. Designed for describing AI-generated plans and sequences of programmatic steps to reach a solution, Exelent combines simplicity with the familiarity of Python.","title":"Introduction"},{"location":"Exelent/#key-properties-of-exelent","text":"Pythonic Syntax : Exelent uses a Pythonic syntax, making it accessible and familiar to users of Python. This design choice leverages the extensive Python code training datasets of many LLMs, potentially improving results and reducing the need for extensive fine- Efficiency : The minimal use of keywords and dynamic resolution reduces the number of tokens that need to be generated by LLMs, resulting in more efficient and cost-effective requests. Compatibility : Exelent is compatible with all Python functions, including support for multitasking and parallel planning. Additional behaviors are under development to further enhance its capabilities. Ease of Parsing and Extension : Exelent is easy to parse and extend using the built-in ExelentParser or directly with the ast library, which is fully supported. By incorporating these properties, Exelent aims to provide a robust and efficient solution for AI-driven plan generation and execution.","title":"Key Properties of Exelent"},{"location":"Exelent/#syntax","text":"The syntax of Exelent is straightforward. Each file contains a set of plans, which can be built following three Define a Plan Function : All plans are defined as functions. A plan definition can include arguments specifying the properties of the plan. Define Types within Each Plan : A type represents a predefined behavior, similar to using loops (e.g., \"for\" or \"while\") in imperative programming languages. Types can have properties specified through its arguments. Define Actions within Each Type : An action corresponds to a function that will be linked during the interpretation of the file. Actions are similar to function calls but without declarations, imports, or definitions. Note: This section describes the syntax and structures of the Exelent language. However, it is essential to check the functionality support in the Interpreter Capabilities Table for the interpreter you select. We are working on developing a stable and unified interpreter for Exelent. Following these steps, a standard plan in Exelent will have the following structure: def <plan>(<properties>): with <type>(<properties>): <action>() <action>() As an example, this is a hello_world.xlnt file: # hello_world.xlnt def hello_world(): with Sequential(): print(\"Hello World!\")","title":"Syntax"},{"location":"Exelent/#rules-and-specifications","text":"Although Exelent look like standard Python programs (and are parsed as such), they must adhere to the following specifications to conform to Exelent: Rule of Non-Definition: Exelent files do not contain \"import\" statements, function definitions, or imperative keywords like loops or conditionals. This is because Exelent is a declarative language designed to look like Python. The interpreter is responsible for linking and resolving all functions used in the file. For example: # The file does not contain any more def complex_task(): with Sequential(): do_task_1(\"arg1\") do_task_2(arg2=\"arg2\") Note: While having files with undefined functions is unusual in other languages, in this time, the interpreter will resolve these functions automaticall, so there is no need to worry. KeywordCase Rule : Python reserved keywords remain unchanged, but all Exelent-specific keywords start with an uppercase letter . For instance, \"Sequential()\" is a reserved type in Exelent, so all function/action names must start with a lowercase letter. Pythonic Syntax : All code must be indented and follow a syntax compatible with Python (version 3.10 or later), including proper tabulation, allowing for easier argument formatting.","title":"Rules and Specifications"},{"location":"Exelent/#types","text":"Each with statement in Exelent is associated with a predefined type. The built-in types in Exelent, which must be supported by each interpreter, include: Sequential : Executes the following actions in order. If an action fails, it exits and returns an error. Parallel : Executes the following actions concurrently, initializing and resolving their feedback simultaneously.","title":"Types"},{"location":"Exelent/#conclusion","text":"You have now learned the fundamentals of using Exelent to define and execute plans with Pythonic syntax. By mastering the straightforward rules and leveraging predefined types, you are well-equipped to create efficient and flexible plans that seamlessly integrate with Python functions using Exelent. You can take a look to the interpreter tutorials to start using Exelent.","title":"Conclusion"},{"location":"FastAgentProtocol/","text":"FastAgentProtocol Documentation The FastAgentProtocol is designed to provide a simplified, faster alternative to the previous AgentProtocol . It enables efficient communication between cognitive agents and the main system without the overhead of remote connections. Why Use FastAgentProtocol? Speed & Simplicity : It removes the need for remote server connections, significantly reducing latency. Standardization : All agents in the cognition layer must implement this protocol for consistent communication. Flexibility : The main system no longer needs to manage execution, as the agent handles it independently. How It Works The FastAgentProtocol requires defining how an agent processes tasks in steps, where each step returns essential feedback to the main system. Key Components Iterator : A function that processes input iteratively, yielding steps. Content Getter : Retrieves the content of each step. Is Last Getter : Determines if the current step is the final one. Step Name Getter (optional) : Assigns a name to each step. Implementing a Custom Agent with FastAgentProtocol Define an Iterative Process : The agent's main function should yield steps, each containing a name, content, and finalization status. Create the Protocol Server : Use the FastAgentProtocol class. Define getters for step information. Example Custom Agent from cognition_layer.api import FastAgentProtocol from ecm.mediator.Interpreter import Interpreter from operator import attrgetter class MyAgent: def __init__(self, interpreter: Interpreter): self.interpreter = interpreter def complete_task(self, input: str): my_agent.send_user_input(input) for step in steps: next_action = my_agent.next_action() result = interpreter.run(next_action) step = parse_result_contents(result) yield step def get_fast_ap_server(interpreter: Interpreter) -> FastAgentProtocol: agent = MyAgent(interpreter) return FastAgentProtocol( name=\"My Custom Agent\", iterator=agent.complete_task, step_name_getter=attrgetter(\"name\"), # Equivalent to step.name content_getter=attrgetter(\"content\"), # Equivalent to step.content is_last_getter=attrgetter(\"is_last\"), # Equivalent to step.is_last ) Using an implemented serverwith Fast AP To use an agent with FastAgentProtocol in the main program: from cognition_layer.fast_react.api.server import get_fast_ap_server from cognition_layer.tools.registry import ItemRegistry server = get_fast_ap_server(interpreter=interpreter) while True: query = input(\"Task: \") for step in server.send_task(query): print(f\"Step: {step.name} -> {step.content}\") Conclusion FastAgentProtocol provides a unified, efficient approach to agent communication. By following the pattern of defining iterators and feedback structures, agents can seamlessly integrate with the main system while optimizing performance and reducing complexity.","title":"FastAgentProtocol Documentation"},{"location":"FastAgentProtocol/#fastagentprotocol-documentation","text":"The FastAgentProtocol is designed to provide a simplified, faster alternative to the previous AgentProtocol . It enables efficient communication between cognitive agents and the main system without the overhead of remote connections.","title":"FastAgentProtocol Documentation"},{"location":"FastAgentProtocol/#why-use-fastagentprotocol","text":"Speed & Simplicity : It removes the need for remote server connections, significantly reducing latency. Standardization : All agents in the cognition layer must implement this protocol for consistent communication. Flexibility : The main system no longer needs to manage execution, as the agent handles it independently.","title":"Why Use FastAgentProtocol?"},{"location":"FastAgentProtocol/#how-it-works","text":"The FastAgentProtocol requires defining how an agent processes tasks in steps, where each step returns essential feedback to the main system.","title":"How It Works"},{"location":"FastAgentProtocol/#key-components","text":"Iterator : A function that processes input iteratively, yielding steps. Content Getter : Retrieves the content of each step. Is Last Getter : Determines if the current step is the final one. Step Name Getter (optional) : Assigns a name to each step.","title":"Key Components"},{"location":"FastAgentProtocol/#implementing-a-custom-agent-with-fastagentprotocol","text":"Define an Iterative Process : The agent's main function should yield steps, each containing a name, content, and finalization status. Create the Protocol Server : Use the FastAgentProtocol class. Define getters for step information. Example Custom Agent from cognition_layer.api import FastAgentProtocol from ecm.mediator.Interpreter import Interpreter from operator import attrgetter class MyAgent: def __init__(self, interpreter: Interpreter): self.interpreter = interpreter def complete_task(self, input: str): my_agent.send_user_input(input) for step in steps: next_action = my_agent.next_action() result = interpreter.run(next_action) step = parse_result_contents(result) yield step def get_fast_ap_server(interpreter: Interpreter) -> FastAgentProtocol: agent = MyAgent(interpreter) return FastAgentProtocol( name=\"My Custom Agent\", iterator=agent.complete_task, step_name_getter=attrgetter(\"name\"), # Equivalent to step.name content_getter=attrgetter(\"content\"), # Equivalent to step.content is_last_getter=attrgetter(\"is_last\"), # Equivalent to step.is_last )","title":"Implementing a Custom Agent with FastAgentProtocol"},{"location":"FastAgentProtocol/#using-an-implemented-serverwith-fast-ap","text":"To use an agent with FastAgentProtocol in the main program: from cognition_layer.fast_react.api.server import get_fast_ap_server from cognition_layer.tools.registry import ItemRegistry server = get_fast_ap_server(interpreter=interpreter) while True: query = input(\"Task: \") for step in server.send_task(query): print(f\"Step: {step.name} -> {step.content}\")","title":"Using an implemented serverwith Fast AP"},{"location":"FastAgentProtocol/#conclusion","text":"FastAgentProtocol provides a unified, efficient approach to agent communication. By following the pattern of defining iterators and feedback structures, agents can seamlessly integrate with the main system while optimizing performance and reducing complexity.","title":"Conclusion"},{"location":"FastReact/","text":"FastReact is a cognitive agent designed to optimize the reasoning and action process using the ReAct methodology (Reason + Act). Its primary goal is to accelerate task execution by combining reasoning and action in a single iteration, reducing latency while maintaining system efficiency. Motivation and Approach The motivation behind FastReact arises from the limitations of previous models like Xplore, which, while robust, were slow due to the separation between reasoning and action execution. FastReact overcomes this by ensuring that each iteration performs both processes in a single call to the LLM. This is achieved by training the LLM to always respond in a structured JSON format, where it is forced to reason and generate the Python code that represents the action to be executed. FastReact Workflow The workflow of FastReact follows these primary steps: Initialization : Cognitive memory is configured with key instructions, and initial messages are preserved to establish the task's starting state. Capturing the Current State : In each iteration, a screenshot of the system is taken and converted into a message that is added to the history, providing the LLM with a visual understanding of the current context. Generating the Response : The LLM receives the full interaction history and produces a structured JSON. Execution : The Python code is parsed using the Exelent language and executed through the system's interpreter. Memory Update : The LLM's response is saved into the cognitive memory to ensure continuity and progress in future iterations. This process repeats until the LLM indicates that the task has been completed. Cognitive memory plays an essential role, preserving critical instructions and optimizing token usage by removing unnecessary images, thereby reducing computational costs. This mechanism can be obtained by using the following prompt: class JsonFastReactResponse(BaseModel): reasoning: str = Field(description=\"A reasoning for solving the task\") function: str = Field( description=\"The function with pythonic notation. E.g: myfunc(2, 3, 'foo')\" ) all_tasks_completed: bool = Field( description=\"True if and only if all tasks from the user have been completed\" ) FR_PROMPT = f\"\"\" You are a ReAct agent. On each call you must observe the history and then generate the appropriate reasoning + action in json format. The response should use the following json template: {FastReactParser.get_format_instructions()} Ensure the arguments use pythonic notation. The system will call you with the observation from your action. \"\"\" Conclusion FastReact represents an evolution in cognitive agent design respect to other agents such as Xpore or RePlan. By consolidating reasoning and action into a single call and automating execution through Exelent, it offers a fast, efficient, and adaptable solution. Its integration of cognitive memory and visual perception through screenshots makes it a robust and agile agent, capable of handling complex tasks in changing environments.","title":"FastReact"},{"location":"FastReact/#motivation-and-approach","text":"The motivation behind FastReact arises from the limitations of previous models like Xplore, which, while robust, were slow due to the separation between reasoning and action execution. FastReact overcomes this by ensuring that each iteration performs both processes in a single call to the LLM. This is achieved by training the LLM to always respond in a structured JSON format, where it is forced to reason and generate the Python code that represents the action to be executed.","title":"Motivation and Approach"},{"location":"FastReact/#fastreact-workflow","text":"The workflow of FastReact follows these primary steps: Initialization : Cognitive memory is configured with key instructions, and initial messages are preserved to establish the task's starting state. Capturing the Current State : In each iteration, a screenshot of the system is taken and converted into a message that is added to the history, providing the LLM with a visual understanding of the current context. Generating the Response : The LLM receives the full interaction history and produces a structured JSON. Execution : The Python code is parsed using the Exelent language and executed through the system's interpreter. Memory Update : The LLM's response is saved into the cognitive memory to ensure continuity and progress in future iterations. This process repeats until the LLM indicates that the task has been completed. Cognitive memory plays an essential role, preserving critical instructions and optimizing token usage by removing unnecessary images, thereby reducing computational costs. This mechanism can be obtained by using the following prompt: class JsonFastReactResponse(BaseModel): reasoning: str = Field(description=\"A reasoning for solving the task\") function: str = Field( description=\"The function with pythonic notation. E.g: myfunc(2, 3, 'foo')\" ) all_tasks_completed: bool = Field( description=\"True if and only if all tasks from the user have been completed\" ) FR_PROMPT = f\"\"\" You are a ReAct agent. On each call you must observe the history and then generate the appropriate reasoning + action in json format. The response should use the following json template: {FastReactParser.get_format_instructions()} Ensure the arguments use pythonic notation. The system will call you with the observation from your action. \"\"\"","title":"FastReact Workflow"},{"location":"FastReact/#conclusion","text":"FastReact represents an evolution in cognitive agent design respect to other agents such as Xpore or RePlan. By consolidating reasoning and action into a single call and automating execution through Exelent, it offers a fast, efficient, and adaptable solution. Its integration of cognitive memory and visual perception through screenshots makes it a robust and agile agent, capable of handling complex tasks in changing environments.","title":"Conclusion"},{"location":"Home/","text":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f \ud83d\ude80 Introduction Welcome to the main repository for our cutting-edge project on the implementation of ECM (Execution-Cognition Machine) as a strategic approach towards the development of Computer Autonomous AI. This initiative represents a significant leap in crafting an intelligent system that not only mimic but also evolve human-like cognitive functionalities autonomously in computer interaction. \ud83e\udde0 The project revolves around designing, testing, and refining theoretical models that translate complex human problem-solving capabilities into computational strategies executable by AI. We integrate advanced AI frameworks, particularly focusing on AutoGPT as the backbone for adaptive and scalable solutions. Our system architecture is robust, accommodating rapid iterations and rigorous validations through continuous integration and deployment mechanisms. \ud83d\udcda For detailed insights into our methodologies and system functionalities, please refer to the README, the documentation included in this repository or surf through the pages of this Wiki.","title":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f"},{"location":"Home/#gu-systems-ecm-approximation-to-computer-autonomous-ai","text":"","title":"\ud83c\udf1f GU-Systems: ECM approximation to Computer Autonomous AI \ud83c\udf1f"},{"location":"Home/#introduction","text":"Welcome to the main repository for our cutting-edge project on the implementation of ECM (Execution-Cognition Machine) as a strategic approach towards the development of Computer Autonomous AI. This initiative represents a significant leap in crafting an intelligent system that not only mimic but also evolve human-like cognitive functionalities autonomously in computer interaction. \ud83e\udde0 The project revolves around designing, testing, and refining theoretical models that translate complex human problem-solving capabilities into computational strategies executable by AI. We integrate advanced AI frameworks, particularly focusing on AutoGPT as the backbone for adaptive and scalable solutions. Our system architecture is robust, accommodating rapid iterations and rigorous validations through continuous integration and deployment mechanisms. \ud83d\udcda For detailed insights into our methodologies and system functionalities, please refer to the README, the documentation included in this repository or surf through the pages of this Wiki.","title":"\ud83d\ude80 Introduction"},{"location":"Interpreter/","text":"Introduction The Interpreter module provides a framework for executing Exelent files . It acts as an abstract class to unify various execution layer managers. This guide will demonstrate how to use the interpreter with ROSA as an example interpreter, the same applies for later implementations such as Pyxcel. Functionalities Overview All interpreters are located in the ecm/mediator directory. For this example, we will import the RosaInterpreter as follows: from ecm.mediator.rosa_interpreter import RosaInterpreter, RosaInterpreterSupports Each interpreter defines a support class that specifies its capabilities. You can visualize the supported properties with the following command: print(RosaInterpreterSupports()) The core functionality of interpreters is provided by the methods they implement. While interpreters can define additional methods, the predefined ones include: run : Receives a ParsedTask object and executes it from start to finish. It may also accept a callback argument to define a function for receiving execution feedback. arun : Receives a ParsedTask object and executes it asynchronously, accepting a callback argument for feedback. stop : Stops a running task by its name. hard_stop : Forcefully stops a running task by its name (use with caution as it may have undesirable effects). wait_for : Waits for a specific call from the task, such as a status change or task completion. kill : Closes the interpreter (does not ensure it is capable to be used again in the same process) Using the Interpreter To use the RosaInterpreter, first initialize it: from ecm.mediator.rosa_interpreter import RosaInterpreter interpreter = RosaInterpreter() To execute a task, use the run method. You need to parse an Exelent file with the actions to execute. Optionally, you can provide a callback function to handle task feedback. The callback implementation specifics are documented by the selected interpreter. For this example, we will use the hello_world file found in /tests/resources/hello_world.xlnt . # This is the .xlnt file def my_task(): with Sequential(on_fail=DUMP_LOGS): with Sequential(): click(\"windows_icon\") click(\"notepad\") with Sequential(): click(\"window\") write(\"Hello World!\") This file defines two actions: click and write. You need to implement these actions before executing the task: from ecm.tools.registry import ItemRegistry # Note that just by registering the function will make it available for all interpreters. @ItemRegistry.register_function def click(location: str): print(f\"Clicked {location}!\") @ItemRegistry.register_function def write(text: str): print(text) With the Exelent file and the tools set up, you are ready to execute the task: import ecm.exelent.parser as parser from ecm.shared import get_root_path path = get_root_path() / \"tests\" / \"resources\" / \"hello_world.xlnt\" task = parser.parse(path) interpreter.run(task, callback=\"silent\") In this example, we pass the \"silent\" keyword to the callback. Each interpreter may support different keywords or objects. >>> interpreter.run(task, callback=\"silent\") Clicked windows_icon! Clicked notepad! Clicked window! Hello World! After you have finished using the interpreter, some implementations require cleanup. Therefore, it is good practice to terminate the interpreter. interpreter.kill() Conclusion By following this guide, you now have a foundational understanding of how to utilize the Interpreter module to execute tasks parsed by the Exelent Parser. This knowledge will allow you to manage and control task execution within your projects effectively. Remember to clean up by terminating the interpreter when it's no longer needed to maintain system integrity. Happy coding!","title":"Interpreter"},{"location":"Interpreter/#introduction","text":"The Interpreter module provides a framework for executing Exelent files . It acts as an abstract class to unify various execution layer managers. This guide will demonstrate how to use the interpreter with ROSA as an example interpreter, the same applies for later implementations such as Pyxcel.","title":"Introduction"},{"location":"Interpreter/#functionalities-overview","text":"All interpreters are located in the ecm/mediator directory. For this example, we will import the RosaInterpreter as follows: from ecm.mediator.rosa_interpreter import RosaInterpreter, RosaInterpreterSupports Each interpreter defines a support class that specifies its capabilities. You can visualize the supported properties with the following command: print(RosaInterpreterSupports()) The core functionality of interpreters is provided by the methods they implement. While interpreters can define additional methods, the predefined ones include: run : Receives a ParsedTask object and executes it from start to finish. It may also accept a callback argument to define a function for receiving execution feedback. arun : Receives a ParsedTask object and executes it asynchronously, accepting a callback argument for feedback. stop : Stops a running task by its name. hard_stop : Forcefully stops a running task by its name (use with caution as it may have undesirable effects). wait_for : Waits for a specific call from the task, such as a status change or task completion. kill : Closes the interpreter (does not ensure it is capable to be used again in the same process)","title":"Functionalities Overview"},{"location":"Interpreter/#using-the-interpreter","text":"To use the RosaInterpreter, first initialize it: from ecm.mediator.rosa_interpreter import RosaInterpreter interpreter = RosaInterpreter() To execute a task, use the run method. You need to parse an Exelent file with the actions to execute. Optionally, you can provide a callback function to handle task feedback. The callback implementation specifics are documented by the selected interpreter. For this example, we will use the hello_world file found in /tests/resources/hello_world.xlnt . # This is the .xlnt file def my_task(): with Sequential(on_fail=DUMP_LOGS): with Sequential(): click(\"windows_icon\") click(\"notepad\") with Sequential(): click(\"window\") write(\"Hello World!\") This file defines two actions: click and write. You need to implement these actions before executing the task: from ecm.tools.registry import ItemRegistry # Note that just by registering the function will make it available for all interpreters. @ItemRegistry.register_function def click(location: str): print(f\"Clicked {location}!\") @ItemRegistry.register_function def write(text: str): print(text) With the Exelent file and the tools set up, you are ready to execute the task: import ecm.exelent.parser as parser from ecm.shared import get_root_path path = get_root_path() / \"tests\" / \"resources\" / \"hello_world.xlnt\" task = parser.parse(path) interpreter.run(task, callback=\"silent\") In this example, we pass the \"silent\" keyword to the callback. Each interpreter may support different keywords or objects. >>> interpreter.run(task, callback=\"silent\") Clicked windows_icon! Clicked notepad! Clicked window! Hello World! After you have finished using the interpreter, some implementations require cleanup. Therefore, it is good practice to terminate the interpreter. interpreter.kill()","title":"Using the Interpreter"},{"location":"Interpreter/#conclusion","text":"By following this guide, you now have a foundational understanding of how to utilize the Interpreter module to execute tasks parsed by the Exelent Parser. This knowledge will allow you to manage and control task execution within your projects effectively. Remember to clean up by terminating the interpreter when it's no longer needed to maintain system integrity. Happy coding!","title":"Conclusion"},{"location":"ItemRegistry/","text":"Introduction The ItemRegistry is a class designed similar to a database. Its main purpose is to store what we call Actions, Tools and Items in order to enable modules such as the Exelent Parser or the Interpreters to retrieve complex objects by just using its name (an string). In the following sections, you will learn how to use, interact and register your own items inside the ItemRegistry and some deprecations that you can still found in some directories. Initializing The ItemRegistry acts as a database, thus it is able to be shared between different layers and threads even when you don't have access to the same instance. For obtaining this, you can use 2 different types of instantiation: If you call the ItemRegistry without arguments, you will receive the default ItemRegistry , all the threads will share the same default instance. from ecm.tools.item_registry_v2 import ItemRegistry obj_1 = object() obj_2 = object() registry_1 = ItemRegistry() registry_2 = ItemRegistry() print(obj_1 is obj_2) # -> False print(registry_1 is registry_2) # -> True If you want to force the registry to maintain a separated database, you can add a name to you registry , this will return an empty registry that can be called from other threads only if they use the same name: from ecm.tools.item_registry_v2 import ItemRegistry default_registry = ItemRegistry() my_registry = ItemRegistry(name=\"different\") my_registry_2 = ItemRegistry(name=\"different\") print(default_registry is my_registry) # -> False print(my_registry is my_registry_2) # -> True For obtaining information about the current instances and its content you can use 2 funcions: ItemRegistry.summary() # We add some items... ==================== Item Registry ==================== [default] * (ACTION): Action(name='click', active=True, content=<function click at 0x7607e0f7fa30>, is_callable=True, description=\"Clicks with the mouse on the specified element. Example: click('Firefox Icon') or click('Navigation Bar'). Ensure to provide an especific description if needed.\", labels=[]) * (TOOL): Tool(name='screenshot', active=True, content=<function screenshot at 0x7607e79c8af0>, is_callable=True, description='', labels=[]) [different] * (TOOL): Tool(name='move_mouse_to', active=True, content=<function move_mouse_to at 0x760800cee0e0>, is_callable=True, description='', labels=[]) * (TOOL): Tool(name='send_click_event', active=True, content=<function send_click_event at 0x7607e0f7f9a0>, is_callable=True, description='', labels=[]) Adding Actions and Tools When working with agents we will want the AI to retrieve the function use_my_mouse() with only requesting to the agent a string that says: \"use_my_mouse\" . For this, since only some functions are targeted to be used by an AI, you must register your functions in the ItemRegistry. Here it is important to differerentiate between two types of functions: - Actions : These are those functions targeted to the AI, they should contain a docstring, be fully typed and clear and be simple to use. This means, you should at most receive one or two arguments (if any) and the use should be self-explanatory. Use arguments as int or str for best practices. A good action could be the following: @ItemRegistry.register(type=\"action\") def close_app(name_of_the_app: str) -> None: \"\"\"Closes an app by its name. The app should be active to be closed. Usage: close(\"firefox\").\"\"\" app = my_app_retriever.retrieve(name_of_the_app) app.close() ... Tools : These are functions that are stored in the ItemRegistry are not targeted to the AI but the developer. This can be defined as any other function. @ItemRegistry.register(type=\"tool\") def close_app(app_name: str, app_registry: AppRegistry, check_for_errors: bool = True) -> None: \"\"\" Generates a summary of all the current apps \"\"\" ... As you can see, all the actions and tools are registered by just using the @ItemRegistry().register decorator. Note that this decorator will be executed as the same time as the file is imported, for this reason, you will see multiple imports of actions when the developer wants the actions to be available. These functions should be saved in the /action_space directory, usually in a file called as actions.py . # We use the `noqa` label to avoid intellisense or formatters to flag this import as an error import action_space.experimental.screenshot.actions # noqa Loading Actions Following the Principle of Least Atonishment in python the imports that are used to save the actions/tools, are not fully loaded into the registry, so imports don't alter the functioning of your program. After you have selected which actions you have imported, they must be loaded in the ItemRegistry instance you want to work with. For example, you can use the load_all() method to enable all tools and actions retrieved in the imports into a selected instance: from ecm.tools.item_registry_v2 import ItemRegistry import action_space.my_lib.actions # noqa # No action avaliable ItemRegistry.summary() # Note that we are calling the default instance ItemRegistry().load_all() # All actions are available ItemRegistry.summary() If you want to load only a specific action, you can use the load() method: ItemRegistry().load(\"screenshot\") Sometimes you will want to add multiple actions that are related, for example, all the keyboard utils. For this, the version V2 of the ItemRegistry enables the actions to be grouped inside a package. Then you can easily load them all at the same time. from ecm.tools.item_registry_v2 import ItemRegistry @ItemRegistry.register(package=\"keyboard\") def press_A(): \"\"\"I press the Key A\"\"\" ... @ItemRegistry.register(package=\"keyboard\") def press_B(): \"\"\"I press the Key A\"\"\" ... ItemRegistry().load_package(\"keyboard\") Note: Some functions in this repository are still using the version V1 of the ItemRegistry to maintain backward-compatibility and thus, cannot be encapsulated into a package. Extracting Actions and Tools Now that you know how to integrate actions and tools, you can exit here if you only are going to use these registry for building new actions or tools to AI's (all the agents extract their capacities from this registry). However, if you are building your own agent, you will need to know how to manage the actions and tools saved in the ItemRegistry. All the functions that are labeled as actions, will be saved in the following dataclass: @dataclass class Action(Item): name: str content: Callable description: str is_callable: bool = True As you can see, the name of the function, callable itself and a description are mandatory, and will be automatically retrieved when using ItemRegistry.register from the name of the function and docstring. In the other hand, the Tools have the following dataclass: class Tool(Item): name: str content: Callable is_callable: bool = True Similar to the actions the contain a callable, but they not enforce a docstring. Note that if you want to add some metadata to the tools or actions you can use the .label property inherited from the Item class. For example, if you want to mark the tool as dangerous you could add: # .label is a list[str] item = Item(\"fire\", do_fire) item.label.append(\"danger\") All the information about this classes can be found at the item_registry_v2.py file. Now if you want to extract the actions or tools that have been loaded into a registry (for example using load_all() ) you can access the .tools or .actions dictionaries, that will return the items by giving their name: registry = ItemRegistry() all_actions_loaded = registry.actions.values() # -> list[Action] all_tools_loaded = registry.tools.values() # -> list[Tool] screenshot = registry.actions[\"screenshot\"] screenshot() press_A = registry.actions[\"keyboard.press_A\"] press_A Note: The actions saved inside a package will be accessible by using their package name followed with a dot. This enables to have multiple actions with the same name, however, is generally not a good idea to use them at the same time, since the AI could missunderstand the difference between each one Some Addons When developing using the ItemRegistry, we enable to use some tools that will ease the debug of the actions: Invalidation : By invalidating a registry, all the actions and tools saved will be replaced with a mock that won't execute the function itself but a logging method that will act as the function. For example you could use this to simulate the AI could call a function that shut downs the pc: registry = ItemRegistry() registry.invalidate() mock = registry.actions[\"shutdown\"] mock(\"now\", force=True) # Output -> mock([now], {force: True}) Remote Execution : The ItemRegistry can be configured to be used on a remote machine, obtain more infomation at the RemoteExecution Guide Alias : You can add multiple names to the same function, this is useful for AI when it hallucinates different names for an specific function. Inside the ItemRegistry, they will be saved as different functions: @ItemRegistry.alias([ \"type\", \"write_text\", ]) @ItemRegistry.register(type=\"action\") def write(text: str): \"\"\"Explanation...\"\"\" ... Note: Alias only works for action not tools. This could enlarge the size of your prompt (thera are more actions to be explained), add at most 1 or 2 aliases. Conclusion With this you have fully learned how to use the ItemRegistry, this class is used in multiple layers over the system such as interpreters, exelent parsers, agents... You can try to add your own actions and register them to the default ItemRegistry, they should be automatically used in the agents integrated in this repo. Note: The deprecated version ItemRegistryV1 can be still found at /ecm/tools/item_registry_v1.py . The file /ecm/tools/registry.py will automatilcally redirect to the v2 registry. This class has been intended to be backward-compatible but the previus versions will not be continuated. If you want to disable the enforcing of the version v2, you can change the flag PATCH_ITEM_REGISTRY_V1 at the constats.py file.","title":"Introduction"},{"location":"ItemRegistry/#introduction","text":"The ItemRegistry is a class designed similar to a database. Its main purpose is to store what we call Actions, Tools and Items in order to enable modules such as the Exelent Parser or the Interpreters to retrieve complex objects by just using its name (an string). In the following sections, you will learn how to use, interact and register your own items inside the ItemRegistry and some deprecations that you can still found in some directories.","title":"Introduction"},{"location":"ItemRegistry/#initializing","text":"The ItemRegistry acts as a database, thus it is able to be shared between different layers and threads even when you don't have access to the same instance. For obtaining this, you can use 2 different types of instantiation: If you call the ItemRegistry without arguments, you will receive the default ItemRegistry , all the threads will share the same default instance. from ecm.tools.item_registry_v2 import ItemRegistry obj_1 = object() obj_2 = object() registry_1 = ItemRegistry() registry_2 = ItemRegistry() print(obj_1 is obj_2) # -> False print(registry_1 is registry_2) # -> True If you want to force the registry to maintain a separated database, you can add a name to you registry , this will return an empty registry that can be called from other threads only if they use the same name: from ecm.tools.item_registry_v2 import ItemRegistry default_registry = ItemRegistry() my_registry = ItemRegistry(name=\"different\") my_registry_2 = ItemRegistry(name=\"different\") print(default_registry is my_registry) # -> False print(my_registry is my_registry_2) # -> True For obtaining information about the current instances and its content you can use 2 funcions: ItemRegistry.summary() # We add some items... ==================== Item Registry ==================== [default] * (ACTION): Action(name='click', active=True, content=<function click at 0x7607e0f7fa30>, is_callable=True, description=\"Clicks with the mouse on the specified element. Example: click('Firefox Icon') or click('Navigation Bar'). Ensure to provide an especific description if needed.\", labels=[]) * (TOOL): Tool(name='screenshot', active=True, content=<function screenshot at 0x7607e79c8af0>, is_callable=True, description='', labels=[]) [different] * (TOOL): Tool(name='move_mouse_to', active=True, content=<function move_mouse_to at 0x760800cee0e0>, is_callable=True, description='', labels=[]) * (TOOL): Tool(name='send_click_event', active=True, content=<function send_click_event at 0x7607e0f7f9a0>, is_callable=True, description='', labels=[])","title":"Initializing"},{"location":"ItemRegistry/#adding-actions-and-tools","text":"When working with agents we will want the AI to retrieve the function use_my_mouse() with only requesting to the agent a string that says: \"use_my_mouse\" . For this, since only some functions are targeted to be used by an AI, you must register your functions in the ItemRegistry. Here it is important to differerentiate between two types of functions: - Actions : These are those functions targeted to the AI, they should contain a docstring, be fully typed and clear and be simple to use. This means, you should at most receive one or two arguments (if any) and the use should be self-explanatory. Use arguments as int or str for best practices. A good action could be the following: @ItemRegistry.register(type=\"action\") def close_app(name_of_the_app: str) -> None: \"\"\"Closes an app by its name. The app should be active to be closed. Usage: close(\"firefox\").\"\"\" app = my_app_retriever.retrieve(name_of_the_app) app.close() ... Tools : These are functions that are stored in the ItemRegistry are not targeted to the AI but the developer. This can be defined as any other function. @ItemRegistry.register(type=\"tool\") def close_app(app_name: str, app_registry: AppRegistry, check_for_errors: bool = True) -> None: \"\"\" Generates a summary of all the current apps \"\"\" ... As you can see, all the actions and tools are registered by just using the @ItemRegistry().register decorator. Note that this decorator will be executed as the same time as the file is imported, for this reason, you will see multiple imports of actions when the developer wants the actions to be available. These functions should be saved in the /action_space directory, usually in a file called as actions.py . # We use the `noqa` label to avoid intellisense or formatters to flag this import as an error import action_space.experimental.screenshot.actions # noqa","title":"Adding Actions and Tools"},{"location":"ItemRegistry/#loading-actions","text":"Following the Principle of Least Atonishment in python the imports that are used to save the actions/tools, are not fully loaded into the registry, so imports don't alter the functioning of your program. After you have selected which actions you have imported, they must be loaded in the ItemRegistry instance you want to work with. For example, you can use the load_all() method to enable all tools and actions retrieved in the imports into a selected instance: from ecm.tools.item_registry_v2 import ItemRegistry import action_space.my_lib.actions # noqa # No action avaliable ItemRegistry.summary() # Note that we are calling the default instance ItemRegistry().load_all() # All actions are available ItemRegistry.summary() If you want to load only a specific action, you can use the load() method: ItemRegistry().load(\"screenshot\") Sometimes you will want to add multiple actions that are related, for example, all the keyboard utils. For this, the version V2 of the ItemRegistry enables the actions to be grouped inside a package. Then you can easily load them all at the same time. from ecm.tools.item_registry_v2 import ItemRegistry @ItemRegistry.register(package=\"keyboard\") def press_A(): \"\"\"I press the Key A\"\"\" ... @ItemRegistry.register(package=\"keyboard\") def press_B(): \"\"\"I press the Key A\"\"\" ... ItemRegistry().load_package(\"keyboard\") Note: Some functions in this repository are still using the version V1 of the ItemRegistry to maintain backward-compatibility and thus, cannot be encapsulated into a package.","title":"Loading Actions"},{"location":"ItemRegistry/#extracting-actions-and-tools","text":"Now that you know how to integrate actions and tools, you can exit here if you only are going to use these registry for building new actions or tools to AI's (all the agents extract their capacities from this registry). However, if you are building your own agent, you will need to know how to manage the actions and tools saved in the ItemRegistry. All the functions that are labeled as actions, will be saved in the following dataclass: @dataclass class Action(Item): name: str content: Callable description: str is_callable: bool = True As you can see, the name of the function, callable itself and a description are mandatory, and will be automatically retrieved when using ItemRegistry.register from the name of the function and docstring. In the other hand, the Tools have the following dataclass: class Tool(Item): name: str content: Callable is_callable: bool = True Similar to the actions the contain a callable, but they not enforce a docstring. Note that if you want to add some metadata to the tools or actions you can use the .label property inherited from the Item class. For example, if you want to mark the tool as dangerous you could add: # .label is a list[str] item = Item(\"fire\", do_fire) item.label.append(\"danger\") All the information about this classes can be found at the item_registry_v2.py file. Now if you want to extract the actions or tools that have been loaded into a registry (for example using load_all() ) you can access the .tools or .actions dictionaries, that will return the items by giving their name: registry = ItemRegistry() all_actions_loaded = registry.actions.values() # -> list[Action] all_tools_loaded = registry.tools.values() # -> list[Tool] screenshot = registry.actions[\"screenshot\"] screenshot() press_A = registry.actions[\"keyboard.press_A\"] press_A Note: The actions saved inside a package will be accessible by using their package name followed with a dot. This enables to have multiple actions with the same name, however, is generally not a good idea to use them at the same time, since the AI could missunderstand the difference between each one","title":"Extracting Actions and Tools"},{"location":"ItemRegistry/#some-addons","text":"When developing using the ItemRegistry, we enable to use some tools that will ease the debug of the actions: Invalidation : By invalidating a registry, all the actions and tools saved will be replaced with a mock that won't execute the function itself but a logging method that will act as the function. For example you could use this to simulate the AI could call a function that shut downs the pc: registry = ItemRegistry() registry.invalidate() mock = registry.actions[\"shutdown\"] mock(\"now\", force=True) # Output -> mock([now], {force: True}) Remote Execution : The ItemRegistry can be configured to be used on a remote machine, obtain more infomation at the RemoteExecution Guide Alias : You can add multiple names to the same function, this is useful for AI when it hallucinates different names for an specific function. Inside the ItemRegistry, they will be saved as different functions: @ItemRegistry.alias([ \"type\", \"write_text\", ]) @ItemRegistry.register(type=\"action\") def write(text: str): \"\"\"Explanation...\"\"\" ... Note: Alias only works for action not tools. This could enlarge the size of your prompt (thera are more actions to be explained), add at most 1 or 2 aliases.","title":"Some Addons"},{"location":"ItemRegistry/#conclusion","text":"With this you have fully learned how to use the ItemRegistry, this class is used in multiple layers over the system such as interpreters, exelent parsers, agents... You can try to add your own actions and register them to the default ItemRegistry, they should be automatically used in the agents integrated in this repo. Note: The deprecated version ItemRegistryV1 can be still found at /ecm/tools/item_registry_v1.py . The file /ecm/tools/registry.py will automatilcally redirect to the v2 registry. This class has been intended to be backward-compatible but the previus versions will not be continuated. If you want to disable the enforcing of the version v2, you can change the flag PATCH_ITEM_REGISTRY_V1 at the constats.py file.","title":"Conclusion"},{"location":"LLMs-and-State-of-Art/","text":"Introduction to Large Language Models (LLMs) Large Language Models (LLMs) such as OpenAI's GPT series (GPT-3.5, GPT-4, and others) represent the pinnacle of current natural language processing technologies. These models have been pivotal in demonstrating capabilities close to human-level text understanding and generation, offering significant advantages in terms of scalability, cost-effectiveness, and ease of integration. The choice of GPT-X as our primary model is driven by its cost efficiency, which offers a low cost per token, and its stability\u2014being a product of a well-established company, it ensures reliability for long-term projects. Additionally, OpenAI provides robust APIs that facilitate straightforward web-based queries, an essential feature for seamless integration into diverse applications. In line with exploring other robust models to enhance our system's capabilities, we are also considering incorporating models like Microsoft's Bing, Meta's Llama, and the emerging Gemini model. Each of these models brings unique strengths: OpenAI GPT-X : Known for robust performance and versatility in various NLP tasks, making it ideal for core system operations. Bing : Utilizes Microsoft's extensive experience in AI and search technologies to provide enriched conversational capabilities. Llama : An OpenSource alternative, offers adaptability across different conversational contexts, ideal for applications requiring versatile linguistic styles. Gemini : Focuses on multitasking and handling multiple domains, which is crucial for systems requiring broad knowledge bases. Going further, the evolution from traditional LLMs to systems capable of AGI (Artificial Generalist Agents) involves creating models that can understand, learn, and perform any intellectual task comparable to human capabilities. AGI aims to transcend the limitations of typical NLP tasks by providing solutions that can apply learned knowledge across various disciplines. This shift is crucial for developing systems like GU-Systems, which require a level of cognitive flexibility and adaptability that goes beyond simple task execution. Autonomous AI takes this a step further by developing systems that operate independently of human oversight, which is essential for applications involving real-time decision making or when human input may introduce delays or biases. The ability to make autonomous decisions is critical for the areas of our project that involve real-time data interpretation and response generation without human intervention. AI State-Of-Art Diagram Integrating Cognitive Agents within GU-Systems To translate the sophisticated data processing capabilities of LLMs into actionable strategies in real-world applications, it is necessary to embed these models within Cognitive Agents . These agents utilize mechanisms that convert generated text and insights into direct actions, enabling effective operation in various environments. An excellent resource for current technologies and frameworks that facilitate the implementation of these agents is the awesome-AGI repository on GitHub, which showcases some of the most popular and cutting-edge repositories today. Framework Evaluation for Optimal Integration Our exploration of available frameworks through resources like the awesome-AGI repository revealed several potential candidates, including MetaGPT, AgentGPT, and AutoGPT: MetaGPT : Targets professional and enterprise environments, facilitating rapid and secure AI integration within technological workspaces. However, its focus on enterprise solutions does not align with our project's need for broader applicability and flexibility. AgentGPT : Provides a user-friendly GUI and supports a collaborative AI-human working model. It is designed for semi-supervised operations, which do not meet the autonomy requirements of our project. Ultimately, AutoGPT emerged as the optimal choice. It is selected for its active community support, stability, ease of integration, and its architecture that supports feedback-driven AI capable of utilizing skills/actions in a cognitive loop\u2014perfectly matching the requirements for GU-Systems. AutoGPT facilitates the integration of agents based on the Profile-Memory-Planning-Action model , which is extensively used across multiple disciplines for robust agent implementation. It includes features like: Forge System : Simplifies the deployment of new models, providing a platform where users can collaboratively develop and standardize AI technologies, which aligns with our vision of creating a flexible and adaptive system. Agent Protocol : This protocol standardizes interactions with AI agents via a REST API, streamlining the management of multiple agents and ensuring that GU-Systems can function efficiently as an Execution-Cognition Machine (ECM) that leverages these standards. Learn more about Agent Protocol AutoGPT/AgentProtocol BlackBox Diagram Conclusions Understanding these state-of-the-art technologies and selecting the right frameworks like AutoGPT are crucial steps toward realizing the ambitious goals of GU-Systems. By integrating advanced AGI and autonomous AI capabilities, GU-Systems is set to redefine the landscape of interactive, cognitive AI applications, ensuring that our project remains at the cutting edge of technology innovation.","title":"LLMs and State of Art"},{"location":"LLMs-and-State-of-Art/#introduction-to-large-language-models-llms","text":"Large Language Models (LLMs) such as OpenAI's GPT series (GPT-3.5, GPT-4, and others) represent the pinnacle of current natural language processing technologies. These models have been pivotal in demonstrating capabilities close to human-level text understanding and generation, offering significant advantages in terms of scalability, cost-effectiveness, and ease of integration. The choice of GPT-X as our primary model is driven by its cost efficiency, which offers a low cost per token, and its stability\u2014being a product of a well-established company, it ensures reliability for long-term projects. Additionally, OpenAI provides robust APIs that facilitate straightforward web-based queries, an essential feature for seamless integration into diverse applications. In line with exploring other robust models to enhance our system's capabilities, we are also considering incorporating models like Microsoft's Bing, Meta's Llama, and the emerging Gemini model. Each of these models brings unique strengths: OpenAI GPT-X : Known for robust performance and versatility in various NLP tasks, making it ideal for core system operations. Bing : Utilizes Microsoft's extensive experience in AI and search technologies to provide enriched conversational capabilities. Llama : An OpenSource alternative, offers adaptability across different conversational contexts, ideal for applications requiring versatile linguistic styles. Gemini : Focuses on multitasking and handling multiple domains, which is crucial for systems requiring broad knowledge bases. Going further, the evolution from traditional LLMs to systems capable of AGI (Artificial Generalist Agents) involves creating models that can understand, learn, and perform any intellectual task comparable to human capabilities. AGI aims to transcend the limitations of typical NLP tasks by providing solutions that can apply learned knowledge across various disciplines. This shift is crucial for developing systems like GU-Systems, which require a level of cognitive flexibility and adaptability that goes beyond simple task execution. Autonomous AI takes this a step further by developing systems that operate independently of human oversight, which is essential for applications involving real-time decision making or when human input may introduce delays or biases. The ability to make autonomous decisions is critical for the areas of our project that involve real-time data interpretation and response generation without human intervention. AI State-Of-Art Diagram","title":"Introduction to Large Language Models (LLMs)"},{"location":"LLMs-and-State-of-Art/#integrating-cognitive-agents-within-gu-systems","text":"To translate the sophisticated data processing capabilities of LLMs into actionable strategies in real-world applications, it is necessary to embed these models within Cognitive Agents . These agents utilize mechanisms that convert generated text and insights into direct actions, enabling effective operation in various environments. An excellent resource for current technologies and frameworks that facilitate the implementation of these agents is the awesome-AGI repository on GitHub, which showcases some of the most popular and cutting-edge repositories today.","title":"Integrating Cognitive Agents within GU-Systems"},{"location":"LLMs-and-State-of-Art/#framework-evaluation-for-optimal-integration","text":"Our exploration of available frameworks through resources like the awesome-AGI repository revealed several potential candidates, including MetaGPT, AgentGPT, and AutoGPT: MetaGPT : Targets professional and enterprise environments, facilitating rapid and secure AI integration within technological workspaces. However, its focus on enterprise solutions does not align with our project's need for broader applicability and flexibility. AgentGPT : Provides a user-friendly GUI and supports a collaborative AI-human working model. It is designed for semi-supervised operations, which do not meet the autonomy requirements of our project. Ultimately, AutoGPT emerged as the optimal choice. It is selected for its active community support, stability, ease of integration, and its architecture that supports feedback-driven AI capable of utilizing skills/actions in a cognitive loop\u2014perfectly matching the requirements for GU-Systems. AutoGPT facilitates the integration of agents based on the Profile-Memory-Planning-Action model , which is extensively used across multiple disciplines for robust agent implementation. It includes features like: Forge System : Simplifies the deployment of new models, providing a platform where users can collaboratively develop and standardize AI technologies, which aligns with our vision of creating a flexible and adaptive system. Agent Protocol : This protocol standardizes interactions with AI agents via a REST API, streamlining the management of multiple agents and ensuring that GU-Systems can function efficiently as an Execution-Cognition Machine (ECM) that leverages these standards. Learn more about Agent Protocol AutoGPT/AgentProtocol BlackBox Diagram","title":"Framework Evaluation for Optimal Integration"},{"location":"LLMs-and-State-of-Art/#conclusions","text":"Understanding these state-of-the-art technologies and selecting the right frameworks like AutoGPT are crucial steps toward realizing the ambitious goals of GU-Systems. By integrating advanced AGI and autonomous AI capabilities, GU-Systems is set to redefine the landscape of interactive, cognitive AI applications, ensuring that our project remains at the cutting edge of technology innovation.","title":"Conclusions"},{"location":"MouseAgent-Insights/","text":"Introduction The MouseAgent is a vision-based agent that uses LLM's capabilities to describe images in order to generate mouse intelligent movements and interactions . Thus, the main goal of this agent is to locate, move the mouse and interact with different elements in the user display. For obtaining this, multiple machine-learning based models can be approached, however using LLM's vision capabilities we empower graphical reasoning where the agent not only generates an action, but also thinks about the arrangement of the apps, buttons and elements in the display, obtaining a better adaptability to multiple scenarios than fine-tunning or using specialized models. Design Insights MouseAgent uses an algorithm inspired on Mac Voice Control , where the user tells numbers to select where the mouse should move. We replicate this behavior by following these steps: Take a screenshot : This will be the first input to the LLM, where the agent must describe and analyse the general arrangement of the elements and reason about how to locate a specified element. A screenshot taken from an example environment. Draw a Grid : Split the screenshot into mutliple cells, each one with its correspondent number so the agent can describe a sector of the screen with just the generation of a label. Each sector of the screen is labeled into a cell. Select Cell : The grid image is passed to the agent, which will reason about the possible cells containing the target element and will generate a number to zoom in. Zoom : Resize the selected cell and repeat the steps 3 and 4 until obtaining the desired accuracy. An example of zoomed cell. Here the agent could find the button \"Code\" 5 Inverse Resolution : Use inverse coordinate calculation in order to determine the pixel or coordinates of the center of the display's selected sector and use those coordinates in order to move the mouse to that location. Implementation All the grid drawing and computation has been designed into the Grid class at this file . It encapsulates the logic of zooming and selecting cells as shows: # Loading Screenshot image_path = \"screenshot.png\" image = Image.open(image_path) grid = Grid.from_image(image, size=10) # grid.image contains the grid drawing plt.imshow(grid.image) plt.show() # You can make zoom into the cells selection = int(input(\"Cell: \")) sub_grid = grid.zoom(selection, size=5) plt.imshow(sub_grid.image) plt.show() # You can also access the cells by using the grid attribute print(grid.cells[9]) The class MouseDescriptor uses the Grid class to move the mouse. MouseAgent generates a graph that executes the algorithm explained in the previous section. ```python The MouseAgent can be called with just one command MouseAgent.find(\"Amazon Icon at Firefox\") `` Note: higher iterations in the MouseAgent enables more accuracy, however, using more than 2 iterations has been shown to be ineffective for user displays.","title":"Introduction"},{"location":"MouseAgent-Insights/#introduction","text":"The MouseAgent is a vision-based agent that uses LLM's capabilities to describe images in order to generate mouse intelligent movements and interactions . Thus, the main goal of this agent is to locate, move the mouse and interact with different elements in the user display. For obtaining this, multiple machine-learning based models can be approached, however using LLM's vision capabilities we empower graphical reasoning where the agent not only generates an action, but also thinks about the arrangement of the apps, buttons and elements in the display, obtaining a better adaptability to multiple scenarios than fine-tunning or using specialized models.","title":"Introduction"},{"location":"MouseAgent-Insights/#design-insights","text":"MouseAgent uses an algorithm inspired on Mac Voice Control , where the user tells numbers to select where the mouse should move. We replicate this behavior by following these steps: Take a screenshot : This will be the first input to the LLM, where the agent must describe and analyse the general arrangement of the elements and reason about how to locate a specified element. A screenshot taken from an example environment. Draw a Grid : Split the screenshot into mutliple cells, each one with its correspondent number so the agent can describe a sector of the screen with just the generation of a label. Each sector of the screen is labeled into a cell. Select Cell : The grid image is passed to the agent, which will reason about the possible cells containing the target element and will generate a number to zoom in. Zoom : Resize the selected cell and repeat the steps 3 and 4 until obtaining the desired accuracy. An example of zoomed cell. Here the agent could find the button \"Code\" 5 Inverse Resolution : Use inverse coordinate calculation in order to determine the pixel or coordinates of the center of the display's selected sector and use those coordinates in order to move the mouse to that location.","title":"Design Insights"},{"location":"MouseAgent-Insights/#implementation","text":"All the grid drawing and computation has been designed into the Grid class at this file . It encapsulates the logic of zooming and selecting cells as shows: # Loading Screenshot image_path = \"screenshot.png\" image = Image.open(image_path) grid = Grid.from_image(image, size=10) # grid.image contains the grid drawing plt.imshow(grid.image) plt.show() # You can make zoom into the cells selection = int(input(\"Cell: \")) sub_grid = grid.zoom(selection, size=5) plt.imshow(sub_grid.image) plt.show() # You can also access the cells by using the grid attribute print(grid.cells[9]) The class MouseDescriptor uses the Grid class to move the mouse. MouseAgent generates a graph that executes the algorithm explained in the previous section. ```python","title":"Implementation"},{"location":"MouseAgent-Insights/#the-mouseagent-can-be-called-with-just-one-command","text":"MouseAgent.find(\"Amazon Icon at Firefox\") `` Note: higher iterations in the MouseAgent enables more accuracy, however, using more than 2 iterations has been shown to be ineffective for user displays.","title":"The MouseAgent can be called with just one command"},{"location":"Planex-Insights/","text":"Introduction Implementation of the Cognition Layer Algorithm ($A_1$) with Planex The Cognition Layer Algorithm, sometimes referred to as $A_1$, defines the intelligent or cognitive layer of the ECM. A detailed problem analysis can be found in the ECM Problem Analysis , where we divided the ECM cognition problem into three subproblems: Planify, Reduce, and Translate. Design Planex has been designed as a three-agent model . By leveraging LangChain, we can utilize the capabilities of large language models (LLMs) such as GPT-3.5. In this context, we assume the knowledge base $C'$ aligns with the properties established in the analysis. This framework allows us to effectively define and chain these three agents, with their behavior primarily specified through two methods: Fine-Tuning : By fine-tuning the models, we can achieve the desired behavior from each agent more accurately. However, this methodology requires an unbiased dataset and extensive analysis/training. Prompt Engineering (Selected Approach) : Using prompt engineering, we can quickly deploy the agents with an approximation of the fine-tuned behavior. Zero-shot prompts enable experimentation, modification, and testing of agent results. We selected the prompt engineering method because it allows for the rapid exploration of multiple agents and new approaches, in alignment with the easily replaceable modules of the ECM. Prompt Engineering All the prompts designed can be found in the /cognition_layer/planex/agents/prompts.py file of the repository. In that file, each agent has three defined prompts: Instructions : Here we declare the expected behavior of the agent. As defined in Lei Wang et al. paper , we define the Profile of the agent. The main properties of each agent are: Planner : The planner's objective is \"to provide a detailed step-by-step plan to address the user's query.\" Reducer : The reducer's objective is \"to review a given plan and provide a new plan that achieves the same result using predefined functions.\" Translator : The translator's objective is \"to translate the plan into Exelent language.\" Guidelines : Using a trial-and-error methodology, we define a set of rules that improve the agent's behavior by explaining and warning about possible failures and misconceptions about the goal. For example, \"Ensure the new plan uses only the Exelent language constructs and achieves the same result as the original plan.\" Example : By using one-shot prompting, we can improve the reliability and standardize the response of the model, specifying for each agent a possible result and its format. For some agents we also provide some information about the system, such as which tools are available, which is the focused window, operative system, etc. For this step we could take advantage of langchain tool formatting for defining the valid tools the ECM can receive. Results Using this simple but efficient model, we achieve the following advantages: Simple Task Solving : For tasks that require three or four consecutive steps, Planex can appropriately define and execute the correct actions. Examples include: \"Open Spotify\" and \"Write 'hello world' on the terminal.\" Fast and Controlled Results : The results are consistently defined after three steps, establishing a concrete number of steps to execute. The main disadvantages found while testing this agent are the following: Large Prompt : As this model uses a one-shot prompting methodology, it requires an extensive prompt each time it is executed, making the request more expensive and necessitating re-learning how to solve the query each time it is called. Fine-tuning could address this issue, but further research is needed. No Failure Reaction : If the reducer or translator fails to properly select the correct tools, the agent cannot recover and must be fully reloaded. Not Fully System Aware : Although we have introduced information about the system, the agent cannot fully understand and develop a mental simulation of the system's status. This limitation leads to failures where the agent assumes previously opened apps, defined requirements, etc. All this properties can be tested in this repository by using the following command: python ecm/core/main.py --agent planex If you are in a safe environment you can also use the python executable in /ecm/core/run_in_host.py PlanexV2 PlanexV2, located in the directory /cognition_layer/planexv2 , is a four-agent model for $A_1$ that improves upon the original Planex agent by introducing the Blamer , an agent capable of reacting to exceptions and recalling the failed agent. The Blamer follows the same schema as other agents, with three key properties: Exception Handling : The Blamer is only called when an exception occurs. It receives the exception as a string and provides the system with context information about all Planex agents. Response Specification : Using LangChain, we fully specify the format of the Blamer's response, defining three key concepts to resolve: the blamed agent (Who failed?), the explanation, and advice for avoiding the failure when the agent is called again. Selective Recall : The Blamer can recall agents from the Planex chain as needed, skipping those that are not necessary (i.e., those that are correct). Results Key Advantages Failure Reaction : The agent can now recover from failures, reusing agents and ensuring that the response will return a valid Exelent file. Improved Accuracy : By showing the agents their failures, we achieve better results, with improved accuracy and more reliable plans. Key Disadvantages Cost of Recovery : Recovering from a failure requires a larger prompt, making it more expensive than expected, even though some agents are skipped. Limited Recovery : The Blamer is not always able to fully recover Planex from failures. If the plan is too long (i.e., involves too many steps), PlanexV2 can enter a loop, failing to recover. To address this, PlanexV2 has a maximum step limit. All these properties can be tested in this repository using the following command: python ecm/core/main.py --agent planexv2","title":"Introduction"},{"location":"Planex-Insights/#introduction","text":"","title":"Introduction"},{"location":"Planex-Insights/#implementation-of-the-cognition-layer-algorithm-a_1-with-planex","text":"The Cognition Layer Algorithm, sometimes referred to as $A_1$, defines the intelligent or cognitive layer of the ECM. A detailed problem analysis can be found in the ECM Problem Analysis , where we divided the ECM cognition problem into three subproblems: Planify, Reduce, and Translate.","title":"Implementation of the Cognition Layer Algorithm ($A_1$) with Planex"},{"location":"Planex-Insights/#design","text":"Planex has been designed as a three-agent model . By leveraging LangChain, we can utilize the capabilities of large language models (LLMs) such as GPT-3.5. In this context, we assume the knowledge base $C'$ aligns with the properties established in the analysis. This framework allows us to effectively define and chain these three agents, with their behavior primarily specified through two methods: Fine-Tuning : By fine-tuning the models, we can achieve the desired behavior from each agent more accurately. However, this methodology requires an unbiased dataset and extensive analysis/training. Prompt Engineering (Selected Approach) : Using prompt engineering, we can quickly deploy the agents with an approximation of the fine-tuned behavior. Zero-shot prompts enable experimentation, modification, and testing of agent results. We selected the prompt engineering method because it allows for the rapid exploration of multiple agents and new approaches, in alignment with the easily replaceable modules of the ECM.","title":"Design"},{"location":"Planex-Insights/#prompt-engineering","text":"All the prompts designed can be found in the /cognition_layer/planex/agents/prompts.py file of the repository. In that file, each agent has three defined prompts: Instructions : Here we declare the expected behavior of the agent. As defined in Lei Wang et al. paper , we define the Profile of the agent. The main properties of each agent are: Planner : The planner's objective is \"to provide a detailed step-by-step plan to address the user's query.\" Reducer : The reducer's objective is \"to review a given plan and provide a new plan that achieves the same result using predefined functions.\" Translator : The translator's objective is \"to translate the plan into Exelent language.\" Guidelines : Using a trial-and-error methodology, we define a set of rules that improve the agent's behavior by explaining and warning about possible failures and misconceptions about the goal. For example, \"Ensure the new plan uses only the Exelent language constructs and achieves the same result as the original plan.\" Example : By using one-shot prompting, we can improve the reliability and standardize the response of the model, specifying for each agent a possible result and its format. For some agents we also provide some information about the system, such as which tools are available, which is the focused window, operative system, etc. For this step we could take advantage of langchain tool formatting for defining the valid tools the ECM can receive.","title":"Prompt Engineering"},{"location":"Planex-Insights/#results","text":"Using this simple but efficient model, we achieve the following advantages: Simple Task Solving : For tasks that require three or four consecutive steps, Planex can appropriately define and execute the correct actions. Examples include: \"Open Spotify\" and \"Write 'hello world' on the terminal.\" Fast and Controlled Results : The results are consistently defined after three steps, establishing a concrete number of steps to execute. The main disadvantages found while testing this agent are the following: Large Prompt : As this model uses a one-shot prompting methodology, it requires an extensive prompt each time it is executed, making the request more expensive and necessitating re-learning how to solve the query each time it is called. Fine-tuning could address this issue, but further research is needed. No Failure Reaction : If the reducer or translator fails to properly select the correct tools, the agent cannot recover and must be fully reloaded. Not Fully System Aware : Although we have introduced information about the system, the agent cannot fully understand and develop a mental simulation of the system's status. This limitation leads to failures where the agent assumes previously opened apps, defined requirements, etc. All this properties can be tested in this repository by using the following command: python ecm/core/main.py --agent planex If you are in a safe environment you can also use the python executable in /ecm/core/run_in_host.py","title":"Results"},{"location":"Planex-Insights/#planexv2","text":"PlanexV2, located in the directory /cognition_layer/planexv2 , is a four-agent model for $A_1$ that improves upon the original Planex agent by introducing the Blamer , an agent capable of reacting to exceptions and recalling the failed agent. The Blamer follows the same schema as other agents, with three key properties: Exception Handling : The Blamer is only called when an exception occurs. It receives the exception as a string and provides the system with context information about all Planex agents. Response Specification : Using LangChain, we fully specify the format of the Blamer's response, defining three key concepts to resolve: the blamed agent (Who failed?), the explanation, and advice for avoiding the failure when the agent is called again. Selective Recall : The Blamer can recall agents from the Planex chain as needed, skipping those that are not necessary (i.e., those that are correct).","title":"PlanexV2"},{"location":"Planex-Insights/#results_1","text":"","title":"Results"},{"location":"Planex-Insights/#key-advantages","text":"Failure Reaction : The agent can now recover from failures, reusing agents and ensuring that the response will return a valid Exelent file. Improved Accuracy : By showing the agents their failures, we achieve better results, with improved accuracy and more reliable plans.","title":"Key Advantages"},{"location":"Planex-Insights/#key-disadvantages","text":"Cost of Recovery : Recovering from a failure requires a larger prompt, making it more expensive than expected, even though some agents are skipped. Limited Recovery : The Blamer is not always able to fully recover Planex from failures. If the plan is too long (i.e., involves too many steps), PlanexV2 can enter a loop, failing to recover. To address this, PlanexV2 has a maximum step limit. All these properties can be tested in this repository using the following command: python ecm/core/main.py --agent planexv2","title":"Key Disadvantages"},{"location":"Planex/","text":"Planex as an Approximation to $A_1$ Planex is a sophisticated 3-step planner agent designed to approximate the ECM problem through the utilization of LangChain. This approximation involves the collaborative efforts of three distinct agents, each focusing on a crucial aspect of the process: Planning, Reduction, and Translation, as delineated in the Theoretical Analysis . To provide a comprehensive understanding, these three steps correspond to the following concepts: - Planning : The planning agent receives a natural language query from the user and devises a solution to approximate the problem. This process is independent of the specific context or tools available to the agents. - Reduction : The reduction agent takes the explanation of the problem provided by the planner and identifies a set of tools that correspond to each instruction. Consequently, the resulting plan includes the necessary keywords and tools for execution. - Translation : The translation agent receives the plan and generates an Exelent file, which can be executed to achieve the desired solution. Usage To begin, let us explore the implementation of these agents. All agents within Planex are located in the /agents directory. Each agent possesses an attribute chain , which contains the execution module of the chain. Additionally, each agent includes a function for direct execution with a query, as illustrated in the example below: from cognition_layer.planex.agents.planner import Planner from cognition_layer.planex.agents.reducer import Reducer from cognition_layer.planex.agents.translator import Translator planner = Planner() reducer = Reducer() translator = Translator() # Execute an example action for each agent planner_result = planner.plan(\"Open Spotify\", verbose=True) reducer_result = reducer.reduce(planner_result.content, verbose=True) translator_result = translator.translate(translator.content, verbose=False) print(\"Plan defined: \", translator_result.content) It is important to note that each agent returns a BaseMessage from LangChain, ensuring both traceability and scalability. As a result, the output of the agents is contained in the .content attribute of the Messages. Upon executing the above code, you may observe that the plan references functions not yet defined. This occurs because the agents have not been provided with the specific actions they can utilize to solve the plan. To define new actions, you can register your functions within the ItemRegistry, and they will be automatically integrated into the planners. from ecm.tools.registry import ItemRegistry @ItemRegistry.register_function def click(place: str) -> None: \"\"\"Clicks on the specified place\"\"\" print(\"Clicked on \", place) # If you instantiate the tool after initializing the agents, notify the reducer to update its actions: reducer.auto_bind_actions() It is crucial that the docstring and typing are provided for the registered function, as this information is used by the agent to describe the function to the LLM. After registering the new actions, you can re-execute your three agents, and the defined actions will be considered when formulating the Exelent plan. Merging Chains As mentioned earlier, each agent contains a LangChain chain. This allows for the combination of all agents into a single entity by pipelining the necessary messages for each agent: planex = ( planner.chain | (lambda output: {\"input\": output.content, \"actions\": reducer.actions}) | reducer.chain | (lambda output: {\"input\": output.content}) | translator.chain ) You can now effortlessly execute Planex by invoking it as a chain: result = planex.invoke({\"input\": query}) print(\"Result: \", result.content) Planex Prompt Engineering The instructions defined for each agent in Planex can be found in the /agents/prompts.py module. This module contains multiple prompts that are included in each invocation. Each prompt comprises specific instructions detailing the target, guidelines to be followed, and examples to illustrate proper usage. You are encouraged to modify these prompts to explore potential new behaviors and functionalities of Planex. After defining the prompts in the prompts.py file, they are merged for each agent as follows: sys_message = ( \"\\nInstructions: \\n\" + PlanexPrompts.AGENT_INSTRUCTIONS + \"\\nGuidelines: \\n\" + PlanexPrompts.AGENT_GUIDELINES + \"\\nExample:\\n\" + PlanexPrompts.AGENT_EXAMPLE ) # The agent here could be the planner, reducer, or translator agent.prompt = ChatPromptTemplate.from_messages( [(\"system\", sys_message), (\"user\", \"{input}\")] ) In this implementation, the sys_message variable is constructed by concatenating the instructions, guidelines, and example prompts defined in the PlanexPrompts class. This combined system message is then assigned to the prompt attribute of the respective agent (planner, reducer, or translator). The ChatPromptTemplate.from_messages method is used to create a prompt template from these system and user messages, facilitating effective communication and task execution by the agents. Feel free to experiment with and refine these prompts to optimize the performance and adaptability of Planex to various scenarios and requirements.","title":"Planex as an Approximation to $A_1$"},{"location":"Planex/#planex-as-an-approximation-to-a_1","text":"Planex is a sophisticated 3-step planner agent designed to approximate the ECM problem through the utilization of LangChain. This approximation involves the collaborative efforts of three distinct agents, each focusing on a crucial aspect of the process: Planning, Reduction, and Translation, as delineated in the Theoretical Analysis . To provide a comprehensive understanding, these three steps correspond to the following concepts: - Planning : The planning agent receives a natural language query from the user and devises a solution to approximate the problem. This process is independent of the specific context or tools available to the agents. - Reduction : The reduction agent takes the explanation of the problem provided by the planner and identifies a set of tools that correspond to each instruction. Consequently, the resulting plan includes the necessary keywords and tools for execution. - Translation : The translation agent receives the plan and generates an Exelent file, which can be executed to achieve the desired solution.","title":"Planex as an Approximation to $A_1$"},{"location":"Planex/#usage","text":"To begin, let us explore the implementation of these agents. All agents within Planex are located in the /agents directory. Each agent possesses an attribute chain , which contains the execution module of the chain. Additionally, each agent includes a function for direct execution with a query, as illustrated in the example below: from cognition_layer.planex.agents.planner import Planner from cognition_layer.planex.agents.reducer import Reducer from cognition_layer.planex.agents.translator import Translator planner = Planner() reducer = Reducer() translator = Translator() # Execute an example action for each agent planner_result = planner.plan(\"Open Spotify\", verbose=True) reducer_result = reducer.reduce(planner_result.content, verbose=True) translator_result = translator.translate(translator.content, verbose=False) print(\"Plan defined: \", translator_result.content) It is important to note that each agent returns a BaseMessage from LangChain, ensuring both traceability and scalability. As a result, the output of the agents is contained in the .content attribute of the Messages. Upon executing the above code, you may observe that the plan references functions not yet defined. This occurs because the agents have not been provided with the specific actions they can utilize to solve the plan. To define new actions, you can register your functions within the ItemRegistry, and they will be automatically integrated into the planners. from ecm.tools.registry import ItemRegistry @ItemRegistry.register_function def click(place: str) -> None: \"\"\"Clicks on the specified place\"\"\" print(\"Clicked on \", place) # If you instantiate the tool after initializing the agents, notify the reducer to update its actions: reducer.auto_bind_actions() It is crucial that the docstring and typing are provided for the registered function, as this information is used by the agent to describe the function to the LLM. After registering the new actions, you can re-execute your three agents, and the defined actions will be considered when formulating the Exelent plan.","title":"Usage"},{"location":"Planex/#merging-chains","text":"As mentioned earlier, each agent contains a LangChain chain. This allows for the combination of all agents into a single entity by pipelining the necessary messages for each agent: planex = ( planner.chain | (lambda output: {\"input\": output.content, \"actions\": reducer.actions}) | reducer.chain | (lambda output: {\"input\": output.content}) | translator.chain ) You can now effortlessly execute Planex by invoking it as a chain: result = planex.invoke({\"input\": query}) print(\"Result: \", result.content)","title":"Merging Chains"},{"location":"Planex/#planex-prompt-engineering","text":"The instructions defined for each agent in Planex can be found in the /agents/prompts.py module. This module contains multiple prompts that are included in each invocation. Each prompt comprises specific instructions detailing the target, guidelines to be followed, and examples to illustrate proper usage. You are encouraged to modify these prompts to explore potential new behaviors and functionalities of Planex. After defining the prompts in the prompts.py file, they are merged for each agent as follows: sys_message = ( \"\\nInstructions: \\n\" + PlanexPrompts.AGENT_INSTRUCTIONS + \"\\nGuidelines: \\n\" + PlanexPrompts.AGENT_GUIDELINES + \"\\nExample:\\n\" + PlanexPrompts.AGENT_EXAMPLE ) # The agent here could be the planner, reducer, or translator agent.prompt = ChatPromptTemplate.from_messages( [(\"system\", sys_message), (\"user\", \"{input}\")] ) In this implementation, the sys_message variable is constructed by concatenating the instructions, guidelines, and example prompts defined in the PlanexPrompts class. This combined system message is then assigned to the prompt attribute of the respective agent (planner, reducer, or translator). The ChatPromptTemplate.from_messages method is used to create a prompt template from these system and user messages, facilitating effective communication and task execution by the agents. Feel free to experiment with and refine these prompts to optimize the performance and adaptability of Planex to various scenarios and requirements.","title":"Planex Prompt Engineering"},{"location":"Pyxcel-Interpreter/","text":"Warnings and Notes Pyxcel is ROS Agnostic, fully created with python packages Pyxcel uses ItemRegistryV2, it is designed to be backward-compatible but the oldest agent tested is Xplore. Pyxcel ensures that the feedback messages \"RUNNING\" and \"FINISH\" are sent to callbacks. The callback function is equivalente to the ROSA feedback. Pyxcel can return results with the \"RESULT\" message on the feedback_callback. Supported Properties Property Default Value Notes stop Yes hard_stop No (Use with caution) sync_calls Yes async_calls Yes Recommended wait_for No callbacks Yes Full control implemented with Feedback Messages feedback Yes callback_keywords (\"RUNNING\", \"STEP\", \"SUCCESS\", \"ABORT\", \"FINISH\", \"SWITCH\") RUNNING and FINISH are ensured for every task types \"Sequential\" Additional types may be implemented in the future References: - Pyxcel Internals PyxcelInterpreter Attributes Attribute Type Description callback_dict dict[str, ExecutionStatus] Maps callback keywords to their execution statuses. Examples Initializing and killing from execution_layer.pyxcel.interprter.pyxcel_interpreter import PyxcelInterpreter interpreter = PyxcelInterpreter() interpreter.kill() Running import ecm.exelent.parser as parser my_task = parser.parse(\"path_to_xlnt_file\") interpreter.run(my_task) # Will return at finish interpreter.arun(my_task) # Returns immediately Stopping # Note: Stopping nested functions is not fully stable interpreter.run(my_task) interpreter.stop(my_task.name)","title":"Pyxcel Interpreter"},{"location":"Pyxcel-Interpreter/#warnings-and-notes","text":"Pyxcel is ROS Agnostic, fully created with python packages Pyxcel uses ItemRegistryV2, it is designed to be backward-compatible but the oldest agent tested is Xplore. Pyxcel ensures that the feedback messages \"RUNNING\" and \"FINISH\" are sent to callbacks. The callback function is equivalente to the ROSA feedback. Pyxcel can return results with the \"RESULT\" message on the feedback_callback.","title":"Warnings and Notes"},{"location":"Pyxcel-Interpreter/#supported-properties","text":"Property Default Value Notes stop Yes hard_stop No (Use with caution) sync_calls Yes async_calls Yes Recommended wait_for No callbacks Yes Full control implemented with Feedback Messages feedback Yes callback_keywords (\"RUNNING\", \"STEP\", \"SUCCESS\", \"ABORT\", \"FINISH\", \"SWITCH\") RUNNING and FINISH are ensured for every task types \"Sequential\" Additional types may be implemented in the future References: - Pyxcel Internals","title":"Supported Properties"},{"location":"Pyxcel-Interpreter/#pyxcelinterpreter-attributes","text":"Attribute Type Description callback_dict dict[str, ExecutionStatus] Maps callback keywords to their execution statuses.","title":"PyxcelInterpreter Attributes"},{"location":"Pyxcel-Interpreter/#examples","text":"Initializing and killing from execution_layer.pyxcel.interprter.pyxcel_interpreter import PyxcelInterpreter interpreter = PyxcelInterpreter() interpreter.kill() Running import ecm.exelent.parser as parser my_task = parser.parse(\"path_to_xlnt_file\") interpreter.run(my_task) # Will return at finish interpreter.arun(my_task) # Returns immediately Stopping # Note: Stopping nested functions is not fully stable interpreter.run(my_task) interpreter.stop(my_task.name)","title":"Examples"},{"location":"ROSA-Interpreter/","text":"Warnings and Notes Rosa does support concurrent tasks, however only one Rosa can be instantiated at the time , this is due to ROS2 dependency. Don't worry about initing with RosaInterpreter() or Rosa() multiple times, it is programmed as a singleton, but don't try to instantiate various ROSA in multiple process. Human in the loop or waitings in ROSA can be easily handled with the tools you pass. Just communicate your functions by using Feedback Messages. ROSA only ensures \"RUNINNG\" and \"FINISH\" feedback messages will be sent to the callbacks. The other ones will depend on the code inside the tools. You can use the gureg command in the shell to debug in live and look what messages are being passed inside ROSA. Also you can use ROS2 topic tools or change the LOG.LEVEL inside the constants Supported Properties Property Default Value Notes stop Yes hard_stop Yes (Use with caution) sync_calls Yes async_calls Yes Recommended wait_for Yes callbacks Yes Full control implemented with Feedback Messages feedback Yes callback_keywords (\"RUNNING\", \"STEP\", \"SUCCESS\", \"ABORT\", \"FINISH\", \"SWITCH\") RUNNING and FINISH are ensured for every task types \"Sequential\" , \"ControlledSequence\" On develop the implementation of Parallel/Conditional tasks References: - How to use Feedback Messages - Rosa Internals RosaInterpreter Attributes Attribute Type Description type_dict dict[str, SequenceType] Maps sequence types to their implementations. callback_dict dict[str, ExecutionStatus] Maps callback keywords to their execution statuses. Examples Initing and kill from ecm.mediator.rosa_interpreter import RosaInterpreter interpreter = RosaInterpreter() interpreter.kill() Running import ecm.exelent.parser as parser my_task = parser.parse(\"path_to_exln_file\") interpreter.run(my_task) # Will return at finish interpreter.arun(my_task) # Returns immediatly Waiting: # Be careful with waiting, you must be sure the call will be raised or you could end blocked. # You can safely wait for FINISH, but for messages as STEP, SUCCESS or ABORT is better to use callbacks. interpreter.arun(my_task) interpreter.wait_for(my_task.name, \"FINISH\") # Equivalent to interpreter.run() Stopping: interpreter.arun(my_task) interpreter.stop(my_task.name)","title":"ROSA Interpreter"},{"location":"ROSA-Interpreter/#warnings-and-notes","text":"Rosa does support concurrent tasks, however only one Rosa can be instantiated at the time , this is due to ROS2 dependency. Don't worry about initing with RosaInterpreter() or Rosa() multiple times, it is programmed as a singleton, but don't try to instantiate various ROSA in multiple process. Human in the loop or waitings in ROSA can be easily handled with the tools you pass. Just communicate your functions by using Feedback Messages. ROSA only ensures \"RUNINNG\" and \"FINISH\" feedback messages will be sent to the callbacks. The other ones will depend on the code inside the tools. You can use the gureg command in the shell to debug in live and look what messages are being passed inside ROSA. Also you can use ROS2 topic tools or change the LOG.LEVEL inside the constants","title":"Warnings and Notes"},{"location":"ROSA-Interpreter/#supported-properties","text":"Property Default Value Notes stop Yes hard_stop Yes (Use with caution) sync_calls Yes async_calls Yes Recommended wait_for Yes callbacks Yes Full control implemented with Feedback Messages feedback Yes callback_keywords (\"RUNNING\", \"STEP\", \"SUCCESS\", \"ABORT\", \"FINISH\", \"SWITCH\") RUNNING and FINISH are ensured for every task types \"Sequential\" , \"ControlledSequence\" On develop the implementation of Parallel/Conditional tasks References: - How to use Feedback Messages - Rosa Internals","title":"Supported Properties"},{"location":"ROSA-Interpreter/#rosainterpreter-attributes","text":"Attribute Type Description type_dict dict[str, SequenceType] Maps sequence types to their implementations. callback_dict dict[str, ExecutionStatus] Maps callback keywords to their execution statuses.","title":"RosaInterpreter Attributes"},{"location":"ROSA-Interpreter/#examples","text":"Initing and kill from ecm.mediator.rosa_interpreter import RosaInterpreter interpreter = RosaInterpreter() interpreter.kill() Running import ecm.exelent.parser as parser my_task = parser.parse(\"path_to_exln_file\") interpreter.run(my_task) # Will return at finish interpreter.arun(my_task) # Returns immediatly Waiting: # Be careful with waiting, you must be sure the call will be raised or you could end blocked. # You can safely wait for FINISH, but for messages as STEP, SUCCESS or ABORT is better to use callbacks. interpreter.arun(my_task) interpreter.wait_for(my_task.name, \"FINISH\") # Equivalent to interpreter.run() Stopping: interpreter.arun(my_task) interpreter.stop(my_task.name)","title":"Examples"},{"location":"ROSA/","text":"Using ROSA (ROS Agent) Introduction ROSA (ROS Agent) is a crucial component in our system that simplifies the interaction with the Task Sequence Protocol (TSP) through a series of easy-to-use functions at higher levels. This guide covers the basics of how to utilize ROSA for handling tasks, executing sequences, and managing execution statuses within a test-driven development environment. Setup ROSA Before executing any tasks, initialize the ROSA instance. Here's how to set up ROSA within your test environment: from execution_layer.rosa.interfaces.rosa import ROSA rosa = ROSA() Executing a Task To execute a task, you need to define a SequencePackage with a list of ActionPackage items that specify what actions to perform. In the following example, we will use an example function that prints Waiting... 3 times and finishes printing \"Hello ROSA!\". For this, we will use a set of functions called sleep_and_print included in the mocks . If you want to use your own functions, you can look at the mocks and copy the templates with your own code. from execution_layer.rosa.ros2.tools.packages import ActionPackage, SequencePackage, SequencePriority waiting = ActionPackage( action_id=ItemRegistry.get_id(sleep_and_print), text=\"Wating...\" ) end = ActionPackage( action_id=ItemRegistry.get_id(sleep_and_print), text=\"Hello ROSA!\" ) Now that we have a set of actions, we must define the behavior and priority of the actions. For this, we will use a SequencePackage . In this object, we will define the following properties: task_id : Here you will define a name for the task. This will be used as an internal identifier of all the tasks with the same objective. Usually you should write the purpouse of your sequence, in this case wait_and_print type : Here you can select how to execute your set of actions. You can find all types in the types directory. However you can implement your own types, by loading them as stablished in the basic.py docs. Note that the most relevant types are the following: SimpleSequence : Executes the sequence in order, if an action fails, it will return an ABORT code, else a SUCCESS code. ParallelSequence : Yet not implemented. priority : Stablishes the order in which the server will execute the tasks if multiple tasks with the same id are received. You can look at all priorities in this file actions : An array with all the actions you want to perform from execution_layer.rosa.ros2.types.basic import SimpleSequence seq = SequencePackage( task_id=\"wait_and_print\", type=SimpleSequence.get_type(), priority=SequencePriority.NORMAL, actions=[wait_for_text, end_text], ) Now that you have the task defined, we will create a task in ROSA and build a function for controlling the feedback returned from the server. For creating a feedback manager (optional) you can define a function for managing each Feedback object received from ROSA. A feedback object contains two main properties: _exec_status : This value should not be modified, it returns some information of the status of the SequenceType. The most common values are the following: FINISH : This value is always returned when the SequenceType finishes (wether it success or fails) ABORT : Returned when the SequenceType fails SUCCESS : Returned when the SequenceType has ended properly STEP : Returned between the execution of each action RUNNING : Returned when the feedback has asynchronously been generated by an inside action/function object : This value contains any object that you can return from inside the functions executed, use it as you want. As an example we will make the following controller: from execution_layer.rosa.ros2.tools.feedback import Feedback from execution_layer.rosa.ros2.tools.feedback import ExecutionStatus def my_controller(feedback: Feedback): if feedback._exec_status == ExecutionStatus.FINISH: print(\"Task has finished!\") Note that if you don't want to use any controller you can just use the ROSA.muted_callback as argument. Now that we have everything settled up, we just have to execute all with ROSA. Remember that ROSA will use a non-blocking call so if you want to wait for the execution to finish before continuing the program you can use the wait_for function. self.rosa.new_task(\"wait_and_print\", feedback_callback=my_controller) self.rosa.execute(seq) self.rosa.wait_for(\"wait_and_print\", ExecutionStatus.FINISH) Stopping a task Whenever you have launched a task, you may want to abort the following actions. For this reason ROSA implements 2 stopping methods. Soft-Stop and Hard-Stop. A soft-stop allows the current sequence to complete gracefully before stopping, it will raise an event into the SequenceType to stop executing whenever a clean exit is possible. This exit usually happens between action steps. self.rosa.soft_stop(\"wait_and_print\") self.rosa.wait_for(\"test_soft_stop\", ExecutionStatus.FINISH) A hard-stop immediately raises a signal to stop a task, disregarding its current state or any ongoing actions. This is a critical function for emergency situations where stopping a task as quickly as possible is necessary to prevent undesirable effects or to reset the system rapidly. However, this function should not be used unless it is stricly needed since it can end up in corrupted files or inconsistent executions. import time self.rosa._hard_stop(\"wait_and_print\") time.sleep(1) # Wait to ensure the process has been terminated Using Feedback Wherever you are in python, if you want to return feedback to the SequenceType that has called you (if any) remember that you can return an object with the following structure. from execution_layer.rosa.ros2.tools.feedback import Feedback f = Feedback() # Automatically will settle up your task_id f.publish(my_object) # Note: You should have built at least one ROSA instance before using feedback objects. Now this feedback will be managed by a ROSA callback manager if it has been stablished in the task. Conclusion This tutorial provides a foundational understanding of how to interact with ROSA to execute, monitor, and manage tasks within a ROS2-enabled environment. The methods showcased help facilitate effective testing and control of asynchronous task execution, essential for robust software development. Now you are ready to implement and improve your own functionalities with ROSA as an Execution_Layer Algorithm or A_2.","title":"Using ROSA (ROS Agent)"},{"location":"ROSA/#using-rosa-ros-agent","text":"","title":"Using ROSA (ROS Agent)"},{"location":"ROSA/#introduction","text":"ROSA (ROS Agent) is a crucial component in our system that simplifies the interaction with the Task Sequence Protocol (TSP) through a series of easy-to-use functions at higher levels. This guide covers the basics of how to utilize ROSA for handling tasks, executing sequences, and managing execution statuses within a test-driven development environment.","title":"Introduction"},{"location":"ROSA/#setup-rosa","text":"Before executing any tasks, initialize the ROSA instance. Here's how to set up ROSA within your test environment: from execution_layer.rosa.interfaces.rosa import ROSA rosa = ROSA()","title":"Setup ROSA"},{"location":"ROSA/#executing-a-task","text":"To execute a task, you need to define a SequencePackage with a list of ActionPackage items that specify what actions to perform. In the following example, we will use an example function that prints Waiting... 3 times and finishes printing \"Hello ROSA!\". For this, we will use a set of functions called sleep_and_print included in the mocks . If you want to use your own functions, you can look at the mocks and copy the templates with your own code. from execution_layer.rosa.ros2.tools.packages import ActionPackage, SequencePackage, SequencePriority waiting = ActionPackage( action_id=ItemRegistry.get_id(sleep_and_print), text=\"Wating...\" ) end = ActionPackage( action_id=ItemRegistry.get_id(sleep_and_print), text=\"Hello ROSA!\" ) Now that we have a set of actions, we must define the behavior and priority of the actions. For this, we will use a SequencePackage . In this object, we will define the following properties: task_id : Here you will define a name for the task. This will be used as an internal identifier of all the tasks with the same objective. Usually you should write the purpouse of your sequence, in this case wait_and_print type : Here you can select how to execute your set of actions. You can find all types in the types directory. However you can implement your own types, by loading them as stablished in the basic.py docs. Note that the most relevant types are the following: SimpleSequence : Executes the sequence in order, if an action fails, it will return an ABORT code, else a SUCCESS code. ParallelSequence : Yet not implemented. priority : Stablishes the order in which the server will execute the tasks if multiple tasks with the same id are received. You can look at all priorities in this file actions : An array with all the actions you want to perform from execution_layer.rosa.ros2.types.basic import SimpleSequence seq = SequencePackage( task_id=\"wait_and_print\", type=SimpleSequence.get_type(), priority=SequencePriority.NORMAL, actions=[wait_for_text, end_text], ) Now that you have the task defined, we will create a task in ROSA and build a function for controlling the feedback returned from the server. For creating a feedback manager (optional) you can define a function for managing each Feedback object received from ROSA. A feedback object contains two main properties: _exec_status : This value should not be modified, it returns some information of the status of the SequenceType. The most common values are the following: FINISH : This value is always returned when the SequenceType finishes (wether it success or fails) ABORT : Returned when the SequenceType fails SUCCESS : Returned when the SequenceType has ended properly STEP : Returned between the execution of each action RUNNING : Returned when the feedback has asynchronously been generated by an inside action/function object : This value contains any object that you can return from inside the functions executed, use it as you want. As an example we will make the following controller: from execution_layer.rosa.ros2.tools.feedback import Feedback from execution_layer.rosa.ros2.tools.feedback import ExecutionStatus def my_controller(feedback: Feedback): if feedback._exec_status == ExecutionStatus.FINISH: print(\"Task has finished!\") Note that if you don't want to use any controller you can just use the ROSA.muted_callback as argument. Now that we have everything settled up, we just have to execute all with ROSA. Remember that ROSA will use a non-blocking call so if you want to wait for the execution to finish before continuing the program you can use the wait_for function. self.rosa.new_task(\"wait_and_print\", feedback_callback=my_controller) self.rosa.execute(seq) self.rosa.wait_for(\"wait_and_print\", ExecutionStatus.FINISH)","title":"Executing a Task"},{"location":"ROSA/#stopping-a-task","text":"Whenever you have launched a task, you may want to abort the following actions. For this reason ROSA implements 2 stopping methods. Soft-Stop and Hard-Stop. A soft-stop allows the current sequence to complete gracefully before stopping, it will raise an event into the SequenceType to stop executing whenever a clean exit is possible. This exit usually happens between action steps. self.rosa.soft_stop(\"wait_and_print\") self.rosa.wait_for(\"test_soft_stop\", ExecutionStatus.FINISH) A hard-stop immediately raises a signal to stop a task, disregarding its current state or any ongoing actions. This is a critical function for emergency situations where stopping a task as quickly as possible is necessary to prevent undesirable effects or to reset the system rapidly. However, this function should not be used unless it is stricly needed since it can end up in corrupted files or inconsistent executions. import time self.rosa._hard_stop(\"wait_and_print\") time.sleep(1) # Wait to ensure the process has been terminated","title":"Stopping a task"},{"location":"ROSA/#using-feedback","text":"Wherever you are in python, if you want to return feedback to the SequenceType that has called you (if any) remember that you can return an object with the following structure. from execution_layer.rosa.ros2.tools.feedback import Feedback f = Feedback() # Automatically will settle up your task_id f.publish(my_object) # Note: You should have built at least one ROSA instance before using feedback objects. Now this feedback will be managed by a ROSA callback manager if it has been stablished in the task.","title":"Using Feedback"},{"location":"ROSA/#conclusion","text":"This tutorial provides a foundational understanding of how to interact with ROSA to execute, monitor, and manage tasks within a ROS2-enabled environment. The methods showcased help facilitate effective testing and control of asynchronous task execution, essential for robust software development. Now you are ready to implement and improve your own functionalities with ROSA as an Execution_Layer Algorithm or A_2.","title":"Conclusion"},{"location":"RePlan-Insights/","text":"Introduction Implementation of the Cognition Layer Algorithm ($A_1$) with RePlan RePlan is a ReAct -based agent that uses multiple tools to focus on control, permission, and failure reaction of the $A_1$ algorithm. To achieve this, we use the LangChain ReAct agent and chain each action done by the agent into an agent_scratchpad where the agent can think and review the actions and results obtained. The core of this agent resides in its tools. As LangChain states: Docs : \"Agents are only as good as the tools they have.\" The tools provided to RePlan are the following: 1. PlanexV2 as a Tool : We reused PlanexV2's capability to generate Exelent files from queries and reformatted it as a tool fully integrated into RePlan. This enables RePlan to planify from a given query. 2. ExecutionWrapper as a Tool : We integrated the control of the execution layer with a set of tools that enable the agent to listen to the feedback obtained from the actions, approve or deny actions, or create new tasks. Results Key Advantages Reaction : The agent can react to failures, generating new plans or new approaches to the user query. Control : RePlan can accept or deny steps by taking advantage of the ControlledSequence type in Exelent. Better Results : Using RePlan results in better performance and more effective utilization of Planex actions. Key Disadvantages Token Cost : Minimizing the tokens used in RePlan is challenging, as the thinking process of ReAct trades reliability and usability for more expensive requests to the LLM. Not Exelent Aware : Although RePlan can generate Exelent code, it cannot modify the plan, relying on Planex for plan generation. Not Context Aware : ReAct can gather information about the system but encounters the same awareness issues as Planex when planning. This module can be tested like other agents by using the following command: # We recommend using --debug to fully trace all that happens inside RePlan python ecm/core/main.py --agent RePlan --debug","title":"Introduction"},{"location":"RePlan-Insights/#introduction","text":"","title":"Introduction"},{"location":"RePlan-Insights/#implementation-of-the-cognition-layer-algorithm-a_1-with-replan","text":"RePlan is a ReAct -based agent that uses multiple tools to focus on control, permission, and failure reaction of the $A_1$ algorithm. To achieve this, we use the LangChain ReAct agent and chain each action done by the agent into an agent_scratchpad where the agent can think and review the actions and results obtained. The core of this agent resides in its tools. As LangChain states: Docs : \"Agents are only as good as the tools they have.\" The tools provided to RePlan are the following: 1. PlanexV2 as a Tool : We reused PlanexV2's capability to generate Exelent files from queries and reformatted it as a tool fully integrated into RePlan. This enables RePlan to planify from a given query. 2. ExecutionWrapper as a Tool : We integrated the control of the execution layer with a set of tools that enable the agent to listen to the feedback obtained from the actions, approve or deny actions, or create new tasks.","title":"Implementation of the Cognition Layer Algorithm ($A_1$) with RePlan"},{"location":"RePlan-Insights/#results","text":"","title":"Results"},{"location":"RePlan-Insights/#key-advantages","text":"Reaction : The agent can react to failures, generating new plans or new approaches to the user query. Control : RePlan can accept or deny steps by taking advantage of the ControlledSequence type in Exelent. Better Results : Using RePlan results in better performance and more effective utilization of Planex actions.","title":"Key Advantages"},{"location":"RePlan-Insights/#key-disadvantages","text":"Token Cost : Minimizing the tokens used in RePlan is challenging, as the thinking process of ReAct trades reliability and usability for more expensive requests to the LLM. Not Exelent Aware : Although RePlan can generate Exelent code, it cannot modify the plan, relying on Planex for plan generation. Not Context Aware : ReAct can gather information about the system but encounters the same awareness issues as Planex when planning. This module can be tested like other agents by using the following command: # We recommend using --debug to fully trace all that happens inside RePlan python ecm/core/main.py --agent RePlan --debug","title":"Key Disadvantages"},{"location":"Remote-Execution/","text":"ECM Server/Client The ECM algorithms designed in this repository are aimed to be executed remotely, this is, to have a computer or machine that reasons, loads and computes all the cognitive layers ($A_1$) and a client machine that listens and executes all the functions sent by the server ($A_2$), this can be easily activated without affecting the core architecture by using the modules integrated in this repository. The Client/Server modules use RabbitMQ in order to stablish a connection between the two machines, to start this protocol you only need to start listening with the client as follows: import action_space.experimental.mouse.actions # noqa import action_space.experimental.screenshot.actions # noqa from ecm.remote.client import EcmClient if __name__ == \"__main__\": client = EcmClient() client.listen() Note that we must import the actions we want to be enabled in the client machine in order to be auto-detected when received from the server. Warning: If the client is not connected, the server will fail when trying to send the correspondent action. Synchronizing the ItemRegistry After having the client connected, we can use the ItemRegistry to send tasks to the client. For using the ItemRegistry appropriately you must differentiate between two types of capabilites: Registering Functions : This is the base function for sending actions to the client. When loading AI agents, the names of this functions and multiple descriptions on how to use them are loaded in order to let the AI decide when and why to send an action to the client. Registering an action can be done as follows: python @ItemRegistry.register_function def do_something(element: str): \"\"\"Does something using the element. Usage do_something('foo')\"\"\" ... Registering utils : Utils can be also sent to the client, though they won't be notified to the AI's, so you can use this tools to execute AI-hiden algorithms, such as taking screenshots for sending them to the AI, computing calculations, or obtaining information. This actions do not have to be AI-friendly. python @ItemRegistry.register_util def restart(arg1, arg2, arg3): ... Finally, if you want to use your functions in the host machine, just don't apply changes, in the contrary, if you want to execute utils or functions in the remote machine, use the following command to automatically synchronize with the client: # The actions my AI will find from action_space.experimental.mouse.agent import MouseAgent # noqa from ecm.tools.registry import ItemRegistry if __name__ == \"__main__\": ItemRegistry.transfer_execution_to_client() ... # execute your algorithms normally... Warning: ItemRegistryV2 has deprecated this function. The replaced function is EcmServer.wrap_item_registry() All the functions/utils will be sent to the client when trying to access them through the ItemRegistry. Warning: If you try to hard-access the functions without the ItemRegistry, they will be executed in the host machine. For this reason, multiple times you will see ItemRegistry._utils[\"my_func\"](args...) instead of calling the function directly. Modifying connection All the properties such as protocol, ip, etc, can be changed at the .env file. Do not share that file with anyone , it gives access to executing remote code to your machine. For configuring this file you must create a RabbitMQ user by using the following commands: # Add a new user sudo rabbitmqctl add_user <USER> <PASSWORD> # Giving access to the client sudo rabbitmqctl set_user_tags <USER> administrator sudo rabbitmqctl set_permissions -p / <USER> \".*\" \".*\" \".*\"","title":"ECM Server/Client"},{"location":"Remote-Execution/#ecm-serverclient","text":"The ECM algorithms designed in this repository are aimed to be executed remotely, this is, to have a computer or machine that reasons, loads and computes all the cognitive layers ($A_1$) and a client machine that listens and executes all the functions sent by the server ($A_2$), this can be easily activated without affecting the core architecture by using the modules integrated in this repository. The Client/Server modules use RabbitMQ in order to stablish a connection between the two machines, to start this protocol you only need to start listening with the client as follows: import action_space.experimental.mouse.actions # noqa import action_space.experimental.screenshot.actions # noqa from ecm.remote.client import EcmClient if __name__ == \"__main__\": client = EcmClient() client.listen() Note that we must import the actions we want to be enabled in the client machine in order to be auto-detected when received from the server. Warning: If the client is not connected, the server will fail when trying to send the correspondent action.","title":"ECM Server/Client"},{"location":"Remote-Execution/#synchronizing-the-itemregistry","text":"After having the client connected, we can use the ItemRegistry to send tasks to the client. For using the ItemRegistry appropriately you must differentiate between two types of capabilites: Registering Functions : This is the base function for sending actions to the client. When loading AI agents, the names of this functions and multiple descriptions on how to use them are loaded in order to let the AI decide when and why to send an action to the client. Registering an action can be done as follows: python @ItemRegistry.register_function def do_something(element: str): \"\"\"Does something using the element. Usage do_something('foo')\"\"\" ... Registering utils : Utils can be also sent to the client, though they won't be notified to the AI's, so you can use this tools to execute AI-hiden algorithms, such as taking screenshots for sending them to the AI, computing calculations, or obtaining information. This actions do not have to be AI-friendly. python @ItemRegistry.register_util def restart(arg1, arg2, arg3): ... Finally, if you want to use your functions in the host machine, just don't apply changes, in the contrary, if you want to execute utils or functions in the remote machine, use the following command to automatically synchronize with the client: # The actions my AI will find from action_space.experimental.mouse.agent import MouseAgent # noqa from ecm.tools.registry import ItemRegistry if __name__ == \"__main__\": ItemRegistry.transfer_execution_to_client() ... # execute your algorithms normally... Warning: ItemRegistryV2 has deprecated this function. The replaced function is EcmServer.wrap_item_registry() All the functions/utils will be sent to the client when trying to access them through the ItemRegistry. Warning: If you try to hard-access the functions without the ItemRegistry, they will be executed in the host machine. For this reason, multiple times you will see ItemRegistry._utils[\"my_func\"](args...) instead of calling the function directly.","title":"Synchronizing the ItemRegistry"},{"location":"Remote-Execution/#modifying-connection","text":"All the properties such as protocol, ip, etc, can be changed at the .env file. Do not share that file with anyone , it gives access to executing remote code to your machine. For configuring this file you must create a RabbitMQ user by using the following commands: # Add a new user sudo rabbitmqctl add_user <USER> <PASSWORD> # Giving access to the client sudo rabbitmqctl set_user_tags <USER> administrator sudo rabbitmqctl set_permissions -p / <USER> \".*\" \".*\" \".*\"","title":"Modifying connection"},{"location":"Rosa-Insights/","text":"Implementation of the Execution Layer Algorithm with ROSA ($A_2$) The Execution Layer Algorithm, sometimes designated as $A_2$, plays a crucial role in the Execution-Cognition Machine (ECM) architecture. Its primary function is to transform a set of actions selected by the Cognition Algorithm ($A_1$) into executable actions that result in solving the user's problem. $A_2$ is responsible for the execution of these actions, ensuring that they are carried out in an orderly and effective manner, adapting to the needs of the problem and the execution context. Implementation of $A_2$ Using SequenceActionServer and ROS2 (ROSA Approximation) For explaining the architecture of $A_2$ internals, we begin with the setup of our ECM at a low level. Since the theoretical expansion of A' should be supported by the execution layer, the following TSP protocol is proposed. 2.3.1 Task-Sequence Protocol (TSP) Let's imagine the simplest case, suppose a problem ( p \u2208 P ) could be solved with a single action, such as pressing the letter \"K\" key in the keyboard. The Task-Sequence Protocol (PTS) encapsulates this action in an object called ActionPackage . An ActionPackage consists of two key elements: Function : Reference to our action ( b \u2208 B ), such as a keystroke. Note how this function can be passed to the ActionPackage by using the ItemRegistry. Just ensure to register the function with the appropiate decorator and then pass the id to the package. Arguments : Here you can pass details relevant to the action, such as the specific key \"K\". These arguments can be passed as args or kwargs After we are able to make actions. We want to be able to combine them in further ways, such as compositing, so we archive the A' expansion property. For this, using ROS2 Behavior Trees (BT) directly in our ECM would be impractical, as it would force the LLM to build an XML and a set of unnecessary components. Instead, we use an approach based on SequencePackages . A SequencePackage is a set of actions with behavior defined by the SequenceType , which determines whether the actions should be executed in parallel, linearly, conditionally, etc. This allows for the efficient execution of the keystroke action \"K\". When multiple sequences are related to achieving the same objective, they are encapsulated in what is called a Task . A task is a set of related sequences, ordered by priority (defined in each sequence individually). This allows the system to generate more complex plans that include concurrent action execution and even mechanisms for feedback, interruption, or sequence succession in a straightforward manner for the LLM. Although it is possible to send the task directly to the TaskRegistry controller, we will show a cleaner way to manage tasks with ROSA, so by now, just focus on on the how the priority of the task can affect the execution of the plan. SequenceActionServer vs ROSA The SequenceActionServer or SAS (also called IODA as a deprecated name) is responsible for converting requests from higher levels into executable actions for the Gateway using the TSP. It's crucial to remember the separation of responsibilities at higher and lower levels: ROSA : This layer is an interface for building request as a set of actions to be executed. SAS and Lower Levels : These are responsible for HOW to execute those actions, given a plan. Within the question of how to execute a plan given by a higher level, we find different problems to solve, differentiated into 3 modules represented in the following diagram: ROS2 Topics : Using the communication functionalities offered by ROS2, we encapsulate all the Tasks from higher levels in JSON format, which can be read asynchronously through callbacks in the ActionClient (ROS2 Actions). In this way, all tasks will be published in the /resquest topic, while the feedback will be returned in /feedback SequenceActionClient : Also known as \"Request Responder,\" it reads the requests published on the topics and applies the TSP protocol to define which behavior to execute next (interrupt, execute, put on hold, etc.). For each sequence it decides to start, it will receive feedback produced and forward it to higher levels for processing. Responsibility: Define WHEN to execute each sequence. SequenceActionServer : Also known as \"Request Controller,\" it receives sequences sent by the client and executes without the ability to cancel. Its responsibility is to define the type of execution according to the task's topology and its possible BT actions. Responsibility: Define WHO to call to execute the sequence. SequenceTypes : Encapsulated within the \"Request Controller\" in the general diagram, it is responsible for defining the order and conditions of execution for each received sequence. Responsibility: Define HOW to execute the received sequence. UPI Listener : Not shown in Figure 8, it is responsible for receiving asynchronous user requests sent from the UPI in the hardware-layer and sending them directly to higher layers via the ROS2 topics. Its response will be received in the same way as the rest of the sequences, with a different priority if necessary. 2.4 ROSA and ALB In the previous sections, we have discussed the mechanism to implement a ECM at a low level. However, due to its complexity and level of abstraction, ROSA (ROS Agent) was created. ROSA serves as an interface that simplifies the entire TSP into a set of simple functions to be executed by higher layers. This means it converts the rest of the objects into ROS2-Agnostic, eliminating the restrictions caused by dependency among these components. ROSA effectively turns the entire system below it into a black-box model that EXECUTES the sent commands. On the other hand, (although is not necessary to interact with) to eliminate concurrency issues and the linking of functions from lower levels to higher levels, the ALB (Application Layer Builder) is responsible for launching all ROS2 nodes and maintaining the resources used within the same memory space of a single process (multithreaded). Thus, a set of objects created by different layers can be accessed without the need to use pipelines or alternative methods to the system. The ALB will be managed by ROSA so the user doesn't have to interact with ROS2 nodes.","title":"Implementation of the Execution Layer Algorithm with ROSA ($A_2$)"},{"location":"Rosa-Insights/#implementation-of-the-execution-layer-algorithm-with-rosa-a_2","text":"The Execution Layer Algorithm, sometimes designated as $A_2$, plays a crucial role in the Execution-Cognition Machine (ECM) architecture. Its primary function is to transform a set of actions selected by the Cognition Algorithm ($A_1$) into executable actions that result in solving the user's problem. $A_2$ is responsible for the execution of these actions, ensuring that they are carried out in an orderly and effective manner, adapting to the needs of the problem and the execution context.","title":"Implementation of the Execution Layer Algorithm with ROSA ($A_2$)"},{"location":"Rosa-Insights/#implementation-of-a_2-using-sequenceactionserver-and-ros2-rosa-approximation","text":"For explaining the architecture of $A_2$ internals, we begin with the setup of our ECM at a low level. Since the theoretical expansion of A' should be supported by the execution layer, the following TSP protocol is proposed.","title":"Implementation of $A_2$ Using SequenceActionServer and ROS2 (ROSA Approximation)"},{"location":"Rosa-Insights/#231-task-sequence-protocol-tsp","text":"Let's imagine the simplest case, suppose a problem ( p \u2208 P ) could be solved with a single action, such as pressing the letter \"K\" key in the keyboard. The Task-Sequence Protocol (PTS) encapsulates this action in an object called ActionPackage . An ActionPackage consists of two key elements: Function : Reference to our action ( b \u2208 B ), such as a keystroke. Note how this function can be passed to the ActionPackage by using the ItemRegistry. Just ensure to register the function with the appropiate decorator and then pass the id to the package. Arguments : Here you can pass details relevant to the action, such as the specific key \"K\". These arguments can be passed as args or kwargs After we are able to make actions. We want to be able to combine them in further ways, such as compositing, so we archive the A' expansion property. For this, using ROS2 Behavior Trees (BT) directly in our ECM would be impractical, as it would force the LLM to build an XML and a set of unnecessary components. Instead, we use an approach based on SequencePackages . A SequencePackage is a set of actions with behavior defined by the SequenceType , which determines whether the actions should be executed in parallel, linearly, conditionally, etc. This allows for the efficient execution of the keystroke action \"K\". When multiple sequences are related to achieving the same objective, they are encapsulated in what is called a Task . A task is a set of related sequences, ordered by priority (defined in each sequence individually). This allows the system to generate more complex plans that include concurrent action execution and even mechanisms for feedback, interruption, or sequence succession in a straightforward manner for the LLM. Although it is possible to send the task directly to the TaskRegistry controller, we will show a cleaner way to manage tasks with ROSA, so by now, just focus on on the how the priority of the task can affect the execution of the plan.","title":"2.3.1 Task-Sequence Protocol (TSP)"},{"location":"Rosa-Insights/#sequenceactionserver-vs-rosa","text":"The SequenceActionServer or SAS (also called IODA as a deprecated name) is responsible for converting requests from higher levels into executable actions for the Gateway using the TSP. It's crucial to remember the separation of responsibilities at higher and lower levels: ROSA : This layer is an interface for building request as a set of actions to be executed. SAS and Lower Levels : These are responsible for HOW to execute those actions, given a plan. Within the question of how to execute a plan given by a higher level, we find different problems to solve, differentiated into 3 modules represented in the following diagram: ROS2 Topics : Using the communication functionalities offered by ROS2, we encapsulate all the Tasks from higher levels in JSON format, which can be read asynchronously through callbacks in the ActionClient (ROS2 Actions). In this way, all tasks will be published in the /resquest topic, while the feedback will be returned in /feedback SequenceActionClient : Also known as \"Request Responder,\" it reads the requests published on the topics and applies the TSP protocol to define which behavior to execute next (interrupt, execute, put on hold, etc.). For each sequence it decides to start, it will receive feedback produced and forward it to higher levels for processing. Responsibility: Define WHEN to execute each sequence. SequenceActionServer : Also known as \"Request Controller,\" it receives sequences sent by the client and executes without the ability to cancel. Its responsibility is to define the type of execution according to the task's topology and its possible BT actions. Responsibility: Define WHO to call to execute the sequence. SequenceTypes : Encapsulated within the \"Request Controller\" in the general diagram, it is responsible for defining the order and conditions of execution for each received sequence. Responsibility: Define HOW to execute the received sequence. UPI Listener : Not shown in Figure 8, it is responsible for receiving asynchronous user requests sent from the UPI in the hardware-layer and sending them directly to higher layers via the ROS2 topics. Its response will be received in the same way as the rest of the sequences, with a different priority if necessary.","title":"SequenceActionServer vs ROSA"},{"location":"Rosa-Insights/#24-rosa-and-alb","text":"In the previous sections, we have discussed the mechanism to implement a ECM at a low level. However, due to its complexity and level of abstraction, ROSA (ROS Agent) was created. ROSA serves as an interface that simplifies the entire TSP into a set of simple functions to be executed by higher layers. This means it converts the rest of the objects into ROS2-Agnostic, eliminating the restrictions caused by dependency among these components. ROSA effectively turns the entire system below it into a black-box model that EXECUTES the sent commands. On the other hand, (although is not necessary to interact with) to eliminate concurrency issues and the linking of functions from lower levels to higher levels, the ALB (Application Layer Builder) is responsible for launching all ROS2 nodes and maintaining the resources used within the same memory space of a single process (multithreaded). Thus, a set of objects created by different layers can be accessed without the need to use pipelines or alternative methods to the system. The ALB will be managed by ROSA so the user doesn't have to interact with ROS2 nodes.","title":"2.4 ROSA and ALB"},{"location":"Self%E2%80%90Training-Agents/","text":"Introduction In the paper Self-Trained Agents a research about training agents with an iterative mechanism is explored. As its fundamentals, the main process is to fine-tune an LLM by forcing it to reason about its world, correcting it and fine-tuning the agent with its own outputs. By using this process, we are able to fine-tune an agent without using a human generated. In this repository we will take use of this methodology in order to fine-tune the Cognition Layer ($A_1$) Agents in order to minimize the costs, delay and empower the reasoning capabilities of LLMs. Specialization Architecture At the specialization.py module we can find a simple AI graph to implement Self-Training. This module can be used in order to generate samples (for a bigger dataset) that ensures the reasoning about a task is successful. The main algorithm uses the following steps: Try : Receive the task from the user as a prompt, it then tries to generate an action that solves that query and predict the result that its action will generate in the user environment. Human: \"Open the firefox browser\" AI: { reasoning=\"The display...\" , action=\"open(\"Amazon\") , learning=None , expectation=\"The window will open\" } Test : An effect_descriptor object is passed to the AI, this descriptor will be responsible of generating a description of the latests effects in the AI environment. With this description, the AI reasons if the expectation has been completed, and if so, the last reasoning will be returned for saving it as a sample. Learn : If the test has failed, then the AI tries to generate new learnings, reasoning about its failures and how it could overcome it in the next iteration. Reset the environment and return to the try node. Try : Iterate over the steps 1 to 3 adding the learnings obtained from previous nodes to the prompt of the agent. An example usage of this module could be the following program: if __name__ == \"__main__\": # Build an executor (You could use for example RosaInterpreter...) def test(query): result = execute(query) return result # Build the graph graph = SpecializationGraph( action_prompt=\"You are an AI computer expert. You must provide...\", test=test, effect_descriptor=lambda: describe_environment(), reset_state=lambda: reset_my_env(), ).compile() # Execute the graph and obtain a sample user_input = \"I want to do foo\" config = {\"configurable\": {\"thread_id\": str(random.randint(5000, 15000))}} for event in graph.stream({\"query\": user_input}, config, stream_mode=\"values\"): print(\"=\" * 30) print(Fore.YELLOW + json.dumps(event, indent=4) + Fore.RESET) Self-Training Architecture At the specialization.py module you can find an alternative implementation of the previous architecture. In this case, we focus on improving the testing methods and making the architecture as an ubiquitous one. The main steps are the followng: Try : Calls a function that will act emulating the \"try\" node of the Specialization graph, thus if the goal is to generate actions, the function will receive the user query, the learnings and previous failures in order to generate an action (function response) Execute : Calls a function that executes the action provided from the try node. In contrast with the specialization graph, the learn function must have a form to obtain the real solution of the query, if the solution is not correct, the learn node will be called. Also, if the maximum iterations of the agent have been reached, it will also fail, enabling to retry a new reasoning from the begging. Learn : Calls a function that contains generates a reasoning about what have failed and how it can be solved in posterior steps. The same architecture as in Specialization graph is used from now on. An example usage of this module could be the following program: if __name__ == \"__main__\": # Build the graph graph = SelfTrainGraph( agent=lambda input: agent_reason(input), response_executor=lambda agent_output: execute(agent_output), test_approval=lambda execution_response: check(execution_response, expected), learner=lamda graph_status: agent_generate_learnings(graph_status), max_iterations=4, # If it fails more than 4 times exit. ).compile() # Run the graph user_input = \"...\" for event in graph.stream( {\"query\": user_input, \"success\": False, \"current_iterations\": 0}, stream_mode=\"values\", ): result = event # Return sample return TrainingResponse( iterations=result[\"current_iterations\"], output=json.loads(result[\"response\"])[\"reasoning\"], success=result[\"success\"], )","title":"Introduction"},{"location":"Self%E2%80%90Training-Agents/#introduction","text":"In the paper Self-Trained Agents a research about training agents with an iterative mechanism is explored. As its fundamentals, the main process is to fine-tune an LLM by forcing it to reason about its world, correcting it and fine-tuning the agent with its own outputs. By using this process, we are able to fine-tune an agent without using a human generated. In this repository we will take use of this methodology in order to fine-tune the Cognition Layer ($A_1$) Agents in order to minimize the costs, delay and empower the reasoning capabilities of LLMs.","title":"Introduction"},{"location":"Self%E2%80%90Training-Agents/#specialization-architecture","text":"At the specialization.py module we can find a simple AI graph to implement Self-Training. This module can be used in order to generate samples (for a bigger dataset) that ensures the reasoning about a task is successful. The main algorithm uses the following steps: Try : Receive the task from the user as a prompt, it then tries to generate an action that solves that query and predict the result that its action will generate in the user environment. Human: \"Open the firefox browser\" AI: { reasoning=\"The display...\" , action=\"open(\"Amazon\") , learning=None , expectation=\"The window will open\" } Test : An effect_descriptor object is passed to the AI, this descriptor will be responsible of generating a description of the latests effects in the AI environment. With this description, the AI reasons if the expectation has been completed, and if so, the last reasoning will be returned for saving it as a sample. Learn : If the test has failed, then the AI tries to generate new learnings, reasoning about its failures and how it could overcome it in the next iteration. Reset the environment and return to the try node. Try : Iterate over the steps 1 to 3 adding the learnings obtained from previous nodes to the prompt of the agent. An example usage of this module could be the following program: if __name__ == \"__main__\": # Build an executor (You could use for example RosaInterpreter...) def test(query): result = execute(query) return result # Build the graph graph = SpecializationGraph( action_prompt=\"You are an AI computer expert. You must provide...\", test=test, effect_descriptor=lambda: describe_environment(), reset_state=lambda: reset_my_env(), ).compile() # Execute the graph and obtain a sample user_input = \"I want to do foo\" config = {\"configurable\": {\"thread_id\": str(random.randint(5000, 15000))}} for event in graph.stream({\"query\": user_input}, config, stream_mode=\"values\"): print(\"=\" * 30) print(Fore.YELLOW + json.dumps(event, indent=4) + Fore.RESET)","title":"Specialization Architecture"},{"location":"Self%E2%80%90Training-Agents/#self-training-architecture","text":"At the specialization.py module you can find an alternative implementation of the previous architecture. In this case, we focus on improving the testing methods and making the architecture as an ubiquitous one. The main steps are the followng: Try : Calls a function that will act emulating the \"try\" node of the Specialization graph, thus if the goal is to generate actions, the function will receive the user query, the learnings and previous failures in order to generate an action (function response) Execute : Calls a function that executes the action provided from the try node. In contrast with the specialization graph, the learn function must have a form to obtain the real solution of the query, if the solution is not correct, the learn node will be called. Also, if the maximum iterations of the agent have been reached, it will also fail, enabling to retry a new reasoning from the begging. Learn : Calls a function that contains generates a reasoning about what have failed and how it can be solved in posterior steps. The same architecture as in Specialization graph is used from now on. An example usage of this module could be the following program: if __name__ == \"__main__\": # Build the graph graph = SelfTrainGraph( agent=lambda input: agent_reason(input), response_executor=lambda agent_output: execute(agent_output), test_approval=lambda execution_response: check(execution_response, expected), learner=lamda graph_status: agent_generate_learnings(graph_status), max_iterations=4, # If it fails more than 4 times exit. ).compile() # Run the graph user_input = \"...\" for event in graph.stream( {\"query\": user_input, \"success\": False, \"current_iterations\": 0}, stream_mode=\"values\", ): result = event # Return sample return TrainingResponse( iterations=result[\"current_iterations\"], output=json.loads(result[\"response\"])[\"reasoning\"], success=result[\"success\"], )","title":"Self-Training Architecture"},{"location":"SimpleCognitiveMemory/","text":"SimpleCognitiveMemory Documentation The SimpleCognitiveMemory is a lightweight class designed to simplify the management of memory for AI systems, particularly when interacting with LLMs. It handles message storage, automatic pruning of old messages, preservation of important prompts, and optional removal of images to optimize token usage. Key Features Capacity Management : Automatically discards older messages when capacity is exceeded. Preservation of Crucial Messages : Allows preservation of initial messages, such as LLM instructions or initial prompts. Image Pruning : Optionally removes images from messages to reduce the number of tokens and lower memory usage. Initializing You can create an instance of SimpleCognitiveMemory by specifying: - capacity : The maximum number of messages to store (default is 5). - keep_images : Whether to keep image URLs in messages (default is True ). - preserve : A list of messages to be preserved and never pruned (e.g., initial instructions). from cognition_layer.memory.simple import SimpleCognitiveMemory memory = SimpleCognitiveMemory(capacity=10, keep_images=False) Preserving Important Messages To ensure that critical messages like initial prompts or instructions are never discarded, use the preserve parameter: from cognition_layer.memory.simple import SimpleCognitiveMemory from langchain_core.messages import SystemMessage initial_instructions = [SystemMessage(content=\"Follow these rules strictly. [...]\")] memory = SimpleCognitiveMemory(capacity=10, preserve=initial_instructions) Note : The total number of preserved messages cannot exceed the specified capacity. Updating Memory with New Messages To add new messages to the memory: from langchain_core.messages import HumanMessage new_messages = [HumanMessage(content=\"What is the weather today?\")] memory.update(new_messages) Older messages will be automatically removed when the capacity limit is reached. Removing Images Automatically If you want to minimize the token cost by removing images from the memory buffer, set keep_images to False during initialization: memory = SimpleCognitiveMemory(capacity=10, keep_images=False) Alternatively, you can prune images from the messages manually using the utility function: from cognition_layer.memory.simple import prune_images_from_messages prune_images_from_messages(memory.messages) Retrieving Messages Access the current state of memory using the messages property. This will include both preserved and regular messages: all_messages = memory.messages Example Usage from cognition_layer.memory.simple import SimpleCognitiveMemory from langchain_core.messages import SystemMessage, AIMessage, HumanMessage # Initialize memory with capacity and preserved instructions instructions = [SystemMessage(content=\"You are a helpful assistant.\")] memory = SimpleCognitiveMemory(capacity=5, preserve=instructions, keep_images=False) # Update memory with new messages memory.update([AIMessage(content=\"Hello, how can I assist you today?\")]) memory.update([HumanMessage(content=\"What's the weather today?\")]) # Retrieve all stored messages for msg in memory.messages: print(msg.content) Conclusion The SimpleCognitiveMemory class simplifies memory handling for LLMs by: - Automatically managing capacity and removing old messages. - Preserving crucial prompts or instructions. - Optionally reducing memory cost by removing images. This makes it ideal for efficient and scalable LLM-based applications where memory management and token optimization are critical.","title":"SimpleCognitiveMemory Documentation"},{"location":"SimpleCognitiveMemory/#simplecognitivememory-documentation","text":"The SimpleCognitiveMemory is a lightweight class designed to simplify the management of memory for AI systems, particularly when interacting with LLMs. It handles message storage, automatic pruning of old messages, preservation of important prompts, and optional removal of images to optimize token usage.","title":"SimpleCognitiveMemory Documentation"},{"location":"SimpleCognitiveMemory/#key-features","text":"Capacity Management : Automatically discards older messages when capacity is exceeded. Preservation of Crucial Messages : Allows preservation of initial messages, such as LLM instructions or initial prompts. Image Pruning : Optionally removes images from messages to reduce the number of tokens and lower memory usage.","title":"Key Features"},{"location":"SimpleCognitiveMemory/#initializing","text":"You can create an instance of SimpleCognitiveMemory by specifying: - capacity : The maximum number of messages to store (default is 5). - keep_images : Whether to keep image URLs in messages (default is True ). - preserve : A list of messages to be preserved and never pruned (e.g., initial instructions). from cognition_layer.memory.simple import SimpleCognitiveMemory memory = SimpleCognitiveMemory(capacity=10, keep_images=False)","title":"Initializing"},{"location":"SimpleCognitiveMemory/#preserving-important-messages","text":"To ensure that critical messages like initial prompts or instructions are never discarded, use the preserve parameter: from cognition_layer.memory.simple import SimpleCognitiveMemory from langchain_core.messages import SystemMessage initial_instructions = [SystemMessage(content=\"Follow these rules strictly. [...]\")] memory = SimpleCognitiveMemory(capacity=10, preserve=initial_instructions) Note : The total number of preserved messages cannot exceed the specified capacity.","title":"Preserving Important Messages"},{"location":"SimpleCognitiveMemory/#updating-memory-with-new-messages","text":"To add new messages to the memory: from langchain_core.messages import HumanMessage new_messages = [HumanMessage(content=\"What is the weather today?\")] memory.update(new_messages) Older messages will be automatically removed when the capacity limit is reached.","title":"Updating Memory with New Messages"},{"location":"SimpleCognitiveMemory/#removing-images-automatically","text":"If you want to minimize the token cost by removing images from the memory buffer, set keep_images to False during initialization: memory = SimpleCognitiveMemory(capacity=10, keep_images=False) Alternatively, you can prune images from the messages manually using the utility function: from cognition_layer.memory.simple import prune_images_from_messages prune_images_from_messages(memory.messages)","title":"Removing Images Automatically"},{"location":"SimpleCognitiveMemory/#retrieving-messages","text":"Access the current state of memory using the messages property. This will include both preserved and regular messages: all_messages = memory.messages","title":"Retrieving Messages"},{"location":"SimpleCognitiveMemory/#example-usage","text":"from cognition_layer.memory.simple import SimpleCognitiveMemory from langchain_core.messages import SystemMessage, AIMessage, HumanMessage # Initialize memory with capacity and preserved instructions instructions = [SystemMessage(content=\"You are a helpful assistant.\")] memory = SimpleCognitiveMemory(capacity=5, preserve=instructions, keep_images=False) # Update memory with new messages memory.update([AIMessage(content=\"Hello, how can I assist you today?\")]) memory.update([HumanMessage(content=\"What's the weather today?\")]) # Retrieve all stored messages for msg in memory.messages: print(msg.content)","title":"Example Usage"},{"location":"SimpleCognitiveMemory/#conclusion","text":"The SimpleCognitiveMemory class simplifies memory handling for LLMs by: - Automatically managing capacity and removing old messages. - Preserving crucial prompts or instructions. - Optionally reducing memory cost by removing images. This makes it ideal for efficient and scalable LLM-based applications where memory management and token optimization are critical.","title":"Conclusion"},{"location":"System-Architecture-Overview/","text":"System Architecture Overview The architecture for an Execution-Cognition Machine (ECM) is modeled after understanding the necessary theory to implement it. This documentation aims to detail the system's general architecture by revisiting the formal definition of an ECM. The ECM implementation requires two algorithms that meet specific criteria to effectively translate a user's problem into executable actions using the knowledge integrated into a Large Language Model (LLM). Thus, as the formal conclusion of the theoretical approximation stated, we are seaching for two algorithms that satisfy: Algorithm_1(p | C') = \u03bb | \u03bb \u2282 A' \u2227 Algorithm_2(\u03bb) = s In this way, the ECM architecture contains: Cognition Algorithm (A1) : This algorithm translates a problem ( p ) using the knowledge from an LLM ( C' ) into a subset of actions ( A' ) within a defined action set ( A' ). It reflects the ECM's \"cognition\" aspect. Execution Algorithm (A2) : This algorithm takes the subset of actions ( A' ) and the problem ( p ) to produce a solution ( s' ). Since ( C' ) does not directly influence ( s' ), this algorithm can be simplified to ( A_2(p | A') = s' ). This reflects the \"execution\" aspect of the ECM. Architecture Components The ECM is designed to interconnect three key modules: \"Cognition\", \"Execution\", and \"Action Space\". The following diagram illustrates the proposed architecture and the interconnections between these modules: Detailed Architecture Explanation MCA (Main Core Agent) : This class is responsible for maintaining an event loop connecting all the main modules in the ECM. It is built with the rest of the modules with the CELB. Action Space (B') : This is where all possible actions that the system can perform are defined. It serves as the foundational layer from which the Cognition Algorithm selects a subset of actions ( A' ). Cognition Space(A_1) : This module processes the user-defined problem ( p ) using the integrated knowledge ( C' ) from the LLM (taking advantage of AutoGPT capabilities) to determine the appropriate actions ( A' ) from the Action Space. The output is a refined set of actions tailored to solve the problem expressed in an Exelent File. Note that all the system should be agnostic to the changes into the cognitive agent thanks to the AgentProtocol (acting as a mediator). Execution Space(A_2) : Once the subset of actions ( A' ) is identified, this module takes over to execute these actions to achieve the desired outcome ( s' ). It operates independently of the integrated knowledge ( C' ), focusing solely on action implementation. As the moment of writing this, the responsible class for doing this is ROSA, however the implementation should be easily changed by using the mediator. Interpreter : As a middleware betwwwn A_1 and A_2, the interpreter is the class responsible for translating the specifications written in the Exelent file from the Cognitive Module into a set of objects/commands. If the Exelent file contains a set of plugins, this should be handled too by the interpreter, returning some actions to be resolved to the MCA. ECMv2 Architecture Expansion In the realm of artificial intelligence, the trend towards multi-agent systems reflects a move towards more distributed and specialized processing. Expert Agents are specialized entities designed to handle specific tasks or domains, such as gaming or data analysis, with greater efficiency and expertise than a general agent could. This specialization allows for a more scalable system that can adapt and respond more dynamically to complex environments or specific user requirements. For this reason, the version V2 of the ECM aims to expand the action space ( A' ) without the need of more pre-composition or programming of each action. This concept stems from the current trend towards multi-agent architectures , where the main agent delegates the cognitive burden to specialized agents referred to as Expert Agents. In this context, the Exelent language will now need to incorporate new statements that define a set of new requests from the cognition space. These requests will be forwarded by the Main Core Agent (MCA) to the appropriate Expert Agents. For instance, if the task involves playing a video game, instead of burdening the cognition space with this task, it could redirect the request to an agent specialized in gaming. Notably, through the use of the AgentProtocol, we can employ the same interface as a mediator to maintain system stability and prevent modifications that could negatively impact the performance or functionality of the architecture. This ensures that any integration of new agents or capabilities remains plug and play, adhering to the established system architecture without disruptive changes. With this, ECMv2's design philosophy enhances the system's adaptability and scalability by leveraging specialized expertise and maintaining a modular, plug-and-play approach through standardized protocols. This ensures that as the demands of tasks evolve, the architecture can easily integrate new capabilities without losing efficiency or operability.","title":"System Architecture Overview"},{"location":"System-Architecture-Overview/#system-architecture-overview","text":"The architecture for an Execution-Cognition Machine (ECM) is modeled after understanding the necessary theory to implement it. This documentation aims to detail the system's general architecture by revisiting the formal definition of an ECM. The ECM implementation requires two algorithms that meet specific criteria to effectively translate a user's problem into executable actions using the knowledge integrated into a Large Language Model (LLM). Thus, as the formal conclusion of the theoretical approximation stated, we are seaching for two algorithms that satisfy: Algorithm_1(p | C') = \u03bb | \u03bb \u2282 A' \u2227 Algorithm_2(\u03bb) = s In this way, the ECM architecture contains: Cognition Algorithm (A1) : This algorithm translates a problem ( p ) using the knowledge from an LLM ( C' ) into a subset of actions ( A' ) within a defined action set ( A' ). It reflects the ECM's \"cognition\" aspect. Execution Algorithm (A2) : This algorithm takes the subset of actions ( A' ) and the problem ( p ) to produce a solution ( s' ). Since ( C' ) does not directly influence ( s' ), this algorithm can be simplified to ( A_2(p | A') = s' ). This reflects the \"execution\" aspect of the ECM.","title":"System Architecture Overview"},{"location":"System-Architecture-Overview/#architecture-components","text":"The ECM is designed to interconnect three key modules: \"Cognition\", \"Execution\", and \"Action Space\". The following diagram illustrates the proposed architecture and the interconnections between these modules:","title":"Architecture Components"},{"location":"System-Architecture-Overview/#detailed-architecture-explanation","text":"MCA (Main Core Agent) : This class is responsible for maintaining an event loop connecting all the main modules in the ECM. It is built with the rest of the modules with the CELB. Action Space (B') : This is where all possible actions that the system can perform are defined. It serves as the foundational layer from which the Cognition Algorithm selects a subset of actions ( A' ). Cognition Space(A_1) : This module processes the user-defined problem ( p ) using the integrated knowledge ( C' ) from the LLM (taking advantage of AutoGPT capabilities) to determine the appropriate actions ( A' ) from the Action Space. The output is a refined set of actions tailored to solve the problem expressed in an Exelent File. Note that all the system should be agnostic to the changes into the cognitive agent thanks to the AgentProtocol (acting as a mediator). Execution Space(A_2) : Once the subset of actions ( A' ) is identified, this module takes over to execute these actions to achieve the desired outcome ( s' ). It operates independently of the integrated knowledge ( C' ), focusing solely on action implementation. As the moment of writing this, the responsible class for doing this is ROSA, however the implementation should be easily changed by using the mediator. Interpreter : As a middleware betwwwn A_1 and A_2, the interpreter is the class responsible for translating the specifications written in the Exelent file from the Cognitive Module into a set of objects/commands. If the Exelent file contains a set of plugins, this should be handled too by the interpreter, returning some actions to be resolved to the MCA.","title":"Detailed Architecture Explanation"},{"location":"System-Architecture-Overview/#ecmv2-architecture-expansion","text":"In the realm of artificial intelligence, the trend towards multi-agent systems reflects a move towards more distributed and specialized processing. Expert Agents are specialized entities designed to handle specific tasks or domains, such as gaming or data analysis, with greater efficiency and expertise than a general agent could. This specialization allows for a more scalable system that can adapt and respond more dynamically to complex environments or specific user requirements. For this reason, the version V2 of the ECM aims to expand the action space ( A' ) without the need of more pre-composition or programming of each action. This concept stems from the current trend towards multi-agent architectures , where the main agent delegates the cognitive burden to specialized agents referred to as Expert Agents. In this context, the Exelent language will now need to incorporate new statements that define a set of new requests from the cognition space. These requests will be forwarded by the Main Core Agent (MCA) to the appropriate Expert Agents. For instance, if the task involves playing a video game, instead of burdening the cognition space with this task, it could redirect the request to an agent specialized in gaming. Notably, through the use of the AgentProtocol, we can employ the same interface as a mediator to maintain system stability and prevent modifications that could negatively impact the performance or functionality of the architecture. This ensures that any integration of new agents or capabilities remains plug and play, adhering to the established system architecture without disruptive changes. With this, ECMv2's design philosophy enhances the system's adaptability and scalability by leveraging specialized expertise and maintaining a modular, plug-and-play approach through standardized protocols. This ensures that as the demands of tasks evolve, the architecture can easily integrate new capabilities without losing efficiency or operability.","title":"ECMv2 Architecture Expansion"},{"location":"Theoretical-Fundamentals/","text":"Problem Analysis and Theoretical Approach With the objectives established at the Introduction chapter, our focus initially is on addressing each of these objectives individually. This involves connecting LLMs (Large Language Models) to a standard user, defined as someone lacking programming skills and familiarity with non-standard software tools beyond graphical applications like office tools. This suggests developing a \"black box\" approach regarding both the user and the LLM itself. The AGI's Problem For obtaining the objectives stablished, it is important to dive into the concept of AGI's. AGI's (Artificial General Intelligence) can understand, learn, and apply knowledge across a broad range of tasks, similarly to human intelligence. An AGI can theoretically perform any intellectual task that a human can do, applying its intelligence generally across different domains without specific training for each. Implementing an AGI is practically impossible ; however, we will approach the problem by axiomatizing that a human can solve any software problem p \u2208 P using a knowledge source C , and a set of actions A , such that: HumanSolution(p | C, A) = s Where s is the solution to problem p and is also a heuristically viable solution in a Turing machine environment. Definition of ECM's as an approximation to the AGI problem We can approximate the problem by considering the knowledge of an LLM as C' \u2248 C , i.e., an estimator of human knowledge; and the set of programmable actions as A' \u2248 A , i.e., an estimator of the action space to solve p . Therefore, the creation of an AGI implies designing an algorithm that verifies the following equality: Algorithm_1(p | C', A') = s Finally, since C' is already integrated knowledge in LLMs by definition and fully accessible, we only need to design an architecture that acts as an intermediary between the knowledge C' and our problem p to achieve a set of actions A' . Execution of A' should reach our solution s , verifying the following equality: Algorithm_1(p | C') = \u03bb | \u03bb \u2282 A' \u2227 Algorithm_2(\u03bb) = s From now on, we will refer the Algorithm_1 or A_1 as the Cognitive Layer of the problem, where the objective is given a set of actions A', obtain the set of actions \u03bb \u2208 A' that solve the problem; and we will refer the Algorithm_2 or A_2 as the Execution_Layer of the problem, where the objective is given a set of actions \u03bb, execute them in order to reach the solution s. Objectives Simplified The problem of \"how to implement an AGI\" is now simplified into three subproblems: 1. Send the user's problem request p into a query q that the LLM can understand q' . 2. Convert the LLM's natural language response into a set of executable actions \u03bb \u2208 A' . 3. Execute the set of actions \u03bb . This approach is underpinned by the philosophy: \"If a human can solve it, then an LLM should also be able to\". With this idea in mind, we will refer to the implementation of an architecture that accomplish the properties stablished as an Execution-Cognitive Machine or ECM AutoGPT in relation with AGI's Problem AutoGPT is a Python library that uses AI Agents based on the Memory-Profile-Planning-Action (PMPA) model discussed in this paper. It allows programmers to implement agents connected via HTTP requests to GPT-OpenAI and similar models (e.g., LLAMA, even with local execution) easily and maintained by thousands of users collaboratively. A significant feature of this library is that it allows these agents to be equipped with a set of \"skills\" known as \"actions\" or \"abilities,\" with which the agent will know how to interact and thus call sections of code that the programmer must have previously implemented in the agent. The most powerful agent model implementing this technology is @evo.ninja, which successfully stands out for its abilities to solve software tasks/problems as shown in Figure 2 (use of files, I/O, CSV reading, and query resolution...). Despite the achievements by AutoGPT, this library is far from fully integrating our ECM, as its action space A' is a considerably small subset given the set of problems p \u2208 P , i.e., A' \u2248 A . Therefore, the goal of GU-S will be to extend the \"skills\" architecture of AutoGPT to one in line with a ETM. A' Expansion Method Given the AutoGPT AGI's problem, we define the A' Expansion as an alternative to better approach this problem. Before implementing the algorithm itself, we must establish the following axiom: Manually programming a set of actions A' for the entire subset P is not viable due to scalability issues. In simple terms, \"it is not feasible to program all possible actions and solutions that AutoGPT should use.\" Thus, GU-Systems proposes simplifying this problem to implementing a protocol with which to describe an Action Space B' robust enough so that the composition of actions in B generates a space A' \u2248 A . In robotics planning problems, this issue has previously been raised, where a widespread solution even today is the use of known as BehaviorTrees . These systems use a set of simple algorithms that can be combined to generate a virtually scalable action tree for any problem p . That is, BehaviorTrees provide us an easy solution to \"How to build complex plans with simple actions.\" Now we just need to determine WHICH will be these \"simple actions\" and determine if they are robust enough to reach a solution s' . Thus, our actions b \u2208 B are a set of commands and keystrokes (clicks, action on keyboard, etc.), and by combining these actions through a behavior tree, we can expand the action space B such that BT(B) \u2248 A' \u2248 A With this in mind, we have just made a significant approximation to the problem of ECMs, where we also obtain the following properties: The more generalist the set B , the greater the convergence of A' with respect to A The set of actions B is scalable at the programmer level The resolution of the problem p \u2208 P can be solved, regardless of the API or program with which it is interacting","title":"Theoretical Fundamentals"},{"location":"Theoretical-Fundamentals/#problem-analysis-and-theoretical-approach","text":"With the objectives established at the Introduction chapter, our focus initially is on addressing each of these objectives individually. This involves connecting LLMs (Large Language Models) to a standard user, defined as someone lacking programming skills and familiarity with non-standard software tools beyond graphical applications like office tools. This suggests developing a \"black box\" approach regarding both the user and the LLM itself.","title":"Problem Analysis and Theoretical Approach"},{"location":"Theoretical-Fundamentals/#the-agis-problem","text":"For obtaining the objectives stablished, it is important to dive into the concept of AGI's. AGI's (Artificial General Intelligence) can understand, learn, and apply knowledge across a broad range of tasks, similarly to human intelligence. An AGI can theoretically perform any intellectual task that a human can do, applying its intelligence generally across different domains without specific training for each. Implementing an AGI is practically impossible ; however, we will approach the problem by axiomatizing that a human can solve any software problem p \u2208 P using a knowledge source C , and a set of actions A , such that: HumanSolution(p | C, A) = s Where s is the solution to problem p and is also a heuristically viable solution in a Turing machine environment.","title":"The AGI's Problem"},{"location":"Theoretical-Fundamentals/#definition-of-ecms-as-an-approximation-to-the-agi-problem","text":"We can approximate the problem by considering the knowledge of an LLM as C' \u2248 C , i.e., an estimator of human knowledge; and the set of programmable actions as A' \u2248 A , i.e., an estimator of the action space to solve p . Therefore, the creation of an AGI implies designing an algorithm that verifies the following equality: Algorithm_1(p | C', A') = s Finally, since C' is already integrated knowledge in LLMs by definition and fully accessible, we only need to design an architecture that acts as an intermediary between the knowledge C' and our problem p to achieve a set of actions A' . Execution of A' should reach our solution s , verifying the following equality: Algorithm_1(p | C') = \u03bb | \u03bb \u2282 A' \u2227 Algorithm_2(\u03bb) = s From now on, we will refer the Algorithm_1 or A_1 as the Cognitive Layer of the problem, where the objective is given a set of actions A', obtain the set of actions \u03bb \u2208 A' that solve the problem; and we will refer the Algorithm_2 or A_2 as the Execution_Layer of the problem, where the objective is given a set of actions \u03bb, execute them in order to reach the solution s.","title":"Definition of ECM's as an approximation to the AGI problem"},{"location":"Theoretical-Fundamentals/#objectives-simplified","text":"The problem of \"how to implement an AGI\" is now simplified into three subproblems: 1. Send the user's problem request p into a query q that the LLM can understand q' . 2. Convert the LLM's natural language response into a set of executable actions \u03bb \u2208 A' . 3. Execute the set of actions \u03bb . This approach is underpinned by the philosophy: \"If a human can solve it, then an LLM should also be able to\". With this idea in mind, we will refer to the implementation of an architecture that accomplish the properties stablished as an Execution-Cognitive Machine or ECM","title":"Objectives Simplified"},{"location":"Theoretical-Fundamentals/#autogpt-in-relation-with-agis-problem","text":"AutoGPT is a Python library that uses AI Agents based on the Memory-Profile-Planning-Action (PMPA) model discussed in this paper. It allows programmers to implement agents connected via HTTP requests to GPT-OpenAI and similar models (e.g., LLAMA, even with local execution) easily and maintained by thousands of users collaboratively. A significant feature of this library is that it allows these agents to be equipped with a set of \"skills\" known as \"actions\" or \"abilities,\" with which the agent will know how to interact and thus call sections of code that the programmer must have previously implemented in the agent. The most powerful agent model implementing this technology is @evo.ninja, which successfully stands out for its abilities to solve software tasks/problems as shown in Figure 2 (use of files, I/O, CSV reading, and query resolution...). Despite the achievements by AutoGPT, this library is far from fully integrating our ECM, as its action space A' is a considerably small subset given the set of problems p \u2208 P , i.e., A' \u2248 A . Therefore, the goal of GU-S will be to extend the \"skills\" architecture of AutoGPT to one in line with a ETM.","title":"AutoGPT in relation with AGI's Problem"},{"location":"Theoretical-Fundamentals/#a-expansion-method","text":"Given the AutoGPT AGI's problem, we define the A' Expansion as an alternative to better approach this problem. Before implementing the algorithm itself, we must establish the following axiom: Manually programming a set of actions A' for the entire subset P is not viable due to scalability issues. In simple terms, \"it is not feasible to program all possible actions and solutions that AutoGPT should use.\" Thus, GU-Systems proposes simplifying this problem to implementing a protocol with which to describe an Action Space B' robust enough so that the composition of actions in B generates a space A' \u2248 A . In robotics planning problems, this issue has previously been raised, where a widespread solution even today is the use of known as BehaviorTrees . These systems use a set of simple algorithms that can be combined to generate a virtually scalable action tree for any problem p . That is, BehaviorTrees provide us an easy solution to \"How to build complex plans with simple actions.\" Now we just need to determine WHICH will be these \"simple actions\" and determine if they are robust enough to reach a solution s' . Thus, our actions b \u2208 B are a set of commands and keystrokes (clicks, action on keyboard, etc.), and by combining these actions through a behavior tree, we can expand the action space B such that BT(B) \u2248 A' \u2248 A With this in mind, we have just made a significant approximation to the problem of ECMs, where we also obtain the following properties: The more generalist the set B , the greater the convergence of A' with respect to A The set of actions B is scalable at the programmer level The resolution of the problem p \u2208 P can be solved, regardless of the API or program with which it is interacting","title":"A' Expansion Method"},{"location":"What-is-GU/","text":"\ud83c\udf10 What is GU-Systems? \ud83c\udf1f Introduction to Deep Learning Models In the vast landscape of Artificial Intelligence, terms like Llama , GPT-4 , and Gemini are more than just buzzwords. They represent state-of-the-art Deep Learning models , specifically Large Language Models (LLMs) trained with data from across the globe and powered by millions of parameters. These models are pioneering achievements that bring us closer to the utopia of intelligent machines with capabilities such as \"common sense\" and complex action planning that respond in seconds to queries processed on cloud-based servers. Despite having models that unlock groundbreaking technological properties, we are encumbered by significant hardware and software limitations: - Most devices lack the computational power needed to run these models locally. - There is no standard methodology for implementing \"intelligent algorithms\" across APIs, applications, or software tools, requiring AI engineers to intervene and adapt applications for enhanced behaviors. Current solutions like the AIs integrated into Microsoft Word, Canva, or Bing are impressive but just scratch the surface of what's possible. Our project\u2014codenamed GU-Systems (a nod to \"GatUniverse-Systems\" or \"Cat Universe Systems\")\u2014aims to revolutionize how we interact with and standardize AI technologies. GU-Systems is engineered to: - Democratize access : Make intelligent tools accessible to the average user, removing the need to \"search the internet for a specific tool\" for problem-solving. - Simplify AI integration : Help new generations of AI programmers by standardizing how intelligent algorithms are implemented across different projects. GU-Systems Objectives GU-Systems is focused on delivering a dual promise: 1. User Accessibility : Enabling average users to leverage the capabilities of LLMs in Autonomous Computer Interaction through an intuitive interface. 2. Software Community Empowerment : Facilitating the software community to standardize and implement new AI technologies effortlessly. How We Bridge the Gap GU-Systems is not just a device but a movement to standardize and simplify the integration and scaling of AI technologies across various platforms. By providing a unified interface, we are not only enhancing user experience but are also paving the way for a future where AI can be more seamlessly integrated into daily applications.","title":"What is GU"},{"location":"What-is-GU/#what-is-gu-systems","text":"","title":"\ud83c\udf10 What is GU-Systems? \ud83c\udf1f"},{"location":"What-is-GU/#introduction-to-deep-learning-models","text":"In the vast landscape of Artificial Intelligence, terms like Llama , GPT-4 , and Gemini are more than just buzzwords. They represent state-of-the-art Deep Learning models , specifically Large Language Models (LLMs) trained with data from across the globe and powered by millions of parameters. These models are pioneering achievements that bring us closer to the utopia of intelligent machines with capabilities such as \"common sense\" and complex action planning that respond in seconds to queries processed on cloud-based servers. Despite having models that unlock groundbreaking technological properties, we are encumbered by significant hardware and software limitations: - Most devices lack the computational power needed to run these models locally. - There is no standard methodology for implementing \"intelligent algorithms\" across APIs, applications, or software tools, requiring AI engineers to intervene and adapt applications for enhanced behaviors. Current solutions like the AIs integrated into Microsoft Word, Canva, or Bing are impressive but just scratch the surface of what's possible. Our project\u2014codenamed GU-Systems (a nod to \"GatUniverse-Systems\" or \"Cat Universe Systems\")\u2014aims to revolutionize how we interact with and standardize AI technologies. GU-Systems is engineered to: - Democratize access : Make intelligent tools accessible to the average user, removing the need to \"search the internet for a specific tool\" for problem-solving. - Simplify AI integration : Help new generations of AI programmers by standardizing how intelligent algorithms are implemented across different projects.","title":"Introduction to Deep Learning Models"},{"location":"What-is-GU/#gu-systems-objectives","text":"GU-Systems is focused on delivering a dual promise: 1. User Accessibility : Enabling average users to leverage the capabilities of LLMs in Autonomous Computer Interaction through an intuitive interface. 2. Software Community Empowerment : Facilitating the software community to standardize and implement new AI technologies effortlessly.","title":"GU-Systems Objectives"},{"location":"What-is-GU/#how-we-bridge-the-gap","text":"GU-Systems is not just a device but a movement to standardize and simplify the integration and scaling of AI technologies across various platforms. By providing a unified interface, we are not only enhancing user experience but are also paving the way for a future where AI can be more seamlessly integrated into daily applications.","title":"How We Bridge the Gap"},{"location":"Xplore-Insights/","text":"Introduction Implementation of the Cognition Layer Algorithm ($A_1$) with Xplore Xplore is a Graph-based agent that cycles into a loop focusing on describing, planning subgoals and reviewing or reacting to the current status by using the $A_2$ algorithm. It is a minimalist improvement of RePlan enhancing the reasoning capabilities by enforcing reasoning over the images obtained from the display. Design Insights Using LangGraph we can design a graph of agents that interacts with each other in order to obtain complex behaviors. The Xplore core graph is the following: General Planner : This agent is responsible for generating a general plan to satisfy a query. This plan will be generated as a set of strings (plan) with a description of the status of the system and a reasoning on how the plan could be solved. This reasoning contains 3 mandatory labels to complete: description : This ensures the agent reason about the current status of the system, identifying relevant properties such as which windows are open, the user OS, etc. reasoning : This label makes the agent reason about how the goal can be reached. plan : This label is where the plan (set of subgoals as strings) are shortly described following the previous reasoning. Subgoal Planner : This agent is responsible for generating an action or set of actions (with the names according to the actions registered in the action space) in order to satisfy a subgoal. This agent contains 2 mandatory labels: reasoning : A reasoning about what the user has requested and how that subgoal could be reached. steps : The set of actions to execute in order to complete the goal. Note we force the agent to reason again about the subgoal, since this subgoal could be not fully described, so this step reinforces the precission and accuracy of the action generated. Interpreter : This node is responsible of translating the set of actions generated by previous nodes into Exelent code that will be sent to $A_2$. When the interpreter has executed all the actions, it will return. Review Completed : This node is responsible for calling an agent that will receive an image of the previous status of the machine and a posterior status after executing all the actions generated. Then it will remove from the subgoal list those subgoals that have been already reached. If all subgoals have been completed, it ends the execution, else it sends all the subgoals to the subgoal planner. Vision Capabilities In contrast with Planex or RePlan , Xplore have vision capabilities to integrate images from the display into the reasoning. For reaching this, each node that executes in Xplore, is provided with a screenshot of the current status of the display. LLM's such as OpenAI GPT-4o model enable the possibility of passing this images as zero-shot prompts, enhancing the reasoning of the agent fully adapting to the multiple variables of different systems. An example screenshot passed to Xplore Results Key Advantages Adaptability : By using visual capabilities, xplore is able to adapt to multiple environments, taking care of the arrangement of the windows, buttons, etc. Target Aiming : Xplore uses both long-term and short-term planning for building the following actions. This awareness boosts the planning process by simplifying uncertain future status and focusing closer actions. Explainability : By reasoning after each step we can define why the agent selects each action and what is its pourpuse. Cause-Effect Aware : By reviewing the effects of each action the agent takes, makes the agent able to react to incorrect steps and correct the plan to a viable solution. Key Disadvantages Velocity : By reasoning and using visual capabilities in each action the velocity of each action has been reduced to 50s/task (aprox.). Backward Planning : The Agent can't recover from certain actions where the next subgoal cannot be completed without replanning all the task or adding correction subgoals. Hallucinations and Icon difficulties : Not all elements from the display are correctly interpreted from the agent, where visual icons, buttons or drawings are misunderstood. In the next video, we provide an example execution of Xplore. Video","title":"Introduction"},{"location":"Xplore-Insights/#introduction","text":"","title":"Introduction"},{"location":"Xplore-Insights/#implementation-of-the-cognition-layer-algorithm-a_1-with-xplore","text":"Xplore is a Graph-based agent that cycles into a loop focusing on describing, planning subgoals and reviewing or reacting to the current status by using the $A_2$ algorithm. It is a minimalist improvement of RePlan enhancing the reasoning capabilities by enforcing reasoning over the images obtained from the display.","title":"Implementation of the Cognition Layer Algorithm ($A_1$) with Xplore"},{"location":"Xplore-Insights/#design-insights","text":"Using LangGraph we can design a graph of agents that interacts with each other in order to obtain complex behaviors. The Xplore core graph is the following: General Planner : This agent is responsible for generating a general plan to satisfy a query. This plan will be generated as a set of strings (plan) with a description of the status of the system and a reasoning on how the plan could be solved. This reasoning contains 3 mandatory labels to complete: description : This ensures the agent reason about the current status of the system, identifying relevant properties such as which windows are open, the user OS, etc. reasoning : This label makes the agent reason about how the goal can be reached. plan : This label is where the plan (set of subgoals as strings) are shortly described following the previous reasoning. Subgoal Planner : This agent is responsible for generating an action or set of actions (with the names according to the actions registered in the action space) in order to satisfy a subgoal. This agent contains 2 mandatory labels: reasoning : A reasoning about what the user has requested and how that subgoal could be reached. steps : The set of actions to execute in order to complete the goal. Note we force the agent to reason again about the subgoal, since this subgoal could be not fully described, so this step reinforces the precission and accuracy of the action generated. Interpreter : This node is responsible of translating the set of actions generated by previous nodes into Exelent code that will be sent to $A_2$. When the interpreter has executed all the actions, it will return. Review Completed : This node is responsible for calling an agent that will receive an image of the previous status of the machine and a posterior status after executing all the actions generated. Then it will remove from the subgoal list those subgoals that have been already reached. If all subgoals have been completed, it ends the execution, else it sends all the subgoals to the subgoal planner.","title":"Design Insights"},{"location":"Xplore-Insights/#vision-capabilities","text":"In contrast with Planex or RePlan , Xplore have vision capabilities to integrate images from the display into the reasoning. For reaching this, each node that executes in Xplore, is provided with a screenshot of the current status of the display. LLM's such as OpenAI GPT-4o model enable the possibility of passing this images as zero-shot prompts, enhancing the reasoning of the agent fully adapting to the multiple variables of different systems. An example screenshot passed to Xplore","title":"Vision Capabilities"},{"location":"Xplore-Insights/#results","text":"","title":"Results"},{"location":"Xplore-Insights/#key-advantages","text":"Adaptability : By using visual capabilities, xplore is able to adapt to multiple environments, taking care of the arrangement of the windows, buttons, etc. Target Aiming : Xplore uses both long-term and short-term planning for building the following actions. This awareness boosts the planning process by simplifying uncertain future status and focusing closer actions. Explainability : By reasoning after each step we can define why the agent selects each action and what is its pourpuse. Cause-Effect Aware : By reviewing the effects of each action the agent takes, makes the agent able to react to incorrect steps and correct the plan to a viable solution.","title":"Key Advantages"},{"location":"Xplore-Insights/#key-disadvantages","text":"Velocity : By reasoning and using visual capabilities in each action the velocity of each action has been reduced to 50s/task (aprox.). Backward Planning : The Agent can't recover from certain actions where the next subgoal cannot be completed without replanning all the task or adding correction subgoals. Hallucinations and Icon difficulties : Not all elements from the display are correctly interpreted from the agent, where visual icons, buttons or drawings are misunderstood. In the next video, we provide an example execution of Xplore. Video","title":"Key Disadvantages"},{"location":"_Footer/","text":"Navigation: Home | Repository All content is licensed under a Reserved License unless otherwise noted.","title":" Footer"},{"location":"_Sidebar/","text":"Home Introduction \u2728 State of Art - LLM's and Frameworks - AgentProtocol - Bibliography \ud83e\uddea Architecture - Theoretical Fundamentals - Architecture Overview - Architecture Guide - ECM Problem Analysis \ud83d\udee0\ufe0f Tutorials - ItemRegistry - Exelent - Interpreters - FastAgentProtocol - Remote Execution - Cognitive Memory \ud83d\udd0d Component Insights - FastReact - Xplore - MouseAgent - Self Training Agents \ud83d\udca1 Capabilities - RosaInterpreter - PyxcelInterpreter \ud83d\udd1a Deprecations - ROSA Tutorial - ROSA TaskSequence Protocol - Planex Tutorial - Planex Insights - RePlan - Cognition Layer API","title":" Sidebar"}]}